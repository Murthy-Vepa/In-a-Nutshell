<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='80' font-size='80'>‚òÅÔ∏è</text></svg>" />
  <title>Cloud Design Patterns - In a Nutshell</title>
  <meta name="description" content="A comprehensive guide to Cloud Design Patterns from Microsoft Azure Architecture." />
  <link rel="stylesheet" href="Nutshell.css">
  <!-- Bootstrap CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
  <style>
    :root{
      --bg: #ffffff;
      --fg: #0f172a;
      --muted: #64748b;
      --accent: #3b82f6;
      --accent-light: #dbeafe;
      --border: #e2e8f0;
      --sidebar-bg: #ffffff;
      --sidebar-fg: #0f172a;
      --code-bg: linear-gradient(90deg, rgba(59, 130, 246, 0.08) 0%, rgba(59, 130, 246, 0.12) 100%);
      --focus: #10b981;
      --shadow-sm: 0 1px 3px rgba(0,0,0,0.08);
      --shadow-md: 0 4px 6px rgba(0,0,0,0.1), 0 2px 4px rgba(0,0,0,0.06);
      --shadow-lg: 0 10px 20px rgba(0,0,0,0.12), 0 6px 6px rgba(0,0,0,0.08);
      --gradient: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%);
    }
    
    /* Bootstrap Gradient Utility Classes */
    .bg-gradient-blue { background: linear-gradient(135deg, #dbeafe 0%, #bfdbfe 100%) !important; }
    .bg-gradient-green { background: linear-gradient(135deg, #dcfce7 0%, #bbf7d0 100%) !important; }
    .bg-gradient-yellow { background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%) !important; }
    .bg-gradient-pink { background: linear-gradient(135deg, #fce7f3 0%, #fbcfe8 100%) !important; }
    .bg-gradient-purple { background: linear-gradient(135deg, #e9d5ff 0%, #d8b4fe 100%) !important; }
    .bg-gradient-teal { background: linear-gradient(135deg, #ccfbf1 0%, #99f6e4 100%) !important; }
    .bg-gradient-blue-dark { background: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%) !important; }
    .bg-gradient-gray { background: linear-gradient(135deg, #64748b 0%, #475569 100%) !important; }
    .bg-gradient-purple-dark { background: linear-gradient(135deg, #a855f7 0%, #9333ea 100%) !important; }
    .bg-gradient-teal-dark { background: linear-gradient(135deg, #14b8a6 0%, #0d9488 100%) !important; }
    .bg-gradient-green-dark { background: linear-gradient(135deg, #10b981 0%, #059669 100%) !important; }
    .bg-gradient-red { background: linear-gradient(135deg, #fee2e2 0%, #fecaca 100%) !important; }
    .bg-gradient-green-light { background: linear-gradient(135deg, #d1fae5 0%, #a7f3d0 100%) !important; }
    .bg-gradient-blue-sky { background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%) !important; }
    .bg-gradient-red-dark { background: linear-gradient(135deg, #dc2626 0%, #b91c1c 100%) !important; }
    .bg-gradient-indigo { background: linear-gradient(135deg, #4f46e5 0%, #4338ca 100%) !important; }
    .bg-gradient-green-medium { background: linear-gradient(135deg, #10b981 0%, #059669 100%) !important; }
    .bg-gradient-orange { background: linear-gradient(135deg, #f97316 0%, #ea580c 100%) !important; }
    .bg-gradient-violet { background: linear-gradient(135deg, #8b5cf6 0%, #7c3aed 100%) !important; }
    .bg-gradient-lime { background: linear-gradient(135deg, #84cc16 0%, #65a30d 100%) !important; }
    .bg-gradient-sky { background: linear-gradient(135deg, #0284c7 0%, #0369a1 100%) !important; }
    
    /* Apply theme colors to Bootstrap elements */
    body { background-color: var(--bg); color: var(--fg); overflow: hidden; }
    .navbar { background-color: var(--fg) !important; border-bottom: none !important; box-shadow: var(--shadow-md) !important; }
    .navbar-brand { cursor: pointer; color: var(--bg) !important; font-weight: 600; letter-spacing: 0px; }
    .navbar-toggler-icon { 
      filter: invert(1);
      background-image: url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'%3e%3cpath stroke='rgba%2896, 165, 250, 0.9%29' stroke-linecap='round' stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/%3e%3c/svg%3e");
    }
    
    .btn-outline-secondary { border-color: var(--border) !important; color: var(--fg) !important; }
    .btn-outline-secondary:hover { background-color: var(--accent-light) !important; border-color: var(--accent) !important; color: var(--accent) !important; }
    
    /* Sidebar - Modern Design */
    nav.sidebar { 
      background: linear-gradient(180deg, #f3f4f6 0%, #e5e7eb 100%); 
      border-right: 1px solid rgba(0, 0, 0, 0.05) !important;  
      overflow-y: auto; 
      box-shadow: 4px 0 16px rgba(0, 0, 0, 0.06);
      padding-top: 0;
    }
    
    .menu-header {  
      background: linear-gradient(135deg, rgba(0, 0, 0, 0.15), rgba(0, 0, 0, 0.1) 100%);
      font-weight: bold; 
      padding: 1.25rem 1.25rem; 
      letter-spacing: 0px; 
      font-size: 1.1rem;
      position: relative;
      overflow: hidden;
      border: none;
      border-bottom: 2px solid #a5aab3;
      box-shadow: 0 2px 6px rgba(0, 0, 0, 0.12);
      color: #0c346c;
      text-shadow: none;
      margin: 0;
      text-transform: none;
    }
    .menu-header::before {
      content: '';
      position: absolute;
      top: 0;
      left: -100%;
      width: 100%;
      height: 100%;
      background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.15), transparent);
      transition: left 0.6s ease;
    }
    .menu-header:hover::before {
      left: 100%;
    }
    .menu-header::after {
      content: 'üìã';
      position: absolute;
      right: 1.5rem;
      top: 50%;
      transform: translateY(-50%);
      font-size: 1.3rem;
      opacity: 0.9;
      filter: drop-shadow(0 1px 2px rgba(0, 0, 0, 0.2));
    }
    
    .toc { 
      list-style: none; 
      padding: 0rem 0; 
      margin: 0; 
      background: transparent;
    }
    .toc li { 
      margin: 0; 
    }
    
    /* Section grouping */
    .toc li[data-group="overview"] { margin-bottom: 0.75rem; }
    .toc li[data-group="solid"]:first-of-type { 
      margin-top: 1rem; 
      border-top: 2px solid rgba(59, 130, 246, 0.15);
      padding-top: 1rem;
    }
    .toc li[data-group="other-principles"]:first-of-type { 
      margin-top: 1rem; 
      border-top: 2px solid rgba(16, 185, 129, 0.15);
      padding-top: 1rem;
    }
    .toc li[data-group="resources"] { 
      margin-top: 1rem; 
      border-top: 2px solid rgba(100, 116, 139, 0.15);
      padding-top: 1rem;
    }
    
    .list-group-item { 
      background: transparent; 
      border-color: transparent; 
      padding: 0; 
      margin: 0.25rem 0.75rem; 
      border-radius: 0rem;
      transition: all 0.2s ease;
    }
    .list-group-item a { 
      color: #1f2937; 
      text-decoration: none; 
      display: flex; 
      flex-direction: column; 
      align-items: flex-start; 
      gap: 0.4rem; 
      border-left: 3px solid transparent; 
      padding: 0.85rem 1.25rem; 
      transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1); 
      font-weight: 500; 
      border-radius: 0rem;
      font-size: 0.95rem;
      position: relative;
      overflow: hidden;
      background: linear-gradient(90deg, rgba(255, 255, 255, 0.4) 0%, rgba(255, 255, 255, 0.1) 100%);
      border: 1px solid rgba(0, 0, 0, 0.06);
      -webkit-backdrop-filter: blur(10px);
      backdrop-filter: blur(10px);
      box-shadow: 0 1px 3px rgba(0, 0, 0, 0.05);
    }
    .list-group-item a::before {
      content: '';
      position: absolute;
      left: 0;
      top: 0;
      height: 100%;
      width: 4px;
      background: linear-gradient(180deg, #3b82f6 0%, #2563eb 100%);
      transform: scaleY(0);
      transition: transform 0.3s ease;
      border-radius: 0 0px 0px 0;
    }
    .list-group-item a::after {
      content: '‚ñ∂';
      position: absolute;
      right: 1rem;
      top: 50%;
      transform: translateY(-50%) scale(0.7);
      font-size: 0.7rem;
      color: #9ca3af;
      opacity: 0;
      transition: all 0.3s ease;
    }
    .list-group-item a:hover { 
      background: linear-gradient(90deg, rgba(59, 130, 246, 0.15) 0%, rgba(59, 130, 246, 0.08) 100%); 
      border-left-color: transparent;
      color: #1e40af;
      box-shadow: 0 4px 12px rgba(59, 130, 246, 0.2), 0 2px 4px rgba(0, 0, 0, 0.08);
      border-color: rgba(59, 130, 246, 0.2);
      text-decoration: none;
    }
    .list-group-item a:hover::before {
      transform: scaleY(1);
    }
    .list-group-item a:hover::after {
      opacity: 1;
      transform: translateY(-50%) scale(1);
      color: #3b82f6;
    }
    .list-group-item a.active { 
      background: linear-gradient(90deg, rgba(59, 130, 246, 0.22) 0%, rgba(59, 130, 246, 0.12) 100%); 
      color: #1e40af; 
      font-weight: 600; 
      border-left-color: transparent;
      box-shadow: 0 4px 16px rgba(59, 130, 246, 0.25), inset 0 1px 0 rgba(255, 255, 255, 0.3);
      border-color: rgba(59, 130, 246, 0.3);
    }
    .list-group-item a.active::before {
      transform: scaleY(1);
      background: linear-gradient(180deg, #3b82f6 0%, #2563eb 100%);
      width: 5px;
      box-shadow: 0 0 8px rgba(59, 130, 246, 0.5);
    }
    .list-group-item a.active::after {
      opacity: 1;
      color: #2563eb;
      transform: translateY(-50%) scale(1);
    }
    .list-group-item a.active:hover { 
      background: linear-gradient(90deg, rgba(59, 130, 246, 0.28) 0%, rgba(59, 130, 246, 0.16) 100%); 
      box-shadow: 0 6px 20px rgba(59, 130, 246, 0.3), inset 0 1px 0 rgba(255, 255, 255, 0.4);
    }
    
    /* Sub-items tree connectors */
    .list-group-sub-item a::before { 
      content: '‚îú‚îÄ';
      font-size: 0.85rem;
      margin-right: 0.5rem;
      color: #6b7280;
      z-index: 1;
      position: relative;
    }
    
    /* Sub-items styling - similar to main items but smaller and indented */
    .list-group-sub-item {
      background: transparent; 
      border-color: transparent; 
      padding: 0px; 
      margin: 0.2rem 0.75rem 0.2rem 1.5rem;
      border-radius: 0rem;
      transition: all 0.2s ease;
      position: relative;
      list-style-type: none;
    }
    .list-group-sub-item::before {
      content: '';
      position: absolute;
      left: 0;
      top: 0;
      height: 100%;
      width: 4px;
      background: linear-gradient(180deg, #3b82f6 0%, #2563eb 100%);
      transform: scaleY(0);
      transition: transform 0.3s ease;
      border-radius: 0 0px 0px 0;
      z-index: 1;
    }
    .list-group-sub-item a {
      color: #1f2937; 
      text-decoration: none; 
      display: block;
      border-left: 3px solid transparent; 
      padding: 0.65rem 1rem 0.65rem 2.00rem;
      transition: all 0.2s ease; 
      font-weight: 500; 
      border-radius: 0rem;
      font-size: 0.8125rem;
      line-height: 1.4;
      position: relative;
      overflow: hidden;
      background: rgba(255, 255, 255, 0.5);
      border: 1px solid rgba(0, 0, 0, 0.04);
      box-shadow: 0 1px 2px rgba(0, 0, 0, 0.04);
    }
    
    /* Sub-items hover and active states - same as main items */
    .list-group-sub-item a::after {
      content: '‚ñ∂';
      position: absolute;
      right: 1rem;
      top: 50%;
      transform: translateY(-50%) scale(0.7);
      font-size: 0.7rem;
      color: #9ca3af;
      opacity: 0;
      transition: all 0.3s ease;
    }
    
    .list-group-sub-item:hover::before {
      transform: scaleY(1);
    }
    .list-group-sub-item a:hover { 
      background: linear-gradient(90deg, rgba(59, 130, 246, 0.15) 0%, rgba(59, 130, 246, 0.08) 100%); 
      border-left-color: transparent;
      color: #1e40af;
      box-shadow: 0 4px 12px rgba(59, 130, 246, 0.2), 0 2px 4px rgba(0, 0, 0, 0.08);
      border-color: rgba(59, 130, 246, 0.2);
      text-decoration: none;
    }
    .list-group-sub-item a:hover::after {
      opacity: 1;
      transform: translateY(-50%) scale(1);
      color: #3b82f6;
    }
    
    .list-group-sub-item.active::before {
      transform: scaleY(1);
      width: 5px;
      box-shadow: 0 0 8px rgba(59, 130, 246, 0.5);
    }
    .list-group-sub-item a.active { 
      background: linear-gradient(90deg, rgba(59, 130, 246, 0.22) 0%, rgba(59, 130, 246, 0.12) 100%); 
      color: #1e40af; 
      font-weight: 600; 
      border-left-color: transparent;
      box-shadow: 0 4px 16px rgba(59, 130, 246, 0.25), inset 0 1px 0 rgba(255, 255, 255, 0.3);
      border-color: rgba(59, 130, 246, 0.3);
    }
    .list-group-sub-item a.active::after {
      opacity: 1;
      color: #2563eb;
      transform: translateY(-50%) scale(1);
    }
    .list-group-sub-item a.active:hover { 
      background: linear-gradient(90deg, rgba(59, 130, 246, 0.28) 0%, rgba(59, 130, 246, 0.16) 100%); 
      box-shadow: 0 6px 20px rgba(59, 130, 246, 0.3), inset 0 1px 0 rgba(255, 255, 255, 0.4);
    }
    
    .list-group-item a::after {
      content: '‚ñ∂';
      position: absolute;
      right: 1rem;
      top: 50%;
      transform: translateY(-50%) scale(0.7);
      font-size: 0.7rem;
      color: #9ca3af;
      opacity: 0;
      transition: all 0.3s ease;
    }
    
    .list-group-item a:hover { 
      background: linear-gradient(90deg, rgba(59, 130, 246, 0.15) 0%, rgba(59, 130, 246, 0.08) 100%); 
      border-left-color: transparent;
      color: #1e40af;
      box-shadow: 0 4px 12px rgba(59, 130, 246, 0.2), 0 2px 4px rgba(0, 0, 0, 0.08);
      border-color: rgba(59, 130, 246, 0.2);
      text-decoration: none;
    }
    .list-group-item a:hover::before {
      transform: scaleY(1);
    }
    .list-group-item a:hover::after {
      opacity: 1;
      transform: translateY(-50%) scale(1);
      color: #3b82f6;
    }
    .list-group-item a.active { 
      background: linear-gradient(90deg, rgba(59, 130, 246, 0.22) 0%, rgba(59, 130, 246, 0.12) 100%); 
      color: #1e40af; 
      font-weight: 600; 
      border-left-color: transparent;
      box-shadow: 0 4px 16px rgba(59, 130, 246, 0.25), inset 0 1px 0 rgba(255, 255, 255, 0.3);
      border-color: rgba(59, 130, 246, 0.3);
    }
    .list-group-item a.active::after {
      opacity: 1;
      color: #2563eb;
      transform: translateY(-50%) scale(1);
    }
    .list-group-item a.active:hover { 
      background: linear-gradient(90deg, rgba(59, 130, 246, 0.28) 0%, rgba(59, 130, 246, 0.16) 100%); 
      box-shadow: 0 6px 20px rgba(59, 130, 246, 0.3), inset 0 1px 0 rgba(255, 255, 255, 0.4);
    }
    
    /* Badge styling */
    .badge { font-size: 0.8rem; padding: 0.15rem 0.4rem; background: var(--accent-light); color: var(--accent); border: 1px solid var(--accent); font-weight: 600; border-radius: 0.25rem; font-style: normal; line-height: 1.2; opacity: 0.9; }
    .badge { background: var(--accent); color: white; border: none; font-size: 0.6rem; padding: 0.25rem 0.5rem; font-weight: 600; text-transform: uppercase; letter-spacing: 0.5px; display: inline-block; margin-top: 0.5rem; margin-right: 0.35rem; }
    .list-group-item a:hover .badge { opacity: 1; background: var(--accent); color: white; }
    .list-group-item a.active .badge { background: rgba(255, 255, 255, 0.3); color: white; border-color: rgba(255, 255, 255, 0.6); font-weight: 600; opacity: 1; }
        
    /* Content */
    .content { width: 100%; max-width: 100%; margin: 0 auto; background: #ffffff; padding: 2rem; border-radius: 0.75rem; box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08); }
    section { display: none !important; margin-bottom: 2rem; }
    section.active { display: block !important; }
    @keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }
    
    h1 { font-size: 2rem; font-weight: 700; margin: 1rem 0 0.25rem 0; letter-spacing: -0.5px; color: var(--fg); display: block; border: none; }
    h2 { font-size: 1.5rem; font-weight: 600; margin: 1.5rem 0 0.75rem 0; color: var(--fg); border-bottom: 2px solid var(--accent-light); padding-bottom: 0.5rem; }
    h3 { font-size: 1.1rem; color: var(--accent); font-weight: 600; margin: 1rem 0 0.5rem 0; }
    h4 { font-size: 0.8rem; color: var(--fg); font-weight: 600; margin: 0.75rem 0 0.4rem 0; }
    p { margin: 1rem 0; line-height: 1.65; color: var(--fg); }
    ul, ol { margin: 1rem 0; padding-left: 2rem; }
    li { margin: 0.5rem 0; color: var(--fg); }
    
    code { background: var(--code-bg); border: 1px solid var(--border); padding: 0.2rem 0.5rem; font-family: ui-monospace, 'Cascadia Code', 'Source Code Pro', monospace; font-size: 0.9em; color: var(--accent); border-radius: 0.5rem; }
    pre { background: var(--code-bg); border: 0px solid var(--border); padding: 1rem; border-radius: 0.5rem; overflow: auto; box-shadow: var(--shadow-sm); margin: 1rem 0; }
    pre code { padding: 0; background: transparent; border: none; color: var(--fg); }
    
    .callout { border-left: 5px solid var(--accent); background: var(--accent-light); padding: 1rem 1.2rem; margin: 1.5rem 0; border-radius: 0.5rem; box-shadow: var(--shadow-sm); font-weight: 500; color: var(--fg); }
    
    /* Table styling */
    .table { color: var(--fg); }
    .table thead th { background: var(--accent-light); color: var(--accent); border-color: var(--border); font-weight: 600; }
    .table tbody td { border-color: var(--border); }
    .table-striped tbody tr:nth-of-type(odd) { background-color: rgba(0,0,0,0.02); }
    .table-striped tbody tr:hover { background-color: var(--accent-light); }
    
    /* Controls/Pagination */
    .controls { opacity: 0.5; position: fixed; bottom: 0.25rem; right: 1rem; width: auto; z-index: 1000; background: transparent; display: flex; align-items: center; justify-content: center; gap: 0rem; padding: 0; min-height: 40px; }
    @media (max-width: 991px) {
      .controls { bottom: 0.25rem; right: 1rem; }
      .menu-header { color: var(--focus); }
    }
    .controls:hover { opacity: 1; }
    
    .page-indicator { color: var(--accent); font-weight: 600; font-size: 0.875rem; }
    .btn-group .btn { margin: 0px 2px; padding: 0.2rem 0.5rem; background: var(--accent); color: white; border-color: var(--accent); font-size: 1rem; font-weight: bold; }
    .btn-group .btn:hover { background: var(--accent); }
    .btn-group .btn + .btn { margin-left: -1px; }
    
    /* Mobile/Offcanvas */
    .offcanvas { background: var(--bg) !important; }
    .offcanvas-header { border-bottom: 1px solid var(--border); }
    .offcanvas-title { color: var(--fg); font-weight: 600; }
    .btn-close { color: var(--fg); }
    
    /* Scrollbar */
    nav.sidebar::-webkit-scrollbar { width: 6px; }
    nav.sidebar::-webkit-scrollbar-track { background: rgba(0, 0, 0, 0.05); }
    nav.sidebar::-webkit-scrollbar-thumb { background: rgba(0, 0, 0, 0.2); border-radius: 0px; }
    nav.sidebar::-webkit-scrollbar-thumb:hover { background: rgba(0, 0, 0, 0.3); }
    
    /* Mermaid Diagrams */
    .mermaid {
      background: #ffffff;
      border: 1px solid #e2e8f0;
      border-radius: 0.5rem;
      padding: 2rem;
      margin: 1.5rem 0;
      min-height: 400px;
      display: flex;
      align-items: center;
      justify-content: center;
      overflow: visible;
      position: relative;
    }
    .mermaid.rendered {
      min-height: 0;
    }
    .mermaid svg {
      max-width: 100%;
      height: auto;
      min-height: 300px;
      transition: transform 0.3s ease;
      transform-origin: center center;
    }
    .mermaid.zoomed {
      overflow: auto;
      cursor: grab;
    }
    .mermaid.zoomed:active {
      cursor: grabbing;
    }
    .mermaid svg text {
      font-size: 14px !important;
      font-family: 'Segoe UI', system-ui, -apple-system, sans-serif !important;
    }
    
    /* Mermaid title styling */
    .mermaid svg text, .diagram-modal-content svg text {
      font-size: 1rem !important;
      font-weight: bold !important;
      fill: var(--fg) !important;
      font-family: 'Segoe UI', system-ui, -apple-system, sans-serif !important;
    }

    .mermaid svg *
    {
        color: #333;
    }

    .mermaid[data-processed="true"] {
      min-height: 0;
    }
    
    .mermaid svg {
      max-width: 100%;
      height: auto;
      display: inline-block;
    }
    
    /* Zoom controls */
    .zoom-controls {
      position: absolute;
      top: 10px;
      right: 10px;
      z-index: 10;
      opacity: 0.5;
      transition: opacity 0.3s ease;
    }
    .mermaid:hover .zoom-controls {
      opacity: 1;
    }
    .zoom-btn {
      background: var(--accent);
      color: white;
      border: none;
      border-radius: 0.25rem;
      width: 32px;
      height: 32px;
      display: flex;
      align-items: center;
      justify-content: center;
      cursor: pointer;
      font-size: 16px;
      font-weight: bold;
      box-shadow: 0 2px 4px rgba(0,0,0,0.2);
      transition: all 0.2s ease;
    }
    .zoom-btn:hover {
      background: #2563eb;
      transform: scale(1.1);
    }

    /* Modal for diagram zoom */
    .diagram-modal {
      display: none;
      position: fixed;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      background: rgba(0, 0, 0, 0.95);
      z-index: 9999;
      align-items: center;
      justify-content: center;
      padding: 0;
    }
    .diagram-modal.active {
      display: flex;
    }
    .diagram-modal-content {
      position: relative;
      width: 100%;
      height: 100%;
      background: white;
      border-radius: 0;
      padding: 3rem 3rem 3rem 3rem;
      overflow: auto;
      display: flex;
      align-items: flex-start;
      justify-content: center;
    }
    .diagram-modal-content svg {
      max-width: 100%;
      height: auto;
    }
    .modal-close {
      position: fixed;
      top: 1.5rem;
      right: 1.5rem;
      background: #ef4444;
      color: white;
      border: none;
      border-radius: 50%;
      width: 32px;
      height: 32px;
      display: flex;
      align-items: center;
      justify-content: center;
      cursor: pointer;
      font-size: 16px;
      font-weight: bold;
      box-shadow: 0 4px 8px rgba(0,0,0,0.3);
      transition: all 0.2s ease;
      z-index: 10000;
    }
    .modal-close:hover {
      background: #dc2626;
      transform: scale(1.1);
    }
    .modal-zoom-controls {
      position: fixed;
      bottom: 1.5rem;
      right: 1.5rem;
      display: flex;
      gap: 0.5rem;
      z-index: 10000;
      padding: 0rem;
      border-radius: 0.4rem;
    }
    .modal-zoom-btn {
      background: var(--accent);
      color: white;
      border: none;
      border-radius: 0.25rem;
      width: 32px;
      height: 32px;
      display: flex;
      align-items: center;
      justify-content: center;
      cursor: pointer;
      font-size: 16px;
      font-weight: bold;
      box-shadow: 0 2px 4px rgba(0,0,0,0.2);
      transition: all 0.2s ease;
    }
    .modal-zoom-btn:hover {
      background: #2563eb;
      transform: scale(1.1);
    }
    
    /* Utilities */
    .search { height: 0; overflow: hidden; padding: 0 !important; }
    .search input { display: none; }
    .min-vh-100 { min-height: 100vh; }
    .skip-link { position: absolute; left: -9999px; top: auto; width: 1px; height: 1px; overflow: hidden; }
    .skip-link:focus { position: static; width: auto; height: auto; padding: 0.4rem 0.6rem; background: var(--accent); color: white; border-radius: 0.4rem; }
    
    /* Override Bootstrap defaults for theme */
    a { color: var(--accent); }
    a:hover { color: var(--accent); text-decoration: underline; }
    
    /* Responsive - keep sidebar visible on desktop, offcanvas on mobile */
    @media (max-width: 991px) {
      nav.sidebar { display: none; }
      #main { width: 100%; }
      .row { --bs-gutter-x: 0; }
    }
    
    /* Layout - prevent unnecessary scrolling */
    html, body { height: 100%; margin: 0; }
    #appContainer { display: flex; flex-direction: column; height: calc(100vh - 50px); }
    #mainRow { flex: 1; overflow: hidden; display: flex; }
    nav.sidebar { overflow-y: auto; max-height: 100%; position: relative; padding-bottom: 0px; }
    #main { overflow: hidden; display: flex; flex-direction: column; height: 100%; -webkit-tap-highlight-color: transparent; outline: none; border: none; }
    #main:focus { outline: none; }
    .content { overflow-y: auto; flex: 1; width: 100%; min-height: 0; padding: 0rem 1.5rem 0rem 1.5rem; }
    
    /* Contact Info */
    .contact-info {
      font-weight: 400 !important;
      padding: 0.5rem 0.75rem;
      font-size: 0.75rem;
      color: var(--accent-light);
      margin: 0;
      opacity: 0.5;
      white-space: nowrap;
      cursor: pointer;
    }
    .contact-info:hover {
      opacity: 0.9;
      text-decoration: none;
    }
    @media (max-width: 991px) {
      .navbar-brand {
        font-size: 1rem !important;
        flex: 1;
      }
      .contact-info {
        font-size: 0.7rem;
        padding: 0.25rem 0.5rem;
      }
    }
    @media (max-width: 576px) {
      .navbar-brand {
        font-size: 0.9rem !important;
      }
      .contact-info {
        font-size: 0.65rem;
        padding: 0.2rem 0.4rem;
      }
    }

    .list-style-none {
      list-style: none;
      padding: 0;
      margin: 0;
    }

    /* JSON Syntax Highlighting */
    pre code.language-json {
      display: block;
      white-space: pre;
      font-family: 'Cascadia Code', 'Consolas', 'Monaco', 'Courier New', monospace;
    }

    pre code.language-json .json-key {
      color: #0451a5;
      font-weight: 500;
    }

    pre code.language-json .json-string {
      color: #a31515;
    }

    pre code.language-json .json-number {
      color: #098658;
    }

    pre code.language-json .json-boolean {
      color: #0000ff;
      font-weight: 600;
    }

    pre code.language-json .json-null {
      color: #0000ff;
      font-weight: 600;
    }

    pre code.language-json .json-punctuation {
      color: #333;
    }

    /* SQL Syntax Highlighting */
    pre code.language-sql {
      display: block;
      white-space: pre;
      font-family: 'Cascadia Code', 'Consolas', 'Monaco', 'Courier New', monospace;
    }

    pre code.language-sql .sql-keyword {
      color: #0000ff;
      font-weight: 600;
      text-transform: uppercase;
    }

    pre code.language-sql .sql-string {
      color: #a31515;
    }

    pre code.language-sql .sql-number {
      color: #098658;
    }

    pre code.language-sql .sql-comment {
      color: #008000;
      font-style: italic;
    }

    pre code.language-sql .sql-function {
      color: #795e26;
      font-weight: 500;
    }

    pre code.language-sql .sql-operator {
      color: #666;
      font-weight: 500;
    }

    /* Language Label for Code Blocks */
    pre[data-language]::before {
      content: attr(data-language);
      position: absolute;
      top: 8px;
      right: 12px;
      font-size: 0.75em;
      color: #6a737d;
      text-transform: uppercase;
      font-weight: 600;
      letter-spacing: 0.5px;
      background: var(--bg);
      padding: 0.2rem 0.5rem;
      border-radius: 0.25rem;
      border: 1px solid var(--border);
    }

    /* Enhanced pre/code styling for syntax highlighted blocks */
    pre.syntax-highlighted {
      position: relative;
      background: var(--code-bg);
      border: 1px solid var(--border);
      padding: 1.5rem 1rem 1rem 1rem;
      border-radius: 0.5rem;
      overflow-x: auto;
      box-shadow: var(--shadow-sm);
      margin: 1rem 0;
    }

    pre.syntax-highlighted code {
      background: transparent;
      padding: 0;
      border: none;
      color: var(--fg);
      font-size: 0.875rem;
      line-height: 1.6;
    }

    ul
    {
        list-style-type: none;
    }
  /* Document Footer */
    .document-footer {
      text-align: center;
      padding: 20px;
      background-color: #f8f9fa;
      border-radius: 8px;
      margin-top: 20px;
    }
    .document-footer p {
      margin: 0;
      font-size: 14px;
      color: #6c757d;
      line-height: 1.6;
    }
    .document-footer strong {
      color: #495057;
    }  
  </style>
  <!-- Mermaid.js for diagrams -->
  <script src="https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.min.js"></script>
  <script>
    // Initialize Mermaid with proper configuration
    document.addEventListener('DOMContentLoaded', function() {

      mermaid.initialize({
        startOnLoad: false,
        theme: 'base',
        securityLevel: 'loose',
        logLevel: 'error',
        themeVariables: {
         'fontFamily': 'Segoe UI'
        },
        flowchart: {
          useMaxWidth: true,
          htmlLabels: true,
          curve: 'basis',
        },
        sequence: {
          useMaxWidth: false,
          htmlLabels: true,
          diagramMarginX: 50,
          diagramMarginY: 10
        }
      });
      
      // Render all diagrams
      renderMermaidDiagrams();
    });
    
    async function renderMermaidDiagrams() {
      const diagrams = document.querySelectorAll('.mermaid');
      
      for (let i = 0; i < diagrams.length; i++) {
        const diagram = diagrams[i];
        const code = diagram.textContent.trim();
        
        // Store original code
        if (!diagram.hasAttribute('data-original-code')) {
          diagram.setAttribute('data-original-code', code);
        }
        
        try {
          const { svg } = await mermaid.render('mermaid-diagram-' + i, code);
          diagram.innerHTML = svg;
          diagram.setAttribute('data-processed', 'true');
          
          // Add zoom controls
          addZoomControls(diagram);
        } catch (error) {
          console.error('Mermaid rendering error for diagram ' + i + ':', error);
          diagram.innerHTML = '<div style="color: red; padding: 1rem; border: 2px solid red; border-radius: 0.5rem;">Error rendering diagram: ' + error.message + '</div>';
        }
      }
    }
    
    // Add zoom controls to mermaid diagrams
    function addZoomControls(diagram) {
      const controls = document.createElement('div');
      controls.className = 'zoom-controls';
      controls.innerHTML = `
        <button class="zoom-btn" data-action="expand" title="Expand View">‚õ∂</button>
      `;
      
      diagram.style.position = 'relative';
      diagram.insertBefore(controls, diagram.firstChild);
      
      // Expand to modal
      controls.addEventListener('click', (e) => {
        const btn = e.target.closest('.zoom-btn');
        if (!btn) return;
        
        openDiagramModal(diagram);
      });
    }

    // Open diagram in modal
    function openDiagramModal(diagram) {
      // Create modal if it doesn't exist
      let modal = document.getElementById('diagram-modal');
      if (!modal) {
        modal = document.createElement('div');
        modal.id = 'diagram-modal';
        modal.className = 'diagram-modal';
        modal.innerHTML = `
          <button class="modal-close" id="modal-close">√ó</button>
          <div class="diagram-modal-content" id="modal-diagram-content"></div>
          <div class="modal-zoom-controls">
            <button class="modal-zoom-btn" data-action="zoom-in" title="Zoom In">+</button>
            <button class="modal-zoom-btn" data-action="zoom-out" title="Zoom Out">‚àí</button>
            <button class="modal-zoom-btn" data-action="reset" title="Reset Zoom">‚ü≤</button>
          </div>
        `;
        document.body.appendChild(modal);
        
        // Close modal handlers
        modal.querySelector('#modal-close').addEventListener('click', closeDiagramModal);
        modal.addEventListener('click', (e) => {
          if (e.target === modal) closeDiagramModal();
        });
        document.addEventListener('keydown', (e) => {
          if (e.key === 'Escape' && modal.classList.contains('active')) {
            closeDiagramModal();
          }
        });
        
        // Zoom controls in modal
        let scale = 1;
        let translateX = 0;
        let translateY = 0;
        
        modal.querySelector('.modal-zoom-controls').addEventListener('click', (e) => {
          const btn = e.target.closest('.modal-zoom-btn');
          if (!btn) return;
          
          const action = btn.dataset.action;
          const svg = modal.querySelector('svg');
          if (!svg) return;
          
          if (action === 'zoom-in') {
            scale = Math.min(scale + 0.1, 5);
          } else if (action === 'zoom-out') {
            scale = Math.max(scale - 0.1, 0.5);
          } else if (action === 'reset') {
            scale = 1;
            translateX = 0;
            translateY = 0;
          }
          
          svg.style.transform = `scale(${scale}) translate(${translateX / scale}px, ${translateY / scale}px)`;
        });
      }
      
      // Clone diagram content
      const svg = diagram.querySelector('svg');
      if (svg) {
        const content = modal.querySelector('#modal-diagram-content');
        content.innerHTML = '';
        const clonedSvg = svg.cloneNode(true);
        clonedSvg.style.transform = 'scale(1)';
        clonedSvg.style.maxWidth = '100%';
        clonedSvg.style.height = 'auto';
        content.appendChild(clonedSvg);
      }
      
      modal.classList.add('active');
      document.body.style.overflow = 'hidden';
    }

    function closeDiagramModal() {
      const modal = document.getElementById('diagram-modal');
      if (modal) {
        modal.classList.remove('active');
        document.body.style.overflow = '';
      }
    }
    
    // Re-render on theme change
    window.rerenderMermaid = async function() {
      const isDark = document.documentElement.getAttribute('data-theme') === 'dark';
      
      mermaid.initialize({
        startOnLoad: false,
        theme: isDark ? 'base' : 'base',
        securityLevel: 'loose',
        flowchart: {
          useMaxWidth: true,
          htmlLabels: true,
          curve: 'basis',
        },
        sequence: {
          useMaxWidth: false,
          htmlLabels: true,
          diagramMarginX: 50,
          diagramMarginY: 10
        }
      });
      
      const diagrams = document.querySelectorAll('.mermaid[data-processed="true"]');
      for (let i = 0; i < diagrams.length; i++) {
        const diagram = diagrams[i];
        const code = diagram.getAttribute('data-original-code');
        
        if (code) {
          try {
            const { svg } = await mermaid.render('mermaid-diagram-rerender-' + i + '-' + Date.now(), code);
            diagram.innerHTML = svg;
          } catch (error) {
            console.error('Mermaid re-rendering error:', error);
          }
        }
      }
    };
  </script>
</head>
<body>
  <nav class="navbar navbar-expand-lg sticky-top" aria-label="Top bar">
    <div class="container-fluid d-flex align-items-center">
      <button class="navbar-toggler me-2" id="toggleSidebar" type="button" aria-label="Toggle sidebar">
        <span class="navbar-toggler-icon"></span>
      </button>
<span class="navbar-brand mb-0 h1 me-auto">‚òÅÔ∏è Azure Cloud Design Patterns - In a Nutshell</span>
<span class="contact-info mb-0">ü§ù Curated by Murthy Vepa</span>
    </div>      
  </nav>

  <div id="appContainer">
    <div class="row g-0" id="mainRow">
      <nav class="col-lg-3 border-end sidebar" id="sidebar" aria-label="Table of contents">
        <div class="menu-header py-2">Contents</div>
        <ul class="list-group list-group-flush toc" id="toc"></ul>
      </nav>

      <main id="main" class="col-lg-9 d-flex flex-column" tabindex="-1">
        <div class="content" id="content">
        <!-- Overview Section -->
        <section id="overview" role="article">
          <h1>‚òÅÔ∏è Overview</h1>
          <span class="badge">intro</span>
          <span class="badge">overview</span>
          <span class="badge">azure</span>
          
          <h2>Introduction</h2>
          <p>Cloud design patterns are reusable solutions to commonly occurring problems in cloud application architecture. These patterns provide proven approaches for building reliable, scalable, secure, and efficient cloud-native applications on platforms like Microsoft Azure.</p>
          
          <p>This comprehensive guide covers <strong>42 essential cloud design patterns</strong> organized into six key categories, with detailed Azure implementation guidance, code examples, and Well-Architected Framework alignments.</p>

          <div class="callout">
            <strong>üí° Why Use Cloud Design Patterns?</strong>
            <ul>
              <li>‚úÖ <strong>Proven Solutions:</strong> Battle-tested approaches from real-world cloud deployments</li>
              <li>‚úÖ <strong>Faster Development:</strong> Accelerate architecture decisions with established patterns</li>
              <li>‚úÖ <strong>Better Quality:</strong> Improve reliability, security, and performance from the start</li>
              <li>‚úÖ <strong>Common Language:</strong> Enable clear communication across teams and organizations</li>
              <li>‚úÖ <strong>Azure-Optimized:</strong> Leverage Azure services for optimal implementation</li>
            </ul>
          </div>

          <h2>Pattern Categories</h2>
          
          <h3>üìä Data Management (6 patterns)</h3>
          <p>Patterns for managing data storage, access, consistency, and query performance in distributed cloud systems.</p>
          <ul>
            <li><strong>Cache-Aside</strong> - Load data on demand into cache from data store</li>
            <li><strong>CQRS</strong> - Segregate read and write operations using different models</li>
            <li><strong>Event Sourcing</strong> - Use append-only store to record full series of events</li>
            <li><strong>Index Table</strong> - Create indexes over fields frequently queried</li>
            <li><strong>Materialized View</strong> - Pre-populate views over data in multiple stores</li>
            <li><strong>Sharding</strong> - Divide data store into horizontal partitions (shards)</li>
          </ul>

          <h3>üèóÔ∏è Design & Implementation (10 patterns)</h3>
          <p>Patterns for structuring cloud applications, managing dependencies, and integrating components.</p>
          <ul>
            <li><strong>Ambassador</strong> - Create helper services that send network requests on behalf of consumer</li>
            <li><strong>Anti-Corruption Layer</strong> - Implement fa√ßade between modern and legacy systems</li>
            <li><strong>Backends for Frontends (BFF)</strong> - Create separate backend services per frontend type</li>
            <li><strong>Compute Resource Consolidation</strong> - Consolidate multiple tasks into single compute unit</li>
            <li><strong>External Configuration Store</strong> - Move configuration from deployment package to centralized location</li>
            <li><strong>Gateway Aggregation</strong> - Aggregate multiple individual requests into single request</li>
            <li><strong>Gateway Offloading</strong> - Offload shared functionality to gateway proxy</li>
            <li><strong>Gateway Routing</strong> - Route requests to multiple services using single endpoint</li>
            <li><strong>Sidecar</strong> - Deploy application components in separate process/container</li>
            <li><strong>Strangler Fig</strong> - Incrementally migrate legacy system by replacing specific functionality</li>
          </ul>

          <h3>üì¨ Messaging (10 patterns)</h3>
          <p>Patterns for asynchronous communication, event processing, and message-based integration.</p>
          <ul>
            <li><strong>Asynchronous Request-Reply</strong> - Decouple backend processing from frontend using async messaging</li>
            <li><strong>Claim Check</strong> - Split large message into claim check and payload</li>
            <li><strong>Choreography</strong> - Coordinate services through events without central orchestrator</li>
            <li><strong>Competing Consumers</strong> - Enable multiple concurrent consumers to process messages</li>
            <li><strong>Messaging Bridge</strong> - Intermediate component that translates between messaging protocols</li>
            <li><strong>Pipes and Filters</strong> - Decompose complex processing into reusable independent components</li>
            <li><strong>Priority Queue</strong> - Prioritize requests sent to services</li>
            <li><strong>Publisher/Subscriber</strong> - Enable application to announce events to multiple consumers</li>
            <li><strong>Queue-Based Load Leveling</strong> - Use queue as buffer between task and service</li>
            <li><strong>Sequential Convoy</strong> - Process set of related messages in defined order</li>
          </ul>

          <h3>üõ°Ô∏è Reliability & Resiliency (8 patterns)</h3>
          <p>Patterns for building fault-tolerant, self-healing applications that gracefully handle failures.</p>
          <ul>
            <li><strong>Bulkhead</strong> - Isolate elements into pools to prevent cascading failures</li>
            <li><strong>Circuit Breaker</strong> - Prevent application from invoking failing service</li>
            <li><strong>Compensating Transaction</strong> - Undo work performed by series of steps</li>
            <li><strong>Health Endpoint Monitoring</strong> - Implement functional checks accessible through exposed endpoints</li>
            <li><strong>Leader Election</strong> - Coordinate actions by electing one instance as leader</li>
            <li><strong>Retry</strong> - Handle transient failures by transparently retrying failed operations</li>
            <li><strong>Saga</strong> - Manage distributed transactions using sequence of local transactions</li>
            <li><strong>Scheduler Agent Supervisor</strong> - Coordinate set of actions across distributed services</li>
          </ul>

          <h3>‚ö° Performance & Scalability (4 patterns)</h3>
          <p>Patterns for optimizing performance, managing load, and enabling horizontal scale.</p>
          <ul>
            <li><strong>Deployment Stamps</strong> - Deploy multiple independent copies (stamps) of application components</li>
            <li><strong>Geode</strong> - Deploy backend services into satellite deployments around the globe</li>
            <li><strong>Rate Limiting</strong> - Control resource consumption by limiting operations over time period</li>
            <li><strong>Static Content Hosting</strong> - Deploy static content to cloud-based storage service</li>
          </ul>

          <h3>üîê Security (3 patterns)</h3>
          <p>Patterns for authentication, authorization, access control, and security validation.</p>
          <ul>
            <li><strong>Federated Identity</strong> - Delegate authentication to external identity provider</li>
            <li><strong>Quarantine</strong> - Validate external software artifacts before use</li>
            <li><strong>Valet Key</strong> - Use token for restricted direct access to specific resource</li>
          </ul>

          <h2>How to Use This Guide</h2>
          
          <div class="mermaid">
graph TB
    Start[Start Here] --> Problem{Know the<br/>Problem?}
    Problem -->|Yes| Category[Browse by<br/>Category]
    Problem -->|No| Explore[Explore<br/>All Patterns]
    
    Category --> Select[Select Pattern]
    Explore --> Select
    
    Select --> Read[Read Pattern<br/>Documentation]
    Read --> Understand[Understand<br/>Context & Solution]
    Understand --> Check{Suitable for<br/>Your Case?}
    
    Check -->|Yes| Azure[Review Azure<br/>Implementation]
    Check -->|No| Alternative[Check Related<br/>Patterns]
    
    Azure --> Code[Study Code<br/>Examples]
    Code --> Implement[Implement in<br/>Your Workload]
    Implement --> Validate[Validate Against<br/>Well-Architected]
    
    Alternative --> Select
    
    style Start fill:#10b981,stroke:#059669,stroke-width:3px,color:#fff
    style Implement fill:#3b82f6,stroke:#2563eb,stroke-width:3px,color:#fff
    style Validate fill:#8b5cf6,stroke:#7c3aed,stroke-width:3px,color:#fff
          </div>

          <h3>Pattern Structure</h3>
          <p>Each pattern in this guide follows a consistent structure:</p>
          <ul>
            <li><strong>Context & Problem:</strong> The scenario and challenge the pattern addresses</li>
            <li><strong>Solution:</strong> The approach and implementation strategy with diagrams</li>
            <li><strong>Benefits:</strong> Advantages of using the pattern</li>
            <li><strong>Issues & Considerations:</strong> Trade-offs and important factors to consider</li>
            <li><strong>When to Use:</strong> Appropriate and inappropriate scenarios</li>
            <li><strong>Well-Architected Framework:</strong> Alignment with Azure reliability, security, cost, performance, and operational excellence pillars</li>
            <li><strong>Azure Implementation:</strong> Specific Azure services and approaches</li>
            <li><strong>Example Code:</strong> Practical implementation samples</li>
            <li><strong>Related Patterns:</strong> Complementary or alternative patterns</li>
          </ul>

          <h2>Azure Well-Architected Framework</h2>
          <p>All patterns in this guide are aligned with the <strong>Azure Well-Architected Framework</strong>, which provides guidance across five pillars:</p>
          
          <div class="callout">
            <ul>
              <li>üõ°Ô∏è <strong>Reliability (RE):</strong> Ensure application can recover from failures and continue functioning</li>
              <li>üîê <strong>Security (SE):</strong> Protect applications and data from threats</li>
              <li>üí∞ <strong>Cost Optimization (CO):</strong> Manage costs to maximize value delivered</li>
              <li>‚ö° <strong>Performance Efficiency (PE):</strong> Efficiently meet system demands through scaling and optimization</li>
              <li>üîß <strong>Operational Excellence (OE):</strong> Support development and running workloads effectively</li>
            </ul>
          </div>

          <h2>Getting Started</h2>
          
          <h3>For Architects</h3>
          <p>Start by exploring patterns in the <strong>Design & Implementation</strong> category to understand structural approaches. Then review <strong>Reliability & Resiliency</strong> patterns to ensure fault tolerance, and <strong>Security</strong> patterns for access control strategies.</p>

          <h3>For Developers</h3>
          <p>Focus on the <strong>Azure Implementation</strong> and <strong>Example Code</strong> sections within each pattern. The code samples use Azure SDKs, Bicep templates, and Azure services to demonstrate practical implementation.</p>

          <h3>For Operations Teams</h3>
          <p>Pay special attention to <strong>Reliability & Resiliency</strong> patterns for monitoring and fault handling, <strong>Performance & Scalability</strong> patterns for managing load, and the <strong>Well-Architected Framework</strong> alignments for operational best practices.</p>

          <h2>Azure Services Used</h2>
          <p>Patterns in this guide leverage the following Azure services:</p>
          <ul>
            <li><strong>Compute:</strong> Azure Functions, App Service, Container Apps, AKS</li>
            <li><strong>Data:</strong> Azure Cosmos DB, Azure SQL Database, Azure Table Storage, Azure Cache for Redis</li>
            <li><strong>Messaging:</strong> Azure Service Bus, Event Hubs, Event Grid, Storage Queues</li>
            <li><strong>Networking:</strong> Azure Front Door, Application Gateway, API Management, Traffic Manager</li>
            <li><strong>Security:</strong> Microsoft Entra ID, Key Vault, Managed Identity</li>
            <li><strong>DevOps:</strong> Azure Pipelines, GitHub Actions, Bicep, ARM Templates</li>
            <li><strong>Monitoring:</strong> Azure Monitor, Application Insights, Log Analytics</li>
          </ul>

          <h2>Next Steps</h2>
          <p>Ready to explore? Use the navigation menu to browse patterns by category, or use the Previous/Next buttons to read through all 42 patterns sequentially.</p>
          
          <div class="callout">
            <strong>üí° Pro Tip:</strong> Bookmark patterns you frequently reference, and consider combining multiple patterns to solve complex architectural challenges. Most real-world solutions use several patterns working together.
          </div>
        </section>

        <!-- Architecture Styles Introduction -->
        <section id="arch-styles-intro" role="article">
          <h1>üèõÔ∏è Architecture Styles</h1>
          <span class="badge">architecture</span>
          <span class="badge">patterns</span>
          <span class="badge">design</span>

          <h2>What are Architecture Styles?</h2>
          <p>An <strong>architecture style</strong> is a family of architectures that share specific characteristics. Architecture styles place constraints on the design, including the set of elements that can appear and the allowed relationships between those elements. These constraints guide the "shape" of an architecture and, when properly applied, enable certain desirable properties to emerge.</p>

          <p>Architecture styles don't require the use of particular technologies, but some technologies are better suited for certain architectures. For example, containers are well-suited for microservices, while N-tier works well with traditional VMs and load balancers.</p>

          <div class="callout">
            <strong>üí° Key Insight:</strong> The choice of architecture style should be made early with input from informed stakeholders. Changing architectural direction later can be costly, so it's often worthwhile to invest more effort upfront to support long-term efficiency and reduce risks.
          </div>

          <h2>Choosing an Architecture Style</h2>
          <p>When selecting an architecture style, consider these factors:</p>
          <ul>
            <li><strong>Domain complexity</strong> - Simple domains may need simpler architectures; complex domains benefit from more sophisticated patterns</li>
            <li><strong>Update frequency</strong> - Frequent updates favor microservices or event-driven; infrequent updates work with N-tier</li>
            <li><strong>Team maturity</strong> - Microservices require mature DevOps practices; simpler styles work for less experienced teams</li>
            <li><strong>Scalability requirements</strong> - Consider both vertical and horizontal scaling needs</li>
            <li><strong>Data characteristics</strong> - Volume, velocity, and variety of data influence the choice</li>
            <li><strong>Cost constraints</strong> - Some architectures have higher operational costs than others</li>
          </ul>

          <h2>Architecture Styles Comparison</h2>
          <div style="overflow-x: auto;">
            <table class="table table-bordered">
              <thead>
                <tr>
                  <th>Architecture Style</th>
                  <th>Dependency Management</th>
                  <th>Best For Domain Type</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><strong>N-tier</strong></td>
                  <td>Horizontal tiers divided by subnet</td>
                  <td>Traditional business domain. Frequency of updates is low.</td>
                </tr>
                <tr>
                  <td><strong>Web-Queue-Worker</strong></td>
                  <td>Front-end and back-end jobs, decoupled by asynchronous messaging</td>
                  <td>Relatively simple domain with some resource-intensive tasks.</td>
                </tr>
                <tr>
                  <td><strong>Microservices</strong></td>
                  <td>Vertically (functionally) decomposed services that call each other through APIs</td>
                  <td>Complicated domain. Frequent updates.</td>
                </tr>
                <tr>
                  <td><strong>Event-driven</strong></td>
                  <td>Producer or consumer. Independent view for each subsystem.</td>
                  <td>Internet of Things (IoT) and real-time systems.</td>
                </tr>
                <tr>
                  <td><strong>Big Data</strong></td>
                  <td>Divide a huge dataset into small chunks. Parallel processing on local datasets.</td>
                  <td>Batch and real-time data analysis. Predictive analysis using machine learning.</td>
                </tr>
                <tr>
                  <td><strong>Big Compute</strong></td>
                  <td>Data allocation to thousands of cores</td>
                  <td>Compute intensive domains such as simulation.</td>
                </tr>
              </tbody>
            </table>
          </div>

          <h2>Common Challenges</h2>
          <p>Consider these challenges when selecting an architecture style:</p>
          <ul>
            <li><strong>Complexity</strong> - Architecture must match domain complexity; too simple creates "big ball of mud", too complex adds unnecessary overhead</li>
            <li><strong>Asynchronous messaging</strong> - Improves scalability but introduces eventual consistency and duplicate message handling</li>
            <li><strong>Interservice communication</strong> - Decomposed services increase network overhead and latency</li>
            <li><strong>Manageability</strong> - Consider monitoring, deployment, and operational health requirements</li>
          </ul>

          <h2>Explore Architecture Styles</h2>
          <p>Use the navigation menu to explore each architecture style in detail. Each style includes:</p>
          <ul>
            <li>Detailed description and logical diagrams</li>
            <li>When to use and when to avoid</li>
            <li>Benefits and challenges</li>
            <li>Azure service recommendations</li>
            <li>Best practices and considerations</li>
          </ul>
        </section>

        <!-- N-tier Architecture Style -->
        <section id="n-tier" role="article">
          <h1>üè¢ N-tier Architecture</h1>
          <div class="badges">
            <span class="badge badge-architecture">Architecture Style</span>
            <span class="badge badge-traditional">Traditional</span>
          </div>

          <h2>Overview</h2>
          <p>N-tier is a traditional architecture for enterprise applications that divides an application into <strong>logical layers</strong> and <strong>physical tiers</strong>. Each layer has a specific responsibility, and layers manage dependencies by only calling into layers under them. Typical layers include presentation, business logic, and data access.</p>

          <div class="mermaid">
graph TB
    Client[Client Applications<br/>Web/Mobile]
    WAF[Web Application<br/>Firewall]
    
    subgraph "Presentation Tier"
    Web[Web Tier<br/>App Service]
    end
    
    subgraph "Business Logic Tier"
    Mid1[Business Logic 1<br/>Sync Processing]
    Mid2[Business Logic 2<br/>Async Processing]
    Queue[Message Queue]
    end
    
    subgraph "Data Tier"
    Cache[(Cache<br/>Redis)]
    DB[(Database<br/>SQL/NoSQL)]
    end
    
    Client -->|HTTPS| WAF
    WAF --> Web
    Web --> Mid1
    Web -->|Async| Queue
    Queue --> Mid2
    Mid1 --> Cache
    Mid2 --> Cache
    Cache --> DB
    
    style Web fill:#3b82f6,stroke:#2563eb,stroke-width:2px,color:#fff
    style Mid1 fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff
    style Mid2 fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff
    style DB fill:#8b5cf6,stroke:#7c3aed,stroke-width:2px,color:#fff
          </div>

          <h3>Key Characteristics</h3>
          <ul>
            <li><strong>Horizontal layering</strong> - Each tier is a separate physical deployment</li>
            <li><strong>Dependency management</strong> - Layers only call downward, never upward</li>
            <li><strong>Subnet isolation</strong> - Tiers divided by network subnets for security</li>
            <li><strong>Centralized data</strong> - Typically single database shared across tiers</li>
            <li><strong>Synchronous calls</strong> - Request-response pattern between tiers</li>
          </ul>

          <h3>When to Use</h3>
          <p><strong>‚úÖ Use N-tier when:</strong></p>
          <ul>
            <li>Migrating existing applications that already use layered architecture</li>
            <li>Traditional business domain with <strong>low update frequency</strong></li>
            <li>Team familiar with traditional enterprise patterns</li>
            <li>Need to support mixed on-premises and cloud environments</li>
            <li>Regulatory requirements dictate strict tier separation</li>
          </ul>

          <p><strong>‚ùå Avoid when:</strong></p>
          <ul>
            <li>Need frequent updates and rapid deployment cycles</li>
            <li>Domain is complex with many microdomains</li>
            <li>Require independent scaling of components</li>
          </ul>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Familiarity</strong> - Well-understood by most development teams</li>
            <li>‚úÖ <strong>Migration-friendly</strong> - Easy to lift-and-shift existing apps</li>
            <li>‚úÖ <strong>Clear separation</strong> - Defined responsibilities per layer</li>
            <li>‚úÖ <strong>Mixed environments</strong> - Supports hybrid cloud scenarios</li>
          </ul>

          <h3>Challenges</h3>
          <ul>
            <li>‚ö†Ô∏è <strong>Limited agility</strong> - Changes often affect multiple layers</li>
            <li>‚ö†Ô∏è <strong>Horizontal dependencies</strong> - Makes it hard to isolate features</li>
            <li>‚ö†Ô∏è <strong>Tight coupling</strong> - Layers can become interdependent</li>
            <li>‚ö†Ô∏è <strong>Monolithic tendency</strong> - Middle tier can become large and complex</li>
          </ul>

          <h3>Azure Services</h3>
          <ul>
            <li><strong>Web Tier:</strong> Azure App Service, Azure Front Door, Application Gateway</li>
            <li><strong>Business Logic:</strong> Azure App Service, Azure Functions, Azure Container Apps</li>
            <li><strong>Data Tier:</strong> Azure SQL Database, Azure Cosmos DB, Azure Cache for Redis</li>
            <li><strong>Messaging:</strong> Azure Service Bus, Azure Storage Queues</li>
            <li><strong>Security:</strong> Azure WAF, Network Security Groups, Azure Bastion</li>
          </ul>

          <h3>Best Practices</h3>
          <ul>
            <li>Use <strong>autoscaling</strong> in each tier to handle variable load</li>
            <li>Implement <strong>caching</strong> to reduce database load</li>
            <li>Use <strong>asynchronous messaging</strong> for long-running operations</li>
            <li>Apply <strong>network security groups</strong> to enforce tier isolation</li>
            <li>Consider <strong>read replicas</strong> for database scalability</li>
          </ul>
        </section>

        <!-- Web-Queue-Worker Architecture Style -->
        <section id="web-queue-worker" role="article">
          <h1>‚öôÔ∏è Web-Queue-Worker Architecture</h1>
          <div class="badges">
            <span class="badge badge-architecture">Architecture Style</span>
            <span class="badge badge-messaging">Async Processing</span>
          </div>

          <h2>Overview</h2>
          <p>Web-Queue-Worker is an architecture that consists of a <strong>web front end</strong>, a <strong>message queue</strong>, and a <strong>back-end worker</strong>. The web front end handles HTTP requests and user interactions, while the worker performs resource-intensive tasks, long-running workflows, or batch operations. Communication between the front end and worker occurs through an asynchronous message queue.</p>

          <div class="mermaid">
graph LR
    Client[Client Apps]
    IdP[Identity<br/>Provider]
    Web[Web Front End<br/>App Service]
    Queue[Message Queue<br/>Service Bus]
    Worker[Worker<br/>Functions/App Service]
    DB[(Database)]
    Cache[(Cache)]
    CDN[CDN]
    Storage[Remote<br/>Services]
    
    Client -->|Authenticate| IdP
    IdP --> Client
    Client -->|HTTPS| Web
    Web -->|Direct Call| Storage
    Web -->|Read/Write| DB
    Web -->|Enqueue Work| Queue
    Queue -->|Dequeue| Worker
    Worker -->|Process| DB
    Web -.->|Cache| Cache
    Worker -.->|Cache| Cache
    CDN -->|Static Content| Client
    
    style Web fill:#3b82f6,stroke:#2563eb,stroke-width:3px,color:#fff
    style Queue fill:#f59e0b,stroke:#d97706,stroke-width:3px,color:#fff
    style Worker fill:#10b981,stroke:#059669,stroke-width:3px,color:#fff
          </div>

          <h3>Key Characteristics</h3>
          <ul>
            <li><strong>Decoupled components</strong> - Web and worker communicate via queue</li>
            <li><strong>Asynchronous processing</strong> - Long-running tasks don't block user requests</li>
            <li><strong>Independent scaling</strong> - Scale web and worker separately</li>
            <li><strong>Simple domain</strong> - Works well for relatively straightforward business logic</li>
          </ul>

          <h3>When to Use</h3>
          <p><strong>‚úÖ Use Web-Queue-Worker when:</strong></p>
          <ul>
            <li>Have <strong>relatively simple domain</strong> with some resource-intensive tasks</li>
            <li>Need to process background jobs without blocking user requests</li>
            <li>Want easy deployment with managed Azure services</li>
            <li>Need independent scaling of front-end and back-end</li>
          </ul>

          <p><strong>‚ùå Avoid when:</strong></p>
          <ul>
            <li>Domain is complex with multiple sub-domains (use Microservices)</li>
            <li>Components would become large and monolithic</li>
            <li>Need real-time processing (consider Event-driven)</li>
          </ul>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Simple to understand</strong> - Straightforward architecture</li>
            <li>‚úÖ <strong>Easy to deploy</strong> - Well-supported by Azure PaaS services</li>
            <li>‚úÖ <strong>Responsive UI</strong> - Background processing keeps UI fast</li>
            <li>‚úÖ <strong>Independent scaling</strong> - Scale components based on demand</li>
          </ul>

          <h3>Challenges</h3>
          <ul>
            <li>‚ö†Ô∏è <strong>Can become monolithic</strong> - Without careful design, web and worker grow large</li>
            <li>‚ö†Ô∏è <strong>Shared database</strong> - Both components typically share same database</li>
            <li>‚ö†Ô∏è <strong>Limited complexity</strong> - Not suitable for complex domains</li>
          </ul>

          <h3>Azure Services</h3>
          <ul>
            <li><strong>Web Front End:</strong> Azure App Service, Azure Static Web Apps, Azure Front Door</li>
            <li><strong>Message Queue:</strong> Azure Service Bus, Azure Storage Queues, Azure Event Hubs</li>
            <li><strong>Worker:</strong> Azure Functions, Azure App Service (WebJobs), Azure Container Apps</li>
            <li><strong>Data:</strong> Azure SQL Database, Azure Cosmos DB, Azure Storage</li>
            <li><strong>CDN:</strong> Azure CDN, Azure Front Door</li>
          </ul>
        </section>

        <!-- Microservices Architecture Style -->
        <section id="microservices-arch" role="article">
          <h1>üî∑ Microservices Architecture</h1>
          <div class="badges">
            <span class="badge badge-architecture">Architecture Style</span>
            <span class="badge badge-modern">Modern</span>
          </div>

          <h2>Overview</h2>
          <p>The Microservices architecture decomposes applications into a collection of <strong>small, autonomous services</strong>. Each service implements a single business capability within a bounded context and is self-contained with its own data storage. Services communicate through well-defined APIs and can be developed, deployed, and scaled independently.</p>

          <div class="mermaid">
graph TB
    Client[Client Apps]
    ExtSys[External Systems]
    
    subgraph "API Layer"
    Gateway[API Gateway<br/>API Management]
    end
    
    subgraph "Microservices"
    Svc1[Domain Service 1<br/>Orders]
    Svc2[Domain Service 2<br/>Inventory]
    Svc3[Domain Service 3<br/>Shipping]
    Comp[Composition Service]
    end
    
    subgraph "Data Layer"
    DB1[(SQL<br/>Database)]
    DB2[(NoSQL<br/>Database)]
    DB3[(Document<br/>Store)]
    end
    
    subgraph "Infrastructure"
    Msg[Message Bus<br/>Event-Driven]
    Obs[Observability<br/>Monitoring/Logging]
    Orch[Orchestration<br/>AKS/Container Apps]
    end
    
    Client --> Gateway
    ExtSys --> Gateway
    Gateway --> Svc1
    Gateway --> Svc2
    Gateway --> Svc3
    Gateway --> Comp
    
    Comp -.->|Orchestrate| Svc1
    Comp -.->|Orchestrate| Svc2
    
    Svc1 --> DB1
    Svc2 --> DB2
    Svc3 --> DB3
    
    Svc1 -.->|Async Events| Msg
    Svc2 -.->|Async Events| Msg
    Svc3 -.->|Async Events| Msg
    Msg -.-> Svc1
    Msg -.-> Svc2
    Msg -.-> Svc3
    
    style Gateway fill:#3b82f6,stroke:#2563eb,stroke-width:3px,color:#fff
    style Svc1 fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff
    style Svc2 fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff
    style Svc3 fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff
    style Msg fill:#f59e0b,stroke:#d97706,stroke-width:2px,color:#fff
          </div>

          <h3>Key Characteristics</h3>
          <ul>
            <li><strong>Single responsibility</strong> - Each service implements one business capability</li>
            <li><strong>Data autonomy</strong> - Each service owns its data storage</li>
            <li><strong>Independent deployment</strong> - Services can be deployed without coordinating with others</li>
            <li><strong>Polyglot persistence</strong> - Different services can use different database technologies</li>
            <li><strong>API-based communication</strong> - Services interact through well-defined APIs</li>
          </ul>

          <h3>When to Use</h3>
          <p><strong>‚úÖ Use Microservices when:</strong></p>
          <ul>
            <li>Have <strong>complicated domain</strong> requiring frequent updates</li>
            <li>Need teams to work autonomously on different services</li>
            <li>Have mature DevOps practices and automation</li>
            <li>Require high release velocity</li>
            <li>Need to scale different parts independently</li>
          </ul>

          <p><strong>‚ùå Avoid when:</strong></p>
          <ul>
            <li>Domain is simple (use Web-Queue-Worker or N-tier)</li>
            <li>Team lacks DevOps maturity</li>
            <li>Don't have need for independent deployment</li>
            <li>Starting a new product (consider simpler architecture first)</li>
          </ul>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Team autonomy</strong> - Teams can work and deploy independently</li>
            <li>‚úÖ <strong>Technology diversity</strong> - Use best tool for each service</li>
            <li>‚úÖ <strong>Fault isolation</strong> - Failure in one service doesn't bring down others</li>
            <li>‚úÖ <strong>Scalability</strong> - Scale services independently based on demand</li>
            <li>‚úÖ <strong>Frequent updates</strong> - Deploy changes to individual services rapidly</li>
          </ul>

          <h3>Challenges</h3>
          <ul>
            <li>‚ö†Ô∏è <strong>Complexity</strong> - Distributed systems are inherently complex</li>
            <li>‚ö†Ô∏è <strong>Data consistency</strong> - Maintaining consistency across services is challenging</li>
            <li>‚ö†Ô∏è <strong>Service discovery</strong> - Need mechanisms to locate services</li>
            <li>‚ö†Ô∏è <strong>Testing</strong> - End-to-end testing is more difficult</li>
            <li>‚ö†Ô∏è <strong>Operational overhead</strong> - Requires sophisticated monitoring and deployment</li>
          </ul>

          <h3>Azure Services</h3>
          <ul>
            <li><strong>Compute:</strong> Azure Kubernetes Service (AKS), Azure Container Apps, Azure Functions</li>
            <li><strong>API Gateway:</strong> Azure API Management, Azure Front Door</li>
            <li><strong>Messaging:</strong> Azure Service Bus, Azure Event Grid, Azure Event Hubs</li>
            <li><strong>Data:</strong> Azure Cosmos DB, Azure SQL, Azure Cache for Redis</li>
            <li><strong>Observability:</strong> Azure Monitor, Application Insights, Azure Log Analytics</li>
            <li><strong>DevOps:</strong> Azure DevOps, GitHub Actions, Azure Container Registry</li>
          </ul>
        </section>

        <!-- Event-driven Architecture Style -->
        <section id="event-driven-arch" role="article">
          <h1>‚ö° Event-driven Architecture</h1>
          <div class="badges">
            <span class="badge badge-architecture">Architecture Style</span>
            <span class="badge badge-realtime">Real-time</span>
          </div>

          <h2>Overview</h2>
          <p>Event-driven architectures use a <strong>publish-subscribe model</strong> where event producers generate streams of events, and event consumers respond to those events in near real time. Producers and consumers are decoupled from each other, with communication happening through event channels or brokers. This architecture supports both simple event processing and complex event pattern analysis.</p>

          <div class="mermaid">
graph LR
    subgraph "Event Producers"
    P1[Producer 1<br/>IoT Devices]
    P2[Producer 2<br/>Web App]
    P3[Producer 3<br/>Mobile App]
    end
    
    subgraph "Event Ingestion"
    Broker[Event Broker<br/>Event Hubs/Grid]
    end
    
    subgraph "Event Consumers"
    C1[Consumer 1<br/>Analytics]
    C2[Consumer 2<br/>Alerting]
    C3[Consumer 3<br/>Archive]
    C4[Consumer 4<br/>Processing]
    end
    
    P1 -->|Events| Broker
    P2 -->|Events| Broker
    P3 -->|Events| Broker
    
    Broker -->|Subscribe| C1
    Broker -->|Subscribe| C2
    Broker -->|Subscribe| C3
    Broker -->|Subscribe| C4
    
    style Broker fill:#f59e0b,stroke:#d97706,stroke-width:4px,color:#fff
    style P1 fill:#3b82f6,stroke:#2563eb,stroke-width:2px,color:#fff
    style P2 fill:#3b82f6,stroke:#2563eb,stroke-width:2px,color:#fff
    style P3 fill:#3b82f6,stroke:#2563eb,stroke-width:2px,color:#fff
    style C1 fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff
    style C2 fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff
    style C3 fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff
    style C4 fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff
          </div>

          <h3>Key Characteristics</h3>
          <ul>
            <li><strong>Decoupled producers and consumers</strong> - Don't know about each other</li>
            <li><strong>Asynchronous communication</strong> - Non-blocking event processing</li>
            <li><strong>Event persistence</strong> - Events stored by broker for reliability</li>
            <li><strong>Multiple subscribers</strong> - Many consumers can process same event</li>
            <li><strong>Real-time processing</strong> - Low latency event handling</li>
          </ul>

          <h3>When to Use</h3>
          <p><strong>‚úÖ Use Event-driven when:</strong></p>
          <ul>
            <li><strong>IoT and real-time systems</strong> - Need to process high-volume event streams</li>
            <li>Need to integrate multiple subsystems with independent views</li>
            <li>Require real-time processing with minimal latency</li>
            <li>Want to decouple producers from consumers</li>
            <li>Need to process streaming data</li>
          </ul>

          <p><strong>‚ùå Avoid when:</strong></p>
          <ul>
            <li>Require strong consistency across system</li>
            <li>Need simple request-response patterns</li>
            <li>Event ordering is critical and complex</li>
          </ul>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Loose coupling</strong> - Components evolve independently</li>
            <li>‚úÖ <strong>Scalability</strong> - Easy to add new consumers</li>
            <li>‚úÖ <strong>Real-time</strong> - Process events as they occur</li>
            <li>‚úÖ <strong>Fault isolation</strong> - Consumer failures don't affect producers</li>
          </ul>

          <h3>Challenges</h3>
          <ul>
            <li>‚ö†Ô∏è <strong>Guaranteed delivery</strong> - Ensuring events aren't lost</li>
            <li>‚ö†Ô∏è <strong>Event ordering</strong> - Maintaining order across distributed systems</li>
            <li>‚ö†Ô∏è <strong>Eventual consistency</strong> - System state may be temporarily inconsistent</li>
            <li>‚ö†Ô∏è <strong>Debugging</strong> - Tracking event flows is complex</li>
          </ul>

          <h3>Azure Services</h3>
          <ul>
            <li><strong>Event Ingestion:</strong> Azure Event Hubs, Azure Event Grid, Azure Service Bus</li>
            <li><strong>Stream Processing:</strong> Azure Stream Analytics, Azure Functions</li>
            <li><strong>Storage:</strong> Azure Cosmos DB (Change Feed), Azure Data Lake</li>
            <li><strong>Analytics:</strong> Azure Synapse Analytics, Azure Databricks</li>
          </ul>
        </section>

        <!-- Big Data Architecture Style -->
        <section id="big-data-arch" role="article">
          <h1>üìä Big Data Architecture</h1>
          <div class="badges">
            <span class="badge badge-architecture">Architecture Style</span>
            <span class="badge badge-data">Data Intensive</span>
          </div>

          <h2>Overview</h2>
          <p>Big data architectures handle the ingestion, processing, and analysis of data that's <strong>too large or complex</strong> for traditional database systems. These architectures typically include components for data storage (like data lakes), batch processing for historical analysis, stream processing for real-time insights, and analytical data stores for reporting and visualization.</p>

          <div class="mermaid">
graph TB
    subgraph "Data Sources"
    DS1[Structured Data]
    DS2[Semi-Structured]
    DS3[Unstructured]
    DS4[Streaming Data]
    end
    
    subgraph "Batch Pipeline"
    DL[Data Lake<br/>Storage]
    Batch[Batch Processing<br/>Spark/Databricks]
    end
    
    subgraph "Real-time Pipeline"
    Stream[Stream Ingestion<br/>Event Hubs]
    RealTime[Stream Processing<br/>Stream Analytics]
    end
    
    subgraph "Analytics"
    ADS[Analytical Store<br/>Synapse/Cosmos DB]
    Report[Analytics & Reporting<br/>Power BI]
    end
    
    Orch[Orchestration<br/>Data Factory/Synapse]
    
    DS1 --> DL
    DS2 --> DL
    DS3 --> DL
    DS4 --> Stream
    
    DL --> Batch
    Stream --> RealTime
    
    Batch --> ADS
    Batch --> Report
    RealTime --> ADS
    RealTime --> Report
    
    Orch -.->|Coordinate| Batch
    Orch -.->|Coordinate| RealTime
    
    style DL fill:#3b82f6,stroke:#2563eb,stroke-width:2px,color:#fff
    style Batch fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff
    style RealTime fill:#f59e0b,stroke:#d97706,stroke-width:2px,color:#fff
    style ADS fill:#8b5cf6,stroke:#7c3aed,stroke-width:2px,color:#fff
          </div>

          <h3>Key Characteristics</h3>
          <ul>
            <li><strong>Massive datasets</strong> - Handle petabytes of data</li>
            <li><strong>Parallel processing</strong> - Divide data into chunks, process in parallel</li>
            <li><strong>Dual pipelines</strong> - Batch for historical, stream for real-time</li>
            <li><strong>Data lake storage</strong> - Store raw data in native format</li>
            <li><strong>Machine learning</strong> - Support predictive analytics</li>
          </ul>

          <h3>When to Use</h3>
          <p><strong>‚úÖ Use Big Data when:</strong></p>
          <ul>
            <li>Need <strong>batch and real-time data analysis</strong></li>
            <li>Have massive datasets too large for traditional databases</li>
            <li>Require predictive analysis using machine learning</li>
            <li>Need to process diverse data types (structured, semi-structured, unstructured)</li>
          </ul>

          <p><strong>‚ùå Avoid when:</strong></p>
          <ul>
            <li>Data volumes are modest (traditional databases work fine)</li>
            <li>Don't need analytics or machine learning</li>
            <li>Complexity outweighs benefits</li>
          </ul>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Scalability</strong> - Handle petabyte-scale data</li>
            <li>‚úÖ <strong>Flexibility</strong> - Process any data type</li>
            <li>‚úÖ <strong>Cost-effective storage</strong> - Data lakes are cheaper than traditional systems</li>
            <li>‚úÖ <strong>Advanced analytics</strong> - Enable ML and AI scenarios</li>
          </ul>

          <h3>Challenges</h3>
          <ul>
            <li>‚ö†Ô∏è <strong>Complexity</strong> - Many moving parts to coordinate</li>
            <li>‚ö†Ô∏è <strong>Skills required</strong> - Need data engineering expertise</li>
            <li>‚ö†Ô∏è <strong>Data quality</strong> - Ensuring data accuracy and cleanliness</li>
          </ul>

          <h3>Azure Services</h3>
          <ul>
            <li><strong>Storage:</strong> Azure Data Lake Storage Gen2, Azure Blob Storage</li>
            <li><strong>Batch Processing:</strong> Azure Synapse Analytics, Azure Databricks, HDInsight</li>
            <li><strong>Stream Processing:</strong> Azure Stream Analytics, Azure Event Hubs</li>
            <li><strong>Orchestration:</strong> Azure Data Factory, Azure Synapse Pipelines</li>
            <li><strong>Analytics:</strong> Azure Synapse Analytics, Power BI</li>
            <li><strong>ML:</strong> Azure Machine Learning, Azure Databricks</li>
          </ul>
        </section>

        <!-- Big Compute Architecture Style -->
        <section id="big-compute-arch" role="article">
          <h1>üíª Big Compute Architecture</h1>
          <div class="badges">
            <span class="badge badge-architecture">Architecture Style</span>
            <span class="badge badge-hpc">High Performance</span>
          </div>

          <h2>Overview</h2>
          <p>Big compute architectures support <strong>large-scale workloads</strong> that require hundreds or thousands of cores for computationally intensive operations. The work can be split into discrete tasks that run across many cores simultaneously, with each task taking input, processing it, and producing output. Tasks can be either independent (embarrassingly parallel) or tightly coupled requiring high-speed communication.</p>

          <div class="mermaid">
graph TB
    Client[Client Applications]
    
    subgraph "Job Management"
    Queue[Job Queue]
    Scheduler[Scheduler/<br/>Coordinator]
    end
    
    subgraph "Compute Resources"
    direction LR
    subgraph "Parallel Tasks"
    PT1[Task 1]
    PT2[Task 2]
    PT3[Task 3]
    PTN[Task N...]
    end
    
    subgraph "Tightly Coupled"
    TC1[Task A]
    TC2[Task B]
    TC3[Task C]
    end
    end
    
    Client -->|Submit Job| Queue
    Queue --> Scheduler
    Scheduler -->|Route| PT1
    Scheduler -->|Route| PT2
    Scheduler -->|Route| PT3
    Scheduler -->|Route| PTN
    Scheduler -->|Route| TC1
    Scheduler -->|Route| TC2
    Scheduler -->|Route| TC3
    
    TC1 <-.->|RDMA/InfiniBand| TC2
    TC2 <-.->|High-speed Network| TC3
    
    style Scheduler fill:#f59e0b,stroke:#d97706,stroke-width:3px,color:#fff
    style PT1 fill:#3b82f6,stroke:#2563eb,stroke-width:2px,color:#fff
    style PT2 fill:#3b82f6,stroke:#2563eb,stroke-width:2px,color:#fff
    style PT3 fill:#3b82f6,stroke:#2563eb,stroke-width:2px,color:#fff
    style TC1 fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff
    style TC2 fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff
    style TC3 fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff
          </div>

          <h3>Key Characteristics</h3>
          <ul>
            <li><strong>Massive parallelism</strong> - Thousands of cores working simultaneously</li>
            <li><strong>Task decomposition</strong> - Break work into independent units</li>
            <li><strong>Two workload types</strong> - Embarrassingly parallel or tightly coupled</li>
            <li><strong>High-speed networking</strong> - RDMA/InfiniBand for tightly coupled tasks</li>
            <li><strong>Burst capacity</strong> - Scale up when needed, down when idle</li>
          </ul>

          <h3>When to Use</h3>
          <p><strong>‚úÖ Use Big Compute when:</strong></p>
          <ul>
            <li>Have <strong>compute-intensive domains</strong> like simulation, modeling, rendering</li>
            <li>Need to run scientific computing workloads</li>
            <li>Require financial risk modeling or Monte Carlo simulations</li>
            <li>Need engineering stress analysis or fluid dynamics</li>
            <li>3D rendering or video transcoding at scale</li>
          </ul>

          <p><strong>‚ùå Avoid when:</strong></p>
          <ul>
            <li>Workloads aren't computationally intensive</li>
            <li>Tasks can't be parallelized</li>
            <li>Data transfer overhead exceeds compute benefits</li>
          </ul>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Massive scale</strong> - Access thousands of cores on-demand</li>
            <li>‚úÖ <strong>Cost efficiency</strong> - Pay only when running jobs</li>
            <li>‚úÖ <strong>Fast results</strong> - Parallel processing dramatically reduces time</li>
            <li>‚úÖ <strong>Elastic capacity</strong> - Burst to cloud when on-premises capacity is full</li>
          </ul>

          <h3>Challenges</h3>
          <ul>
            <li>‚ö†Ô∏è <strong>Task decomposition</strong> - Breaking work into parallel units requires expertise</li>
            <li>‚ö†Ô∏è <strong>Data movement</strong> - Moving large datasets can be time-consuming</li>
            <li>‚ö†Ô∏è <strong>Cost management</strong> - Large core counts can be expensive if not managed</li>
          </ul>

          <h3>Azure Services</h3>
          <ul>
            <li><strong>Managed Service:</strong> Azure Batch (job scheduling and compute management)</li>
            <li><strong>HPC Cluster:</strong> HPC Pack, Azure CycleCloud</li>
            <li><strong>Compute:</strong> HB-series VMs (HPC), HC-series (compute-optimized)</li>
            <li><strong>Networking:</strong> InfiniBand-enabled VMs for tightly coupled workloads</li>
            <li><strong>Storage:</strong> Azure NetApp Files, Lustre file system</li>
          </ul>
        </section>

        <!-- Ambassador Pattern -->
        <section id="ambassador" role="article">
          <h1>üîå Ambassador Pattern</h1>
          <span class="badge">design</span>
          <span class="badge">proxy</span>
          <span class="badge">connectivity</span>
          
          <h2>Context and Problem</h2>
          <p>Resilient cloud-based applications require features such as <strong>circuit breaking, routing, metering and monitoring</strong>, and the ability to make network-related configuration updates. It might be difficult or impossible to update legacy applications or existing code libraries to add these features.</p>
          
          <p>Network calls might also require substantial configuration for connection, authentication, and authorization. If these calls are used across multiple applications, built using multiple languages and frameworks, the calls must be configured for each instance.</p>

          <h2>Solution</h2>
          <p>Put client frameworks and libraries into an <strong>external process that acts as a proxy</strong> between your application and external services. Deploy the proxy on the same host environment as your application to allow control over routing, resiliency, security features, and to avoid any host-related access restrictions.</p>
          
          <div class="callout">
            <strong>üí° Key Insight:</strong> The ambassador service can be deployed as a <strong>sidecar</strong> to accompany the lifecycle of a consuming application or service. Features offloaded to the ambassador can be managed independently of the application.
          </div>

          <div class="mermaid">
graph LR
    App[Application] -->|Network Request| Ambassador[Ambassador Proxy]
    Ambassador -->|Circuit Breaking<br/>Retry Logic<br/>Monitoring| ExtService[External Service]
    ExtService -->|Response| Ambassador
    Ambassador -->|Response| App
    
    style Ambassador fill:#3b82f6,stroke:#2563eb,stroke-width:3px,color:#fff
    style App fill:#e0f2fe,stroke:#3b82f6,stroke-width:2px
    style ExtService fill:#e0f2fe,stroke:#3b82f6,stroke-width:2px
          </div>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ Standardize and extend instrumentation across applications</li>
            <li>‚úÖ Update and modify ambassador without disturbing application's legacy functionality</li>
            <li>‚úÖ Enable specialized teams to implement security, networking, or authentication features</li>
            <li>‚úÖ Language-agnostic approach to common client connectivity tasks</li>
          </ul>

          <h3>Issues and Considerations</h3>
          <ul>
            <li>‚ö†Ô∏è The proxy adds some latency overhead</li>
            <li>‚ö†Ô∏è Consider the possible impact of including generalized features (e.g., retries might not be safe unless all operations are idempotent)</li>
            <li>‚ö†Ô∏è Consider how to package and deploy the proxy</li>
            <li>‚ö†Ô∏è Consider whether to use a single shared instance or an instance per client</li>
          </ul>

          <h2>When to Use This Pattern</h2>
          <p>Use this pattern when you:</p>
          <ul>
            <li>Need to build a common set of client connectivity features for multiple languages or frameworks</li>
            <li>Need to offload cross-cutting client connectivity concerns to infrastructure developers</li>
            <li>Need to support cloud or cluster connectivity requirements in a legacy application</li>
          </ul>

          <p><strong>Not suitable when:</strong></p>
          <ul>
            <li>‚ùå Network request latency is critical</li>
            <li>‚ùå Client connectivity features are consumed by a single language</li>
            <li>‚ùå Connectivity features can't be generalized and require deeper integration</li>
          </ul>

          <h2>Well-Architected Framework Alignment</h2>
          <ul>
            <li><strong>üõ°Ô∏è Reliability:</strong> Provides an opportunity to add reliability patterns to network communication (retry, buffering)</li>
            <li><strong>üîê Security:</strong> Augments security on network communications (TLS, encryption)</li>
          </ul>
        </section>

        <!-- Anti-Corruption Layer Pattern -->
        <section id="anti-corruption" role="article">
          <h1>üõ°Ô∏è Anti-Corruption Layer Pattern</h1>
          <span class="badge">design</span>
          <span class="badge">legacy</span>
          <span class="badge">integration</span>
          
          <h2>Context and Problem</h2>
          <p>Most applications rely on other systems for some data or functionality. When a legacy application is migrated to a modern system, it might still need existing legacy resources. New features must be able to call the legacy system.</p>
          
          <p>Often these <strong>legacy systems suffer from quality issues</strong> such as convoluted data schemas or obsolete APIs. Maintaining access between new and legacy systems can force the new system to adhere to at least some of the legacy system's APIs or other semantics, which can "corrupt" an otherwise cleanly designed modern application.</p>

          <h2>Solution</h2>
          <p><strong>Isolate the different subsystems by placing an anti-corruption layer between them.</strong> This layer translates communications between the two systems, allowing one system to remain unchanged while the other can avoid compromising its design and technological approach.</p>
          
          <div class="callout">
            <strong>üìñ Pattern Origin:</strong> This pattern was first described by Eric Evans in <em>Domain-Driven Design</em>.
          </div>

          <div class="mermaid">
graph LR
    SubA[Modern<br/>Subsystem A] -->|Uses Model A| ACL[Anti-Corruption<br/>Layer]
    ACL -->|Translation| ACL
    ACL -->|Uses Model B| SubB[Legacy<br/>Subsystem B]
    SubB -->|Response B| ACL
    ACL -->|Translate| ACL
    ACL -->|Response A| SubA
    
    style ACL fill:#10b981,stroke:#059669,stroke-width:3px,color:#fff
    style SubA fill:#dbeafe,stroke:#3b82f6,stroke-width:2px
    style SubB fill:#fef3c7,stroke:#f59e0b,stroke-width:2px
          </div>

          <h3>How It Works</h3>
          <ul>
            <li>Communication between subsystem A and the anti-corruption layer uses the <strong>data model and architecture of subsystem A</strong></li>
            <li>Calls from the anti-corruption layer to subsystem B conform to <strong>that subsystem's data model or methods</strong></li>
            <li>The layer contains all logic necessary to translate between the two systems</li>
            <li>Can be implemented as a component within the application or as an independent service</li>
          </ul>

          <h3>Issues and Considerations</h3>
          <ul>
            <li>‚ö†Ô∏è The anti-corruption layer might add latency to calls between systems</li>
            <li>‚ö†Ô∏è Adds an additional service that must be managed and maintained</li>
            <li>‚ö†Ô∏è Consider how the layer will scale and integrate with monitoring, release, and configuration processes</li>
            <li>‚ö†Ô∏è Make sure transaction and data consistency are maintained and can be monitored</li>
            <li>‚ö†Ô∏è Consider whether the layer needs to handle all communication or just a subset of features</li>
          </ul>

          <h2>When to Use This Pattern</h2>
          <p>Use this pattern when:</p>
          <ul>
            <li>A migration is planned to happen over multiple stages, but integration between new and legacy systems needs to be maintained</li>
            <li>Two or more subsystems have different semantics, but still need to communicate</li>
          </ul>

          <p><strong>Not suitable when:</strong></p>
          <ul>
            <li>‚ùå There are no significant semantic differences between new and legacy systems</li>
          </ul>

          <h2>Well-Architected Framework Alignment</h2>
          <ul>
            <li><strong>‚öôÔ∏è Operational Excellence:</strong> Ensures new component design remains uninfluenced by legacy implementations, reducing technical debt while supporting existing components</li>
          </ul>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#strangler-fig"><strong>Strangler Fig</strong></a> - For gradually migrating legacy systems</li>
            <li>üîó <a href="#messaging-bridge"><strong>Messaging Bridge</strong></a> - For connecting different messaging systems</li>
          </ul>
        </section>

        <!-- Asynchronous Request-Reply Pattern -->
        <section id="async-request-reply" role="article">
          <h1>‚è±Ô∏è Asynchronous Request-Reply Pattern</h1>
          <span class="badge">messaging</span>
          <span class="badge">async</span>
          <span class="badge">communication</span>
          
          <h2>Context and Problem</h2>
          <p>In modern application development, client applications often depend on remote APIs to provide business logic and compose functionality. These API calls typically take place over HTTP(S) and follow REST semantics, with responses expected in <strong>100 ms or less</strong>.</p>
          
          <p>However, in some scenarios, the work done by the backend might be <strong>long-running</strong> (seconds, minutes, or even hours). In that case, it isn't feasible to wait for the work to complete before responding to the request.</p>

          <h2>Solution</h2>
          <p>Use <strong>HTTP polling</strong> to handle long-running operations asynchronously:</p>
          
          <ol>
            <li>The client application makes a synchronous call to the API, triggering a long-running operation on the backend</li>
            <li>The API responds as quickly as possible with <strong>HTTP 202 (Accepted)</strong>, acknowledging the request has been received</li>
            <li>The response holds a <strong>location reference</strong> pointing to an endpoint the client can poll for the result</li>
            <li>The API offloads processing to another component (e.g., a message queue)</li>
            <li>For every successful call to the status endpoint, it returns <strong>HTTP 200</strong> while pending</li>
            <li>Once work is complete, the status endpoint returns completion or redirects to the resource URL</li>
          </ol>

          <div class="callout">
            <strong>üí° Key Insight:</strong> The HTTP 202 response should include <strong>Location</strong> (URL to poll for status) and <strong>Retry-After</strong> (estimate of when processing will complete) headers.
          </div>

          <div class="mermaid">
sequenceDiagram
    participant Client
    participant API
    participant Queue
    participant Worker
    participant Status
    
    Client->>API: POST /api/process
    API->>Queue: Enqueue task
    API-->>Client: 202 Accepted<br/>Location: /status/123
    
    Note over Client: Client polls status endpoint
    
    Client->>Status: GET /status/123
    Status-->>Client: 200 OK (pending)
    
    Queue->>Worker: Process task
    Worker->>Worker: Long operation
    Worker->>Status: Update complete
    
    Client->>Status: GET /status/123
    Status-->>Client: 302 Redirect to result
    
    Client->>API: GET /results/123
    API-->>Client: 200 OK (result data)
          </div>

          <h3>Response Headers</h3>
          <table class="table table-striped">
            <thead>
              <tr>
                <th>Header</th>
                <th>Purpose</th>
                <th>Notes</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>Location</strong></td>
                <td>URL the client should poll for response status</td>
                <td>Can include SAS token if access control needed (Valet Key Pattern)</td>
              </tr>
              <tr>
                <td><strong>Retry-After</strong></td>
                <td>Estimate of when processing will complete</td>
                <td>Prevents clients from overwhelming backend with retries</td>
              </tr>
            </tbody>
          </table>

          <h3>Issues and Considerations</h3>
          <ul>
            <li>‚ö†Ô∏è Not all services have the same semantics for async operations</li>
            <li>‚ö†Ô∏è Upon successful processing, the Location resource should return appropriate HTTP codes (200, 201, or 204)</li>
            <li>‚ö†Ô∏è If an error occurs during processing, persist the error at the Location resource URL</li>
            <li>‚ö†Ô∏è Legacy clients might not support this pattern - consider a fa√ßade or Azure Logic Apps as integration layer</li>
            <li>‚ö†Ô∏è Consider providing a way for clients to cancel long-running requests</li>
          </ul>

          <h2>When to Use This Pattern</h2>
          <p>Use this pattern for:</p>
          <ul>
            <li>Client-side code (browser applications) where call-back endpoints are difficult</li>
            <li>Service calls where only HTTP protocol is available and the return service can't fire callbacks</li>
            <li>Service calls that need integration with legacy architectures that don't support modern callbacks</li>
          </ul>

          <p><strong>Not suitable when:</strong></p>
          <ul>
            <li>‚ùå You can use a service built for asynchronous notifications (e.g., Azure Event Grid)</li>
            <li>‚ùå Responses must stream in real time to the client</li>
            <li>‚ùå You can use server-side persistent network connections (WebSockets, SignalR)</li>
            <li>‚ùå Network design allows you to open ports to receive asynchronous callbacks</li>
          </ul>

          <h2>Well-Architected Framework Alignment</h2>
          <ul>
            <li><strong>‚ö° Performance Efficiency:</strong> Decoupling request and reply phases improves responsiveness and scalability, maximizing concurrency on the server side</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p>Example using Azure Functions:</p>
          <ul>
            <li><strong>AsyncProcessingWorkAcceptor:</strong> Accepts work and returns HTTP 202 with status endpoint</li>
            <li><strong>AsyncProcessingBackgroundWorker:</strong> Picks up queued operations and executes them</li>
            <li><strong>AsyncOperationStatusChecker:</strong> Status endpoint that returns progress or redirects to results</li>
          </ul>
        </section>

        <!-- Backends for Frontends Pattern -->
        <section id="backends-frontends" role="article">
          <h1>üñ•Ô∏è Backends for Frontends (BFF) Pattern</h1>
          <span class="badge">design</span>
          <span class="badge">api</span>
          <span class="badge">bff</span>
          
          <h2>Context and Problem</h2>
          <p>Consider an application initially designed with a desktop web UI and corresponding backend service. As business requirements change, a mobile interface is added. Both interfaces interact with the same backend service, but the <strong>capabilities of a mobile device differ significantly</strong> from a desktop browser in terms of screen size, performance, and display limitations.</p>
          
          <p>A backend service frequently encounters <strong>competing demands from multiple frontend systems</strong>, resulting in frequent updates, potential development bottlenecks, and conflicts in balancing requirements.</p>

          <h2>Solution</h2>
          <p>Introduce a new layer that handles only the requirements specific to the interface. This layer, known as the <strong>backend-for-frontend (BFF) service</strong>, sits between the frontend client and the backend service.</p>
          
          <div class="callout">
            <strong>üí° Key Insight:</strong> Create a BFF service for <strong>each interface</strong> (mobile, web, desktop, etc.). This customizes the client experience without affecting other interfaces.
          </div>

          <div class="mermaid">
graph TB
    Mobile[üì± Mobile Client] -->|Lightweight API| MobileBFF[Mobile BFF]
    Desktop[üñ•Ô∏è Desktop Client] -->|Full-featured API| DesktopBFF[Desktop BFF]
    
    MobileBFF --> AuthService[Auth Service]
    MobileBFF --> UserService[User Service]
    MobileBFF --> Cache[Cache]
    
    DesktopBFF --> AuthService
    DesktopBFF --> UserService
    DesktopBFF --> OrderService[Order Service]
    DesktopBFF --> Analytics[Analytics Service]
    
    style MobileBFF fill:#8b5cf6,stroke:#7c3aed,stroke-width:3px,color:#fff
    style DesktopBFF fill:#3b82f6,stroke:#2563eb,stroke-width:3px,color:#fff
    style Mobile fill:#f3e8ff,stroke:#8b5cf6,stroke-width:2px
    style Desktop fill:#dbeafe,stroke:#3b82f6,stroke-width:2px
          </div>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ Customizes client experience for specific interfaces without affecting others</li>
            <li>‚úÖ Optimizes performance to meet needs of the frontend environment</li>
            <li>‚úÖ Each BFF is smaller and less complex than a shared backend service</li>
            <li>‚úÖ Frontend teams independently manage their own BFF service</li>
            <li>‚úÖ Teams control language selection, release cadence, workload prioritization, and feature integration</li>
          </ul>

          <h3>GraphQL Alternative</h3>
          <p>Many BFF services traditionally relied on REST APIs, but <strong>GraphQL implementations are emerging</strong> as an alternative. GraphQL's querying mechanism allows clients to request the data they need without relying on predefined endpoints, potentially eliminating the need for a separate BFF layer.</p>

          <h3>Problems and Considerations</h3>
          <ul>
            <li>‚ö†Ô∏è Maintaining and deploying more services means increased operational overhead</li>
            <li>‚ö†Ô∏è Increased latency might occur because clients aren't contacting services directly</li>
            <li>‚ö†Ô∏è Code duplication is a probable outcome - evaluate trade-off vs. better-tailored experience</li>
            <li>‚ö†Ô∏è BFF should only handle client-specific logic - cross-cutting features (monitoring, authorization) should be abstracted</li>
            <li>‚ö†Ô∏è Consider how learning and implementing this pattern affects the development team</li>
          </ul>

          <h2>When to Use This Pattern</h2>
          <p>Use this pattern when:</p>
          <ul>
            <li>A shared or general-purpose backend service requires substantial development overhead to maintain</li>
            <li>You want to optimize the backend for requirements of specific client interfaces</li>
            <li>You make customizations to a general-purpose backend to accommodate multiple interfaces</li>
            <li>A programming language is better suited for the backend of a specific UI, but not all UIs</li>
          </ul>

          <p><strong>Not suitable when:</strong></p>
          <ul>
            <li>‚ùå Interfaces make the same or similar requests to the backend</li>
            <li>‚ùå Only one interface interacts with the backend</li>
          </ul>

          <h2>Well-Architected Framework Alignment</h2>
          <ul>
            <li><strong>üõ°Ô∏è Reliability:</strong> Isolating services to specific frontend interfaces contains malfunctions - one client doesn't affect another's availability</li>
            <li><strong>üîê Security:</strong> Service separation allows security and authorization to be customized for each client's specific needs</li>
            <li><strong>‚ö° Performance Efficiency:</strong> Backend separation enables optimizations for specific client constraints and functionality</li>
          </ul>

          <h3>Azure Implementation</h3>
          <ul>
            <li><strong>Microsoft Entra ID:</strong> Provides tailored audience claims for mobile and desktop clients</li>
            <li><strong>API Management:</strong> Serves as proxy, validates JWTs, streams activity logs</li>
            <li><strong>Azure Functions:</strong> Serverless solution for exposing BFF service logic</li>
            <li><strong>Azure Monitor:</strong> Centralized monitoring solution for end-to-end observability</li>
          </ul>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#gateway-aggregation"><strong>Gateway Aggregation</strong></a> - Aggregates multiple backend requests</li>
            <li>üîó <a href="#gateway-offloading"><strong>Gateway Offloading</strong></a> - Offloads cross-cutting concerns</li>
            <li>üîó <a href="#gateway-routing"><strong>Gateway Routing</strong></a> - Routes requests to different backends</li>
          </ul>
        </section>

        <!-- Bulkhead Pattern -->
        <section id="bulkhead" role="article">
          <h1>üö¢ Bulkhead Pattern</h1>
          <span class="badge">reliability</span>
          <span class="badge">isolation</span>
          <span class="badge">fault-tolerance</span>
          
          <h2>Context and Problem</h2>
          <p>A cloud-based application might include multiple services, with each service having one or more consumers. <strong>Excessive load or failure in a service will affect all consumers</strong> of the service.</p>
          
          <p>When a consumer sends a request to a service that is misconfigured or not responding, the resources used by the client's request might not be freed in a timely manner. Eventually the consumer can no longer send requests to other services, causing a <strong>cascading failure effect</strong>.</p>

          <div class="callout">
            <strong>üö¢ Pattern Origin:</strong> Named after the sectioned partitions (bulkheads) of a ship's hull. If the hull is compromised, only the damaged section fills with water, preventing the ship from sinking.
          </div>

          <div class="mermaid">
graph TB
    subgraph Consumer["Consumer Application"]
        Pool1[Connection Pool 1<br/>Service A]
        Pool2[Connection Pool 2<br/>Service B]
        Pool3[Connection Pool 3<br/>Service C]
    end
    
    Pool1 -.->|Isolated| ServiceA[Service A<br/>‚ùå Failed]
    Pool2 -->|Healthy| ServiceB[Service B<br/>‚úÖ Running]
    Pool3 -->|Healthy| ServiceC[Service C<br/>‚úÖ Running]
    
    style Pool1 fill:#fee2e2,stroke:#dc2626,stroke-width:2px
    style Pool2 fill:#dcfce7,stroke:#10b981,stroke-width:2px
    style Pool3 fill:#dcfce7,stroke:#10b981,stroke-width:2px
    style ServiceA fill:#fecaca,stroke:#b91c1c,stroke-width:3px
    style ServiceB fill:#bbf7d0,stroke:#059669,stroke-width:2px
    style ServiceC fill:#bbf7d0,stroke:#059669,stroke-width:2px
          </div>

          <h2>Solution</h2>
          <p><strong>Partition service instances into different groups</strong>, based on consumer load and availability requirements. This design helps to isolate failures and allows you to sustain service functionality for some consumers, even during a failure.</p>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ Isolates consumers and services from cascading failures</li>
            <li>‚úÖ Preserves some functionality in the event of a service failure</li>
            <li>‚úÖ Allows you to deploy services that offer different quality of service for consuming applications</li>
            <li>‚úÖ High-priority consumer pools can be configured to use high-priority services</li>
          </ul>

          <h3>Implementation Strategies</h3>
          <p><strong>Consumer-side partitioning:</strong> Use processes, thread pools, and semaphores. Projects like <code>resilience4j</code> and <code>Polly</code> provide frameworks for creating consumer bulkheads.</p>
          
          <p><strong>Service-side partitioning:</strong> Deploy services into separate virtual machines, containers, or processes. Containers offer a good balance of resource isolation with fairly low overhead.</p>

          <h3>Issues and Considerations</h3>
          <ul>
            <li>‚ö†Ô∏è Define partitions around business and technical requirements</li>
            <li>‚ö†Ô∏è If using tactical DDD to design microservices, partition boundaries should align with bounded contexts</li>
            <li>‚ö†Ô∏è Consider the level of isolation vs. overhead in terms of cost, performance, and manageability</li>
            <li>‚ö†Ô∏è Combine bulkheads with retry, circuit breaker, and throttling patterns for sophisticated fault handling</li>
            <li>‚ö†Ô∏è Services communicating via asynchronous messages can be isolated through different sets of queues</li>
            <li>‚ö†Ô∏è Determine the level of granularity (e.g., distribute tenants across partitions)</li>
            <li>‚ö†Ô∏è Monitor each partition's performance and SLA</li>
          </ul>

          <h2>When to Use This Pattern</h2>
          <p>Use this pattern to:</p>
          <ul>
            <li>Isolate resources used to consume a set of backend services</li>
            <li>Isolate critical consumers from standard consumers</li>
            <li>Protect the application from cascading failures</li>
          </ul>

          <p><strong>Not suitable when:</strong></p>
          <ul>
            <li>‚ùå Less efficient use of resources is not acceptable in the project</li>
            <li>‚ùå The added complexity isn't necessary</li>
          </ul>

          <h2>Well-Architected Framework Alignment</h2>
          <ul>
            <li><strong>üõ°Ô∏è Reliability:</strong> Failure isolation prevents faults from affecting other bulkheads</li>
            <li><strong>üîê Security:</strong> Segmentation helps constrain security incidents to the compromised bulkhead</li>
            <li><strong>‚ö° Performance Efficiency:</strong> Each bulkhead can be individually scalable</li>
          </ul>

          <h3>Kubernetes Example</h3>
          <pre><code>apiVersion: v1
kind: Pod
metadata:
  name: drone-management
spec:
  containers:
  - name: drone-management-container
    image: drone-service
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "1"</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#circuit-breaker"><strong>Circuit Breaker</strong></a> - Prevents repeated attempts to invoke failing services</li>
            <li>üîó <a href="#retry"><strong>Retry</strong></a> - Handles transient failures</li>
            <li>üîó <a href="#throttling"><strong>Throttling</strong></a> - Limits the rate of requests</li>
          </ul>
        </section>

        <!-- Cache-Aside Pattern -->
        <section id="cache-aside" role="article">
          <h1>üíæ Cache-Aside Pattern</h1>
          <span class="badge">data</span>
          <span class="badge">performance</span>
          <span class="badge">caching</span>
          
          <h2>Context and Problem</h2>
          <p>Applications use a cache to improve performance for repeated access to information in a data store. However, <strong>cached data can't always remain consistent</strong> with the data store. Applications should implement a strategy that keeps the data in the cache as up-to-date as possible while detecting and handling when cached data becomes stale.</p>

          <h2>Solution</h2>
          <p>An application can emulate read-through caching by implementing the <strong>Cache-Aside pattern</strong>. This strategy loads data into the cache on demand:</p>
          
          <ol>
            <li>The application determines whether an item currently resides in the cache</li>
            <li>If the item isn't in the cache (<strong>cache miss</strong>), the application retrieves the item from the data store</li>
            <li>The application adds the item to the cache and then returns it to the caller</li>
          </ol>

          <div class="callout">
            <strong>üí° Key Insight:</strong> If an application updates information, it follows the <strong>write-through strategy</strong> by making the modification to the data store and invalidating the corresponding item in the cache.
          </div>

          <div class="mermaid">
flowchart TD
    Start([Application Request]) --> Check{Item in<br/>Cache?}
    Check -->|Yes - Cache Hit| ReturnCache[Return from Cache]
    Check -->|No - Cache Miss| ReadDB[Read from<br/>Data Store]
    ReadDB --> AddCache[Add to Cache<br/>with TTL]
    AddCache --> ReturnData[Return Data]
    ReturnCache --> End([Response])
    ReturnData --> End
    
    Update([Update Request]) --> WriteDB[Write to<br/>Data Store]
    WriteDB --> InvalidateCache[Invalidate<br/>Cache Entry]
    InvalidateCache --> Complete([Update Complete])
    
    style Check fill:#3b82f6,stroke:#2563eb,stroke-width:2px,color:#fff
    style AddCache fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff
    style InvalidateCache fill:#f59e0b,stroke:#d97706,stroke-width:2px,color:#fff
          </div>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ Improves response time and reduces data store load</li>
            <li>‚úÖ Application controls cache lifecycle</li>
            <li>‚úÖ Works with any cache technology (Redis, Memcached, etc.)</li>
          </ul>

          <h3>Problems and Considerations</h3>
          <ul>
            <li><strong>Lifetime of cached data:</strong> Ensure expiration policy matches access patterns. Don't make expiration too short (premature expiration) or too long (stale data)</li>
            <li><strong>Evicting data:</strong> Most caches have limited size and use least-recently-used (LRU) policy for eviction</li>
            <li><strong>Configuration:</strong> Can configure cache globally or per cached item</li>
            <li><strong>Priming the cache:</strong> Many solutions prepopulate cache with data likely required at startup</li>
            <li><strong>Consistency:</strong> Doesn't guarantee consistency between data store and cache</li>
            <li><strong>Local caching:</strong> Local cache works well for repeated access but can become inconsistent across instances</li>
            <li><strong>Semantic caching:</strong> Some workloads benefit from semantic meaning-based retrieval rather than exact keys</li>
          </ul>

          <h2>When to Use This Pattern</h2>
          <p>Use this pattern when:</p>
          <ul>
            <li>A cache doesn't provide native read-through and write-through operations</li>
            <li>Resource demand is unpredictable (load data on demand)</li>
          </ul>

          <p><strong>Not suitable when:</strong></p>
          <ul>
            <li>‚ùå The data is sensitive or security related</li>
            <li>‚ùå The cached data set is static (prime cache on startup instead)</li>
            <li>‚ùå Most requests don't experience a cache hit</li>
            <li>‚ùå Caching session state in a web application hosted in a web farm (avoid client-server affinity)</li>
          </ul>

          <h2>Well-Architected Framework Alignment</h2>
          <ul>
            <li><strong>üõ°Ô∏è Reliability:</strong> Caching replicates data, preserving availability if origin store becomes temporarily unavailable</li>
            <li><strong>‚ö° Performance Efficiency:</strong> Improves performance for read-heavy data that changes infrequently and tolerates staleness</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p>Use <strong>Azure Managed Redis</strong> to create a distributed cache shared across multiple application instances:</p>

          <pre><code>// Connect to Azure Managed Redis
private static Lazy&lt;ConnectionMultiplexer&gt; lazyConnection = 
    new Lazy&lt;ConnectionMultiplexer&gt;(() =&gt; {
        string cacheConnection = ConfigurationManager
            .AppSettings["CacheConnection"].ToString();
        return ConnectionMultiplexer.Connect(cacheConnection);
    });

public static ConnectionMultiplexer Connection =&gt; lazyConnection.Value;</code></pre>

          <h4>Read Pattern (Cache-Aside)</h4>
          <pre><code>public async Task&lt;MyEntity&gt; GetMyEntityAsync(int id) {
  var key = $"MyEntity:{id}";
  var cache = Connection.GetDatabase();
  
  // Try to get from cache
  var json = await cache.StringGetAsync(key);
  var value = string.IsNullOrWhiteSpace(json) 
    ? default(MyEntity)
    : JsonConvert.DeserializeObject&lt;MyEntity&gt;(json);
  
  if (value == null) { // Cache miss
    // Get from data store
    value = ... // Retrieve from database
    
    // Add to cache with expiration
    await cache.StringSetAsync(key, 
        JsonConvert.SerializeObject(value));
    await cache.KeyExpireAsync(key, 
        TimeSpan.FromMinutes(5));
  }
  
  return value;
}</code></pre>

          <h4>Write Pattern (Invalidate Cache)</h4>
          <pre><code>public async Task UpdateEntityAsync(MyEntity entity) {
    // 1. Update the data store FIRST
    await this.store.UpdateEntityAsync(entity);
    
    // 2. Invalidate cache entry
    var cache = Connection.GetDatabase();
    var key = $"MyEntity:{entity.Id}";
    await cache.KeyDeleteAsync(key);
}</code></pre>

          <div class="callout">
            <strong>‚ö†Ô∏è Important:</strong> The order of steps is critical. Update the data store <strong>before</strong> removing the item from cache. Otherwise, there's a window where a client might fetch outdated data and add it back to the cache.
          </div>

          <h3>Related Resources</h3>
          <ul>
            <li>üîó <strong>Caching guidance</strong> - Problems to consider when implementing a cache</li>
            <li>üîó <strong>Data consistency primer</strong> - Managing consistency across distributed data</li>
            <li>üîó <strong>Semantic cache tutorial</strong> - Using Azure Managed Redis for semantic caching</li>
          </ul>
        </section>

        <!-- Choreography Pattern -->
        <section id="choreography" role="article">
          <h1>üíÉ Choreography Pattern</h1>
          <span class="badge">messaging</span>
          <span class="badge">events</span>
          <span class="badge">orchestration</span>
          
          <h2>Context and Problem</h2>
          <p>A cloud-based application is often divided into several small services that work together to process a business transaction end-to-end. Even a single operation can result in <strong>multiple point-to-point calls</strong> among all services.</p>
          
          <p>A common pattern for communication is to use a <strong>centralized service or orchestrator</strong>. While the orchestrator can consolidate transaction status, there are drawbacks:</p>
          
          <ul>
            <li>‚ö†Ô∏è Adding or removing services might break existing logic - requires rewiring communication paths</li>
            <li>‚ö†Ô∏è Makes orchestrator implementation complex and hard to maintain</li>
            <li>‚ö†Ô∏è Can introduce performance bottlenecks under load</li>
            <li>‚ö†Ô∏è Becomes a single point of failure</li>
            <li>‚ö†Ô∏è Can cause cascading failures in downstream services</li>
          </ul>

          <div class="mermaid">
graph LR
    Client[Client Request] --> Orchestrator[Central Orchestrator]
    Orchestrator -->|Delegate| ServiceA[Service A]
    Orchestrator -->|Delegate| ServiceB[Service B]
    Orchestrator -->|Delegate| ServiceC[Service C]
    ServiceA -->|Status| Orchestrator
    ServiceB -->|Status| Orchestrator
    ServiceC -->|Status| Orchestrator
    
    style Orchestrator fill:#ef4444,stroke:#dc2626,stroke-width:3px,color:#fff
    style Client fill:#dbeafe,stroke:#3b82f6,stroke-width:2px
    style ServiceA fill:#fef3c7,stroke:#f59e0b,stroke-width:2px
    style ServiceB fill:#fef3c7,stroke:#f59e0b,stroke-width:2px
    style ServiceC fill:#fef3c7,stroke:#f59e0b,stroke-width:2px
          </div>

          <h2>Solution</h2>
          <p><strong>Delegate the transaction handling logic among the services.</strong> Let each service decide and participate in the communication workflow for a business operation without direct communication with each other.</p>
          
          <p>A common implementation uses a <strong>message broker</strong> that buffers requests until downstream components claim and process them through a publisher-subscriber model:</p>

          <div class="mermaid">
graph TB
    Client[Client Request] --> Queue[Message Broker<br/>Queue/Topic]
    Queue -->|Subscribe| ServiceA[Service A]
    Queue -->|Subscribe| ServiceB[Service B]
    Queue -->|Subscribe| ServiceC[Service C]
    ServiceA -->|Publish Result| Queue
    ServiceB -->|Publish Result| Queue
    ServiceC -->|Publish Result| Queue
    
    style Queue fill:#8b5cf6,stroke:#7c3aed,stroke-width:3px,color:#fff
    style Client fill:#dbeafe,stroke:#3b82f6,stroke-width:2px
    style ServiceA fill:#dcfce7,stroke:#10b981,stroke-width:2px
    style ServiceB fill:#dcfce7,stroke:#10b981,stroke-width:2px
    style ServiceC fill:#dcfce7,stroke:#10b981,stroke-width:2px
          </div>

          <h3>How It Works</h3>
          <ol>
            <li>Client requests are queued as messages in a message broker</li>
            <li>Services poll the broker (or broker pushes) based on their business logic</li>
            <li>Each subscribed service performs their operation and responds with success/failure</li>
            <li>If successful, the service can push a message back to continue the workflow</li>
            <li>If failed, the message broker works with other services to compensate the transaction</li>
          </ol>

          <h2>Issues and Considerations</h2>
          <ul>
            <li><strong>‚ö†Ô∏è Handling failures:</strong> Components may have dependencies. Implementing compensating transactions adds complexity</li>
            <li><strong>‚ö†Ô∏è Sequential workflows:</strong> Pattern works best for parallel operations. Sequences become complicated when Service D depends on B and C completing first</li>
            <li><strong>‚ö†Ô∏è Rapid growth complexity:</strong> High number of independent services makes workflow complex. Distributed tracing becomes difficult</li>
            <li><strong>‚ö†Ô∏è Resiliency distribution:</strong> Orchestrator-led designs centralize retry logic. With choreography, downstream components must handle resiliency, increasing point-to-point communication</li>
          </ul>

          <h2>When to Use This Pattern</h2>
          <p>Use this pattern when:</p>
          <ul>
            <li>‚úÖ Downstream components handle atomic operations independently ('fire and forget')</li>
            <li>‚úÖ You expect components to get updated and replaced frequently</li>
            <li>‚úÖ Natural fit for serverless architectures with simple workflows</li>
            <li>‚úÖ Good choice for communications between bounded contexts</li>
            <li>‚úÖ Performance bottleneck introduced by central orchestrator</li>
          </ul>

          <p><strong>Not suitable when:</strong></p>
          <ul>
            <li>‚ùå Application is complex and requires central component for shared logic</li>
            <li>‚ùå Point-to-point communication between components is inevitable</li>
            <li>‚ùå Need to consolidate all operations handled by downstream components</li>
          </ul>

          <h2>Well-Architected Framework Alignment</h2>
          <ul>
            <li><strong>üéØ Operational Excellence:</strong> Autonomous components designed to be replaceable - modify workload with less overall change</li>
            <li><strong>‚ö° Performance Efficiency:</strong> Alternative when performance bottlenecks occur in centralized orchestration topology</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p>Example using Azure Services:</p>
          <ul>
            <li><strong>Azure Service Bus:</strong> Topic with subscriptions and session-aware queue for ordered processing</li>
            <li><strong>Azure Event Grid:</strong> Event-driven state changes (e.g., order shipped status)</li>
            <li><strong>Azure Container Apps:</strong> Hosts Azure Functions for ingestion and event-driven processing</li>
            <li><strong>Session identifiers (GUIDs):</strong> Enable ordered handling of unbounded sequences of related messages</li>
          </ul>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#ambassador"><strong>Ambassador</strong></a> - Modularize business service</li>
            <li>üîó <a href="#queue-load-leveling"><strong>Queue-Based Load Leveling</strong></a> - Handle workload spikes</li>
            <li>üîó <a href="#pub-sub"><strong>Publisher-Subscriber</strong></a> - Asynchronous distributed messaging</li>
            <li>üîó <a href="#compensating-transaction"><strong>Compensating Transaction</strong></a> - Undo failed operations</li>
          </ul>
        </section>

        <!-- Circuit Breaker Pattern -->
        <section id="circuit-breaker" role="article">
          <h1>‚ö° Circuit Breaker Pattern</h1>
          <span class="badge">reliability</span>
          <span class="badge">fault-tolerance</span>
          <span class="badge">resilience</span>
          
          <h2>Context and Problem</h2>
          <p>In a distributed environment, calls to remote resources can fail due to <strong>transient faults</strong> (overcommitted resources, slow network, timeouts). These typically correct themselves after a short period.</p>
          
          <p>However, <strong>unanticipated events</strong> can create faults that take longer to fix - from partial loss of connectivity to complete service failure. In these situations, an application shouldn't continually retry an operation that's unlikely to succeed.</p>
          
          <div class="callout">
            <strong>‚ö†Ô∏è Cascading Failures:</strong> If a service is busy, failure in one part can lead to cascading failures. Concurrent requests might block until timeout expires, holding critical system resources (memory, threads, database connections) and exhausting resources needed by other parts of the system.
          </div>

          <h2>Solution</h2>
          <p>The Circuit Breaker pattern <strong>prevents an application from repeatedly trying to execute an operation that's likely to fail.</strong> It acts as a proxy that monitors recent failures and uses this information to decide whether to allow the operation to proceed or return an exception immediately.</p>

          <div class="mermaid">
stateDiagram-v2
    [*] --> Closed
    Closed --> Open: Failure threshold reached
    Open --> HalfOpen: Timeout expires
    HalfOpen --> Closed: Success count threshold reached
    HalfOpen --> Open: Operation fails
    
    Closed: üü¢ Closed State<br/>Route requests normally<br/>Increment failure counter
    Open: üî¥ Open State<br/>Fail immediately<br/>Return exception
    HalfOpen: üü° Half-Open State<br/>Limited trial requests<br/>Test recovery
          </div>

          <h3>Circuit Breaker States</h3>
          <table class="table table-striped">
            <thead>
              <tr>
                <th>State</th>
                <th>Behavior</th>
                <th>Transition</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>üü¢ Closed</strong></td>
                <td>Requests route to operation normally. Counts recent failures. If failures exceed threshold within time period ‚Üí Open state</td>
                <td>Failure threshold reached</td>
              </tr>
              <tr>
                <td><strong>üî¥ Open</strong></td>
                <td>Requests fail immediately and return exception. Starts timeout timer</td>
                <td>Timer expires ‚Üí Half-Open</td>
              </tr>
              <tr>
                <td><strong>üü° Half-Open</strong></td>
                <td>Limited requests allowed through. If successful ‚Üí Closed. If fail ‚Üí Open</td>
                <td>Success count met or operation fails</td>
              </tr>
            </tbody>
          </table>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ Provides stability while system recovers from failure</li>
            <li>‚úÖ Minimizes impact on performance - quickly rejects likely-to-fail requests</li>
            <li>‚úÖ Maintains response time by avoiding long timeouts</li>
            <li>‚úÖ Can raise events on state changes for monitoring and alerts</li>
            <li>‚úÖ Adaptive techniques using AI/ML can dynamically adjust thresholds based on traffic patterns</li>
          </ul>

          <h2>Issues and Considerations</h2>
          <ul>
            <li><strong>Exception handling:</strong> Application must handle exceptions when operation is unavailable</li>
            <li><strong>Types of exceptions:</strong> Circuit breaker might examine exception types and adjust strategy (e.g., more timeouts needed vs. service crashes)</li>
            <li><strong>Monitoring:</strong> Provide observability into failed and successful requests. Use distributed tracing for end-to-end visibility</li>
            <li><strong>Recoverability:</strong> Configure to match likely recovery pattern of the operation</li>
            <li><strong>Failed operations testing:</strong> In Open state, can periodically ping remote service to check availability</li>
            <li><strong>Manual override:</strong> Provide manual reset option for administrators</li>
            <li><strong>Concurrency:</strong> Large number of concurrent instances shouldn't add excessive overhead</li>
            <li><strong>Resource differentiation:</strong> Be careful with single circuit breaker for resources with multiple independent providers (e.g., sharded data stores)</li>
            <li><strong>Accelerated circuit breaking:</strong> Failure response can contain enough info to trip immediately (e.g., HTTP 429 or 503)</li>
          </ul>

          <h2>When to Use This Pattern</h2>
          <p>Use this pattern when:</p>
          <ul>
            <li>‚úÖ Want to prevent cascading failures by stopping excessive remote calls</li>
            <li>‚úÖ Route traffic intelligently based on real-time failure signals (multiregion resilience)</li>
            <li>‚úÖ Protect against slow dependencies to maintain SLOs</li>
            <li>‚úÖ Manage intermittent connectivity problems in distributed environments</li>
          </ul>

          <p><strong>Not suitable when:</strong></p>
          <ul>
            <li>‚ùå Managing access to local private resources (adds overhead)</li>
            <li>‚ùå Substitute for handling exceptions in business logic</li>
            <li>‚ùå Well-known retry algorithms are sufficient</li>
            <li>‚ùå Waiting for circuit breaker reset introduces unacceptable delays</li>
            <li>‚ùå Message-driven/event-driven architecture with built-in failure isolation</li>
            <li>‚ùå Failure recovery managed at infrastructure/platform level</li>
          </ul>

          <h2>Well-Architected Framework Alignment</h2>
          <ul>
            <li><strong>üõ°Ô∏è Reliability:</strong> Prevents faulting dependency from overloading. Triggers graceful degradation. Couples with automatic recovery for self-preservation and self-healing</li>
            <li><strong>‚ö° Performance Efficiency:</strong> Avoids retry-on-error approach which leads to excessive resource usage during dependency recovery</li>
          </ul>

          <h3>Azure Example Implementation</h3>
          <p>Circuit breaker monitoring Azure Cosmos DB free tier capacity:</p>
          <ul>
            <li><strong>Azure App Service:</strong> Implements circuit breaker logic, returns cached responses when circuit is open</li>
            <li><strong>Azure Cosmos DB:</strong> Free tier with capacity limits - can return 429 responses during overload</li>
            <li><strong>Azure Monitor:</strong> Aggregates logs and metrics, uses dynamic thresholds to detect issues</li>
            <li><strong>Azure Monitor Alerts:</strong> Proactively notifies operations team when thresholds breached</li>
          </ul>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#retry"><strong>Retry</strong></a> - Transparently retry failed operations (combine with Circuit Breaker)</li>
            <li>üîó <a href="#health-monitoring"><strong>Health Endpoint Monitoring</strong></a> - Circuit breaker can test service health via endpoints</li>
            <li>üîó <a href="#bulkhead"><strong>Bulkhead</strong></a> - Isolate resources to prevent cascading failures</li>
          </ul>
        </section>

        <!-- Claim Check Pattern -->
        <section id="claim-check" role="article">
          <h1>üé´ Claim Check Pattern</h1>
          <span class="badge">messaging</span>
          <span class="badge">payload</span>
          <span class="badge">storage</span>
          
          <h2>Context and Problem</h2>
          <p>Traditional messaging systems are optimized for high volumes of <strong>small messages</strong> and often have restrictions on message size. Large messages not only risk exceeding these limits but can also <strong>degrade the performance</strong> of the entire system when stored in the messaging system.</p>

          <h2>Solution</h2>
          <p>Use the Claim-Check pattern: <strong>Don't send large messages to the messaging system.</strong> Instead:</p>
          
          <ol>
            <li>Send the payload to an external data store</li>
            <li>Generate a claim-check token for that payload</li>
            <li>Send a message with the claim-check token to receiving applications</li>
            <li>Receiving applications retrieve the payload from the data store using the token</li>
          </ol>

          <div class="mermaid">
sequenceDiagram
    participant Sender
    participant DataStore as External Data Store
    participant Queue as Message Queue
    participant Receiver
    
    Sender->>DataStore: 1. Save payload
    DataStore-->>Sender: 2. Return claim token
    Sender->>Queue: 3. Send message<br/>with claim token
    Queue->>Receiver: 4. Deliver message<br/>with token
    Receiver->>DataStore: 5. Retrieve payload<br/>using token
    DataStore-->>Receiver: 6. Return payload
    Receiver->>Receiver: 7. Process payload
          </div>

          <div class="callout">
            <strong>üí° Key Insight:</strong> The messaging system never sees or stores the actual payload - only the lightweight claim-check token.
          </div>

          <h2>Issues and Considerations</h2>
          <ul>
            <li><strong>Delete consumed messages:</strong> Delete message and payload after consumption. Use synchronous (immediate) or asynchronous (background process) deletion strategies</li>
            <li><strong>Implement conditionally:</strong> Apply pattern only if message size exceeds messaging system limits. For smaller messages, bypass the pattern to reduce latency</li>
            <li><strong>Sensitive data protection:</strong> Can apply pattern to all or portions of sensitive information in payload</li>
            <li><strong>Complex routing:</strong> Messages traversing multiple components cause bottlenecks due to serialization/deserialization. Use Claim-Check to prevent direct processing by intermediaries</li>
          </ul>

          <h2>When to Use This Pattern</h2>
          <p><strong>Primary use cases:</strong></p>
          <ul>
            <li>‚úÖ Message sizes surpass messaging system limits</li>
            <li>‚úÖ Large messages are straining the system and degrading performance</li>
          </ul>

          <p><strong>Secondary use cases:</strong></p>
          <ul>
            <li>‚úÖ Payloads contain sensitive data not wanted visible to messaging system</li>
            <li>‚úÖ Complex routing scenarios with multiple component hops</li>
          </ul>

          <h2>Well-Architected Framework Alignment</h2>
          <ul>
            <li><strong>üõ°Ô∏è Reliability:</strong> Separating data from message provides increased reliability and disaster recovery for payload through dedicated data store redundancy</li>
            <li><strong>üîê Security:</strong> Extract sensitive data from messages, store in secure data store with tighter access controls. Hides data from unrelated services</li>
            <li><strong>üí∞ Cost Optimization:</strong> Reducing message body size might enable using cheaper messaging solution. Avoids premium features for large message limits</li>
            <li><strong>‚ö° Performance Efficiency:</strong> Manages large messages more effectively. Reduces message size sent to messaging system. Receiving apps access large messages only when needed</li>
          </ul>

          <h3>Azure Implementation Examples</h3>
          <p>Four Azure messaging system scenarios:</p>
          <table class="table table-striped">
            <thead>
              <tr>
                <th>Messaging System</th>
                <th>Token Generation</th>
                <th>Processing</th>
                <th>Data Store</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Azure Queue Storage</td>
                <td>Azure Event Grid (automatic)</td>
                <td>Azure Function</td>
                <td>Azure Blob Storage</td>
              </tr>
              <tr>
                <td>Azure Event Hubs (Standard API)</td>
                <td>Azure Event Grid (automatic)</td>
                <td>Command-line client</td>
                <td>Azure Blob Storage</td>
              </tr>
              <tr>
                <td>Azure Service Bus</td>
                <td>Azure Event Grid (automatic)</td>
                <td>Azure Function</td>
                <td>Azure Blob Storage</td>
              </tr>
              <tr>
                <td>Azure Event Hubs (Kafka API)</td>
                <td>Command-line client (manual)</td>
                <td>Azure Function</td>
                <td>Azure Blob Storage</td>
              </tr>
            </tbody>
          </table>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#async-request-reply"><strong>Asynchronous Request-Reply</strong></a> - Handle long-running operations</li>
            <li>üîó <a href="#competing-consumers"><strong>Competing Consumers</strong></a> - Multiple consumers processing messages</li>
            <li>üîó <a href="#sequential-convoy"><strong>Sequential Convoy</strong></a> - Ordered message processing</li>
          </ul>
        </section>

        <!-- Compensating Transaction Pattern -->
        <section id="compensating-transaction" role="article">
          <h1>‚Ü©Ô∏è Compensating Transaction Pattern</h1>
          <span class="badge">reliability</span>
          <span class="badge">transactions</span>
          <span class="badge">consistency</span>
          
          <h2>Context and Problem</h2>
          <p>Applications running in the cloud frequently modify data spread across various data sources in different geographic locations. To avoid contention and improve performance, applications implement <strong>eventual consistency</strong> rather than strong transactional consistency.</p>
          
          <p>A typical business operation consists of a series of separate steps. While performing these steps, the overall system state might be inconsistent, but when complete, the system should become consistent again.</p>

          <div class="callout">
            <strong>üéØ Challenge:</strong> How to handle a step that fails? You might need to undo all work that previous steps completed. But you can't always simply roll back the data because concurrent instances might have changed it.
          </div>

          <h2>Solution</h2>
          <p>Implement a <strong>compensating transaction</strong>. The steps in a compensating transaction undo the effects of the steps in the original operation. However, it can't always simply replace the current state with the state at the start of the operation because it might overwrite changes made by concurrent instances.</p>
          
          <p>Instead, a compensating transaction must be an <strong>intelligent process</strong> that takes into account work done by concurrent instances - driven by the nature of the work performed.</p>

          <div class="mermaid">
flowchart TD
    Start([Start Transaction]) --> Step1[Step 1: Book Flight]
    Step1 --> Step2[Step 2: Book Hotel]
    Step2 --> Step3[Step 3: Reserve Car]
    Step3 --> Check{All Steps<br/>Successful?}
    
    Check -->|Yes| Complete([Transaction Complete])
    Check -->|No| Comp1[Compensate: Cancel Car]
    Comp1 --> Comp2[Compensate: Cancel Hotel]
    Comp2 --> Comp3[Compensate: Cancel Flight]
    Comp3 --> Rollback([Transaction Rolled Back])
    
    style Check fill:#f59e0b,stroke:#d97706,stroke-width:2px,color:#fff
    style Complete fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff
    style Rollback fill:#ef4444,stroke:#dc2626,stroke-width:2px,color:#fff
          </div>

          <h3>Key Points</h3>
          <ul>
            <li>‚ö†Ô∏è A compensating transaction might <strong>not</strong> undo work in exact reverse order</li>
            <li>‚ö†Ô∏è It might be possible to perform some undo steps <strong>in parallel</strong></li>
            <li>‚ö†Ô∏è Compensating transactions are themselves eventually consistent and can also fail</li>
            <li>‚ö†Ô∏è System should be able to resume at point of failure and continue</li>
            <li>‚ö†Ô∏è Steps should be defined as <strong>idempotent commands</strong> (can be repeated safely)</li>
          </ul>

          <h2>Issues and Considerations</h2>
          <ul>
            <li><strong>Determining failure:</strong> Step might not fail immediately - could get blocked. May need timeout mechanism</li>
            <li><strong>Not easily generalized:</strong> Compensation logic is application-specific, relies on sufficient information to undo effects</li>
            <li><strong>Idempotent steps:</strong> Define steps as idempotent commands so they can be repeated if compensating transaction fails</li>
            <li><strong>Resilient infrastructure:</strong> Must not lose information required to compensate, reliably monitor progress</li>
            <li><strong>Not necessarily full rollback:</strong> Doesn't return system to state at start - compensates for work completed before failure</li>
            <li><strong>Order considerations:</strong> Steps in compensating transaction not necessarily exact opposite. More sensitive data stores should be compensated first</li>
            <li><strong>Preventive measures:</strong> Place short-term locks on resources, obtain resources in advance, finalize before locks expire</li>
            <li><strong>Forgiving retry logic:</strong> More forgiving retry can minimize failures that trigger compensation</li>
          </ul>

          <h2>When to Use This Pattern</h2>
          <p>Use this pattern <strong>only for operations that must be undone if they fail.</strong> If possible, design solutions to avoid the complexity of requiring compensating transactions.</p>

          <h2>Well-Architected Framework Alignment</h2>
          <ul>
            <li><strong>üõ°Ô∏è Reliability:</strong> Compensation actions address malfunctions in critical workload paths by rolling back data changes, breaking transaction locks, or executing native system behavior to reverse effects</li>
          </ul>

          <h3>Example: Travel Website</h3>
          <p>Customers booking itinerary (Seattle ‚Üí London ‚Üí Paris) perform steps:</p>
          <ol>
            <li>Book seat on flight F1 (Seattle to London)</li>
            <li>Book seat on flight F2 (London to Paris)</li>
            <li>Book seat on flight F3 (Paris to Seattle)</li>
            <li>Reserve room at hotel H1 in London</li>
            <li>Reserve room at hotel H2 in Paris</li>
          </ol>

          <p><strong>Compensating transaction steps:</strong> If customer cancels, undo bookings. But steps might not be exact opposite (e.g., canceling flight may not entitle complete refund - business-specific rules apply).</p>

          <div class="callout">
            <strong>üí° Note:</strong> Failure of single step doesn't always necessitate full rollback. For example, if hotel H1 unavailable, preferable to offer different hotel in same city rather than canceling all flights. Customer should decide whether to proceed or cancel entire itinerary.
          </div>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#scheduler-agent"><strong>Scheduler Agent Supervisor</strong></a> - Implement resilient systems with distributed services</li>
            <li>üîó <a href="#retry"><strong>Retry</strong></a> - Minimize compensating transaction use with effective retry policy</li>
            <li>üîó <a href="#saga"><strong>Saga</strong></a> - Manage data consistency across microservices with compensating transactions</li>
            <li>üîó <a href="#pipes-filters"><strong>Pipes and Filters</strong></a> - Alternative to distributed transactions</li>
          </ul>
        </section>

        <!-- Competing Consumers Pattern -->
        <section id="competing-consumers" role="article">
          <h1>üèÉ Competing Consumers Pattern</h1>
          <span class="badge">messaging</span>
          <span class="badge">scalability</span>
          <span class="badge">queue</span>
          
          <h2>Context and Problem</h2>
          <p>An application running in the cloud handles a large number of requests. Rather than process each request synchronously, a common technique is to pass them through a messaging system to another service (consumer service) that handles them <strong>asynchronously</strong>.</p>
          
          <p>The number of requests can vary significantly over time. A sudden increase can cause an unpredictable workload. At peak hours, a system might need to process <strong>hundreds of requests per second</strong>, while at other times the number could be very small.</p>

          <div class="callout">
            <strong>‚ö†Ô∏è Challenge:</strong> Using a single instance of the consumer service can cause that instance to become flooded with requests, or the messaging system might be overloaded. Consumers must be coordinated to ensure each message is delivered to only a single consumer, with load balanced across consumers.
          </div>

          <h2>Solution</h2>
          <p>Use a <strong>message queue</strong> to implement the communication channel. The application posts requests as messages to the queue, and consumer service instances receive messages from the queue and process them. This approach enables the <strong>same pool of consumer instances to handle messages from any application instance.</strong></p>

          <div class="mermaid">
graph TB
    App1[Application<br/>Instance 1] --> Queue[Message Queue]
    App2[Application<br/>Instance 2] --> Queue
    App3[Application<br/>Instance 3] --> Queue
    
    Queue --> Consumer1[Consumer<br/>Instance 1]
    Queue --> Consumer2[Consumer<br/>Instance 2]
    Queue --> Consumer3[Consumer<br/>Instance 3]
    Queue --> Consumer4[Consumer<br/>Instance 4]
    
    style Queue fill:#8b5cf6,stroke:#7c3aed,stroke-width:3px,color:#fff
    style App1 fill:#dbeafe,stroke:#3b82f6,stroke-width:2px
    style App2 fill:#dbeafe,stroke:#3b82f6,stroke-width:2px
    style App3 fill:#dbeafe,stroke:#3b82f6,stroke-width:2px
    style Consumer1 fill:#dcfce7,stroke:#10b981,stroke-width:2px
    style Consumer2 fill:#dcfce7,stroke:#10b981,stroke-width:2px
    style Consumer3 fill:#dcfce7,stroke:#10b981,stroke-width:2px
    style Consumer4 fill:#dcfce7,stroke:#10b981,stroke-width:2px
          </div>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Load-leveled system:</strong> Queue acts as buffer between app instances and consumer instances, minimizing impact on availability and responsiveness</li>
            <li>‚úÖ <strong>Long-running processing:</strong> Handling messages with long-running processing doesn't prevent other messages from being handled concurrently</li>
            <li>‚úÖ <strong>Improved reliability:</strong> Messages not sent to specific instance - failed service instance won't block producer</li>
            <li>‚úÖ <strong>No complex coordination:</strong> Message queue ensures each message delivered at least once without coordination between producers and consumers</li>
            <li>‚úÖ <strong>Scalable:</strong> System can dynamically increase/decrease consumer instances as message volume fluctuates (auto-scaling)</li>
            <li>‚úÖ <strong>Improved resiliency:</strong> Transactional read operations ensure message returned to queue if consumer fails (use dead-letter queues to prevent continuous failures)</li>
          </ul>

          <h2>Issues and Considerations</h2>
          <ul>
            <li><strong>Message ordering:</strong> Order in which consumers receive messages isn't guaranteed. Design system to ensure message processing is <strong>idempotent</strong>. Azure Service Bus can implement guaranteed FIFO ordering using message sessions</li>
            <li><strong>Designing for resiliency:</strong> If system detects and restarts failed instances, implement processing as idempotent operations to minimize effects of single message being retrieved multiple times</li>
            <li><strong>Detecting poison messages:</strong> Malformed message or task requiring unavailable resources can cause service instance to fail. Prevent such messages from being returned to queue - capture and store details elsewhere (use dead-letter queues)</li>
            <li><strong>Handling results:</strong> Service instance is fully decoupled from application logic. If service generates results to pass back, this information must be stored in location accessible to both. Use dedicated message reply queue</li>
            <li><strong>Scaling the messaging system:</strong> In large-scale solution, single queue could be overwhelmed. Consider partitioning messaging system or use load balancing across multiple queues</li>
            <li><strong>Ensuring reliability:</strong> Reliable messaging system needed to guarantee enqueued messages won't be lost - essential for ensuring at-least-once delivery</li>
          </ul>

          <h2>When to Use This Pattern</h2>
          <p>Use this pattern when:</p>
          <ul>
            <li>‚úÖ Workload divided into tasks that can run asynchronously</li>
            <li>‚úÖ Tasks are independent and can run in parallel</li>
            <li>‚úÖ Volume of work is highly variable, requiring scalable solution</li>
            <li>‚úÖ Solution must provide high availability and be resilient if task processing fails</li>
          </ul>

          <p><strong>Not suitable when:</strong></p>
          <ul>
            <li>‚ùå Not easy to separate application workload into discrete tasks</li>
            <li>‚ùå High degree of dependence between tasks</li>
            <li>‚ùå Tasks must be performed synchronously</li>
            <li>‚ùå Tasks must be performed in specific sequence (note: some messaging systems support sessions for ordering)</li>
          </ul>

          <h2>Well-Architected Framework Alignment</h2>
          <ul>
            <li><strong>üõ°Ô∏è Reliability:</strong> Builds redundancy in queue processing by treating consumers as replicas - instance failure doesn't prevent others from processing</li>
            <li><strong>üí∞ Cost Optimization:</strong> Enables scaling based on queue depth, down to zero when empty. Limit maximum concurrent consumer instances</li>
            <li><strong>‚ö° Performance Efficiency:</strong> Distributes load across all consumer nodes, increases utilization, dynamic scaling minimizes overprovisioning</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Service Bus Queues + Azure Functions:</strong></p>
          <ul>
            <li>Service Bus queue triggers in Azure Functions enable direct implementation</li>
            <li><strong>PeekLock mode:</strong> Doesn't remove message, just hides from other consumers. Function calls Complete on success or Abandon on failure</li>
            <li><strong>Auto-scaling:</strong> Azure Functions scale out/in based on queue depth - all instances compete for messages</li>
            <li><strong>Lock renewal:</strong> If function runs longer than PeekLock timeout, lock automatically renewed while function running</li>
          </ul>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#compute-consolidation"><strong>Compute Resource Consolidation</strong></a> - Consolidate multiple consumer instances into single process</li>
            <li>üîó <a href="#queue-load-leveling"><strong>Queue-Based Load Leveling</strong></a> - Queue as buffer to level the load</li>
            <li>üîó <strong>Asynchronous Messaging Primer</strong> - Request/reply messaging with message queues</li>
          </ul>
        </section>

        <!-- Compute Resource Consolidation Pattern -->
        <section id="compute-consolidation" role="article">
          <h1>üì¶ Compute Resource Consolidation Pattern</h1>
          <span class="badge">design</span>
          <span class="badge">cost</span>
          <span class="badge">efficiency</span>
          
          <h2>Context and Problem</h2>
          <p>A cloud application often implements different types of operations. In some solutions, it makes sense to follow <strong>separation of concerns</strong> initially and divide operations into separate computational units hosted and deployed individually (e.g., separate App Service web apps or separate Virtual Machines).</p>
          
          <p>However, deploying a large number of computational units can:</p>
          <ul>
            <li>‚ö†Ô∏è Increase runtime hosting costs</li>
            <li>‚ö†Ô∏è Make management of the system more complex</li>
            <li>‚ö†Ô∏è Each computational unit consumes chargeable resources, even when idle or lightly used</li>
          </ul>

          <div class="mermaid">
graph TB
    subgraph Before["‚ùå Before Consolidation"]
        direction TB
        TaskA[Task A] --> UnitA[Compute Unit A<br/>üí∞ Running]
        TaskB[Task B] --> UnitB[Compute Unit B<br/>üí∞ Running]
        TaskC[Task C] --> UnitC[Compute Unit C<br/>üí∞ Running]
        TaskD[Task D] --> UnitD[Compute Unit D<br/>üí∞ Running]
        TaskE[Task E] --> UnitE[Compute Unit E<br/>üí∞ Running]
    end
    
    subgraph After["‚úÖ After Consolidation"]
        direction TB
        TaskA2[Task A]
        TaskB2[Task B]
        TaskC2[Task C]
        TaskD2[Task D]
        TaskE2[Task E]
        TaskA2 --> Consolidated[Consolidated Compute Unit<br/>üí∞ Cost Optimized]
        TaskB2 --> Consolidated
        TaskC2 --> Consolidated
        TaskD2 --> Consolidated
        TaskE2 --> Consolidated
    end
    
    style Consolidated fill:#10b981,stroke:#059669,stroke-width:3px,color:#fff
          </div>

          <div class="callout">
            <strong>üí∞ Cost Impact:</strong> In Azure, this concern applies to App Services, Container Apps, and Virtual Machines. Running a collection of separate resources that perform well-defined operations but need to cooperate can be an inefficient use of resources.
          </div>

          <h2>Solution</h2>
          <p>To help <strong>reduce costs, increase utilization, improve communication speed, and reduce management</strong>, consolidate multiple tasks or operations into a single computational unit.</p>
          
          <h3>Grouping Criteria</h3>
          <p>Tasks can be grouped according to criteria based on features and costs:</p>
          <ul>
            <li><strong>Similar scalability profile:</strong> Tasks with similar scaling requirements, lifetime, and processing needs</li>
            <li><strong>Elasticity:</strong> Groups scale as a unit - additional instances started/stopped according to workload</li>
            <li><strong>Resource utilization:</strong> Mix tasks with different resource characteristics (e.g., compute-intensive task with memory-intensive task works well)</li>
          </ul>

          <h3>Counter Example - What NOT to Group</h3>
          <ul>
            <li>‚ùå <strong>Task 1:</strong> Polls for infrequent, time-insensitive messages</li>
            <li>‚ùå <strong>Task 2:</strong> Handles high-volume bursts of network traffic</li>
            <li>‚ö†Ô∏è Applying same scaling to Task 1 would result in more tasks listening for infrequent messages - waste of resources</li>
          </ul>

          <h2>Issues and Considerations</h2>
          <ul>
            <li><strong>Scalability and elasticity:</strong> Avoid grouping tasks with conflicting scalability requirements</li>
            <li><strong>Lifetime:</strong> Cloud infrastructure periodically recycles virtual environments. May need to configure unit to prevent recycling during long-running tasks, or use check-pointing</li>
            <li><strong>Release cadence:</strong> If implementation/configuration changes frequently, might need to stop/reconfigure/redeploy entire unit, affecting all tasks</li>
            <li><strong>Security:</strong> Tasks in same unit share security context and can access same resources. High degree of trust required between tasks. Increased attack surface</li>
            <li><strong>Fault tolerance:</strong> If one task fails or behaves abnormally, can affect other tasks in same unit</li>
            <li><strong>Contention:</strong> Avoid tasks that compete for resources. Ideally, tasks should exhibit different resource utilization characteristics</li>
            <li><strong>Complexity:</strong> Combining multiple tasks adds complexity to code, making it harder to test, debug, and maintain</li>
            <li><strong>Stable logical architecture:</strong> Design code so it doesn't need to change even if physical environment changes</li>
            <li><strong>Other strategies:</strong> Consolidation is only one way to reduce costs. Other strategies might be more appropriate (e.g., functional decomposition)</li>
          </ul>

          <div class="callout">
            <strong>üìä Note:</strong> Consider consolidating only after system has been in production. Create a heat map identifying how each task uses resources to determine which tasks are good candidates for sharing compute resources.
          </div>

          <h2>When to Use This Pattern</h2>
          <p>Use this pattern for tasks that are <strong>not cost effective if they run in their own computational units.</strong> If a task spends much of its time idle, running in dedicated unit can be expensive.</p>

          <p><strong>Not suitable when:</strong></p>
          <ul>
            <li>‚ùå Tasks perform critical fault-tolerant operations</li>
            <li>‚ùå Tasks process highly sensitive or private data requiring their own security context</li>
            <li>‚ùå These tasks should run in isolated environment, in separate computational unit</li>
          </ul>

          <h2>Well-Architected Framework Alignment</h2>
          <ul>
            <li><strong>üí∞ Cost Optimization:</strong> Maximizes utilization by avoiding unused provisioned capacity via aggregation on pooled infrastructure</li>
            <li><strong>üéØ Operational Excellence:</strong> More homogeneous compute platform simplifies management and observability, reduces disparate operational approaches, reduces tooling required</li>
            <li><strong>‚ö° Performance Efficiency:</strong> Maximizes utilization by using spare node capacity, reducing need for overprovisioning. Large (vertically scaled) compute instances often used in resource pools</li>
          </ul>

          <h3>Azure Application Platform Choices</h3>
          <table class="table table-striped">
            <thead>
              <tr>
                <th>Service</th>
                <th>Consolidation Approach</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>Azure App Service & Azure Functions</strong></td>
                <td>Deploy shared App Service plans. One or more apps run on same computing resources (same plan)</td>
              </tr>
              <tr>
                <td><strong>Azure Container Apps</strong></td>
                <td>Deploy container apps to same shared environments for related services or same virtual network</td>
              </tr>
              <tr>
                <td><strong>Azure Kubernetes Service (AKS)</strong></td>
                <td>Multiple applications co-located on same computing resources (nodes), grouped by CPU/memory needs (node pools)</td>
              </tr>
              <tr>
                <td><strong>Virtual Machines</strong></td>
                <td>Single set of VMs for all tenants - shared management costs. Virtual Machine Scale Sets for load-balancing and horizontal scaling</td>
              </tr>
            </tbody>
          </table>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <strong>Autoscaling Guidance</strong> - Start/stop instances based on anticipated demand</li>
            <li>üîó <strong>Compute Partitioning Guidance</strong> - Allocate services to minimize running costs while maintaining scalability, performance, availability, security</li>
            <li>üîó <strong>Multitenant Compute Approaches</strong> - Planning compute services for multitenant solutions</li>
          </ul>
        </section>

        <!-- CQRS Pattern -->
        <section id="cqrs" role="article">
          <h1>üìä CQRS (Command Query Responsibility Segregation) Pattern</h1>
          <span class="badge">data</span>
          <span class="badge">design</span>
          <span class="badge">command-query</span>
          
          <h2>Context and Problem</h2>
          <p>In traditional architecture, a <strong>single data model</strong> is often used for both read and write operations. This approach is straightforward and suited for basic CRUD operations.</p>
          
          <p>As applications grow, optimizing read and write operations on a single data model becomes increasingly difficult. This results in challenges:</p>
          <ul>
            <li>‚ö†Ô∏è <strong>Data mismatch:</strong> Read and write representations of data often differ</li>
            <li>‚ö†Ô∏è <strong>Lock contention:</strong> Parallel operations on same data set cause lock contention</li>
            <li>‚ö†Ô∏è <strong>Performance problems:</strong> Load on data store and data access layer, complexity of queries</li>
            <li>‚ö†Ô∏è <strong>Security challenges:</strong> Difficult to manage security when entities subject to both read and write operations</li>
          </ul>

          <div class="mermaid">
graph TB
    subgraph Traditional["‚ùå Traditional CRUD"]
        App1[Application] --> Model[Single Data Model]
        Model --> DB[(Database)]
    end
    
    subgraph CQRS["‚úÖ CQRS Pattern"]
        App2[Application]
        App2 --> WriteModel[Write Model<br/>Commands]
        App2 --> ReadModel[Read Model<br/>Queries]
        WriteModel --> WriteDB[(Write DB)]
        ReadModel --> ReadDB[(Read DB)]
        WriteDB -.Sync.-> ReadDB
    end
    
    style Model fill:#fbbf24,stroke:#f59e0b,stroke-width:2px
    style WriteModel fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff
    style ReadModel fill:#3b82f6,stroke:#2563eb,stroke-width:2px,color:#fff
          </div>

          <h2>Solution</h2>
          <p>Use the CQRS pattern to <strong>separate write operations (commands) from read operations (queries).</strong> Commands update data. Queries retrieve data. The pattern is useful when there's a clear separation needed between commands and reads.</p>

          <h3>Separate Models in a Single Data Store (Basic CQRS)</h3>
          <p>Both read and write models share a single underlying database but maintain <strong>distinct logic</strong> for their operations:</p>
          <ul>
            <li><strong>Write Model:</strong> Handles commands that update/persist data. Includes validation and domain logic. Optimizes for transactional integrity and business processes</li>
            <li><strong>Read Model:</strong> Serves queries for retrieving data. Generates DTOs/projections optimized for presentation layer. Enhances query performance by avoiding domain logic</li>
          </ul>

          <h3>Separate Models in Different Data Stores (Advanced CQRS)</h3>
          <p>Distinct data stores for read and write models enable:</p>
          <ul>
            <li>‚úÖ Scale each model independently to match load</li>
            <li>‚úÖ Use different storage technology (document DB for reads, relational DB for writes)</li>
            <li>‚úÖ Read model can use its own schema optimized for queries</li>
            <li>‚úÖ Can store materialized views to avoid complex joins</li>
            <li>‚úÖ Deploy multiple read-only replicas to reduce latency</li>
          </ul>

          <div class="callout">
            <strong>‚ö†Ô∏è Synchronization Challenge:</strong> When using separate data stores, you must ensure both remain synchronized. Write model publishes events when updating database, which read model uses to refresh its data. This introduces eventual consistency challenges.
          </div>

          <h3>Key Principles</h3>
          <ul>
            <li><strong>Commands:</strong> Represent specific business tasks (e.g., "Book hotel room" not "Set ReservationStatus to Reserved"). Should capture user intent and align with business processes</li>
            <li><strong>Queries:</strong> Never alter data. Return DTOs without domain logic. This distinct separation simplifies design and implementation</li>
            <li><strong>Client-side validation:</strong> Validate conditions before sending command (e.g., disable "Book" button if no rooms available)</li>
            <li><strong>Server-side logic:</strong> Handle edge cases and failures gracefully (e.g., race conditions, waiting lists)</li>
            <li><strong>Asynchronous processing:</strong> Process commands asynchronously via queues instead of synchronously</li>
          </ul>

          <h2>Benefits</h2>
          <ul>
            <li>‚úÖ <strong>Independent scaling:</strong> Read and write models scale independently, minimizing lock contention</li>
            <li>‚úÖ <strong>Optimized data schemas:</strong> Reads use schema optimized for queries, writes use schema optimized for updates</li>
            <li>‚úÖ <strong>Security:</strong> Only appropriate domain entities have permission to perform write actions</li>
            <li>‚úÖ <strong>Separation of concerns:</strong> Write side handles complex business logic, read side remains simple and focused on query efficiency</li>
            <li>‚úÖ <strong>Simpler queries:</strong> Materialized views in read database avoid complex joins</li>
          </ul>

          <h2>Issues and Considerations</h2>
          <ul>
            <li><strong>Increased complexity:</strong> Core concept is straightforward but can introduce significant complexity, especially when combined with Event Sourcing pattern</li>
            <li><strong>Messaging challenges:</strong> Messaging isn't required for CQRS but often used. Must account for message failures, duplicates, retries</li>
            <li><strong>Eventual consistency:</strong> When read and write databases are separated, read data might be stale. Must detect and handle scenarios where user acts on stale data</li>
          </ul>

          <h2>When to Use This Pattern</h2>
          <p>Use this pattern when:</p>
          <ul>
            <li>‚úÖ <strong>Collaborative environments:</strong> Multiple users access same data simultaneously - CQRS reduces merge conflicts with granular commands</li>
            <li>‚úÖ <strong>Task-based user interfaces:</strong> Applications guiding users through complex processes with full command-processing stack (business logic, validation)</li>
            <li>‚úÖ <strong>Performance tuning:</strong> Read performance must be fine-tuned separately from write performance, especially when reads >> writes</li>
            <li>‚úÖ <strong>Separation of development concerns:</strong> Teams work independently on write model (complex business logic) vs. read model (user interface)</li>
            <li>‚úÖ <strong>Evolving systems:</strong> System evolves over time, accommodates new model versions and frequent business rule changes</li>
            <li>‚úÖ <strong>System integration:</strong> Systems integrate with other subsystems using Event Sourcing, remain available even if subsystem fails</li>
          </ul>

          <p><strong>Not suitable when:</strong></p>
          <ul>
            <li>‚ùå Domain or business rules are simple</li>
            <li>‚ùå Simple CRUD-style UI and data access operations are sufficient</li>
          </ul>

          <h2>Well-Architected Framework Alignment</h2>
          <ul>
            <li><strong>‚ö° Performance Efficiency:</strong> Separation of read and write operations in high read-to-write workloads enables targeted performance and scaling optimizations for each operation's specific purpose</li>
          </ul>

          <h3>Combining with Event Sourcing</h3>
          <p>Some CQRS implementations incorporate the <strong>Event Sourcing pattern</strong>:</p>
          <ul>
            <li>Event store is the write model and single source of truth</li>
            <li>Read model generates materialized views from events in highly denormalized form</li>
            <li>Same events that update write model serve as inputs to read model</li>
            <li>Read model builds real-time snapshot of current state, optimizing queries</li>
          </ul>

          <h4>Benefits of Combining Patterns</h4>
          <ul>
            <li>‚úÖ Reduces update conflicts on aggregates, enhances performance and scalability</li>
            <li>‚úÖ Events processed asynchronously to build/update materialized views</li>
            <li>‚úÖ Event store as single source of truth - easily regenerate views by replaying historical events</li>
            <li>‚úÖ Materialized views function as durable, read-only cache optimized for fast queries</li>
          </ul>

          <h4>Considerations for Combining</h4>
          <ul>
            <li>‚ö†Ô∏è <strong>Eventual consistency:</strong> Updates to read store lag behind event generation</li>
            <li>‚ö†Ô∏è <strong>Increased complexity:</strong> Requires different design approach - write code to generate, process, handle events</li>
            <li>‚ö†Ô∏è <strong>View generation performance:</strong> Generating materialized views or projecting data by replaying events can be time-consuming. Implement snapshots at regular intervals</li>
          </ul>

          <h3>C# Code Example</h3>
          <p>Read model definition:</p>
          <pre><code>// Query interface
namespace ReadModel {
  public interface ProductsDao {
    ProductDisplay FindById(int productId);
    ICollection&lt;ProductDisplay&gt; FindByName(string name);
    ICollection&lt;ProductInventory&gt; FindOutOfStockProducts();
  }

  public class ProductDisplay {
    public int Id { get; set; }
    public string Name { get; set; }
    public decimal UnitPrice { get; set; }
    public bool IsOutOfStock { get; set; }
  }
}</code></pre>

          <p>Command example (rate product):</p>
          <pre><code>public class RateProduct : ICommand {
  public RateProduct() {
    this.Id = Guid.NewGuid();
  }
  public Guid Id { get; set; }
  public int ProductId { get; set; }
  public int Rating { get; set; }
  public int UserId { get; set; }
}</code></pre>

          <p>Command handler processes commands sent through messaging system (e.g., queue):</p>
          <pre><code>public class ProductsCommandHandler :
    ICommandHandler&lt;RateProduct&gt; {
  
  private readonly IRepository&lt;Product&gt; repository;

  void Handle(RateProduct command) {
    var product = repository.Find(command.ProductId);
    if (product != null) {
      product.RateProduct(command.UserId, command.Rating);
      repository.Save(product);
    }
  }
}</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#event-sourcing"><strong>Event Sourcing</strong></a> - Simplify tasks in complex domains, provide consistency for transactional data</li>
            <li>üîó <a href="#materialized-view"><strong>Materialized View</strong></a> - Prepopulated views for efficient querying</li>
            <li>üîó <strong>Data Partitioning Guidance</strong> - Divide data into partitions for scalability and performance</li>
          </ul>
        </section>

        <!-- Event Sourcing Pattern -->
        <section id="event-sourcing" role="article">
          <h1>üìú Event Sourcing Pattern</h1>
          <span class="badge">data-management</span>
          <span class="badge">audit-trail</span>
          <span class="badge">immutable-events</span>

          <h2>Context and Problem</h2>
          <p>
            Most applications work with data using a traditional <strong>CRUD</strong> (Create, Read, Update, Delete) model, 
            where the application stores only the <strong>latest state</strong> of data in a relational database. 
            This approach is straightforward but has challenges in high-load systems:
          </p>
          <ul>
            <li><strong>Performance degradation</strong> due to contention for resources and locking issues</li>
            <li><strong>Scalability limits</strong> - CRUD operations are synchronous and data operations block on updates</li>
            <li><strong>Lost history</strong> - Unless there's an auditing mechanism, the history of changes is lost</li>
            <li><strong>Concurrent update conflicts</strong> - Multiple users modifying the same data simultaneously</li>
          </ul>

          <h2>Solution</h2>
          <p>
            The <strong>Event Sourcing pattern</strong> defines an approach where operations on data are driven by a 
            <strong>sequence of events</strong>, each recorded in an <strong>append-only store</strong>. Instead of storing 
            just the current state, the application raises events that describe each action taken on the object.
          </p>
          
          <div class="callout callout-info">
            <strong>üí° Key Concept:</strong> Events are immutable and stored using append-only operations. 
            The current state of any entity can be reconstructed by replaying all events for that entity.
          </div>

          <h3>Workflow</h3>
          <div class="mermaid">
flowchart TB
    UI[Presentation Layer] --> |1. Read Query| ReadStore[(Read-Only Store)]
    UI --> |2. Command| Handler[Command Handler]
    Handler --> |3. Get Events| EventStore[(Event Store)]
    EventStore --> |4. Historical Events| Handler
    Handler --> |5. Business Logic<br/>Raise Events| Queue[Event Queue/Topic]
    Queue --> |6. Events| EventHandlers[Event Handlers]
    EventHandlers --> |Write| EventStore
    EventHandlers --> |Update| ReadStore
    EventHandlers --> |Integrate| External[External Systems]
    
    style EventStore fill:#e1f5ff
    style ReadStore fill:#fff4e6
    style Queue fill:#f3e5f5
          </div>

          <h3>Pattern Advantages</h3>
          <ul>
            <li>‚úÖ <strong>Immutability</strong> - Events are append-only, no contention during processing, vastly improved performance</li>
            <li>‚úÖ <strong>Complete audit trail</strong> - Full history of all changes, can regenerate state at any point in time</li>
            <li>‚úÖ <strong>Domain clarity</strong> - Events have meaning for domain experts, unlike abstract database tables</li>
            <li>‚úÖ <strong>Conflict resolution</strong> - Avoids concurrent update conflicts by not directly updating objects</li>
            <li>‚úÖ <strong>Event replay</strong> - Can reconstruct state by replaying events, assists in testing and debugging</li>
            <li>‚úÖ <strong>Decoupling</strong> - Command handlers raise events, tasks handle events independently</li>
            <li>‚úÖ <strong>Scalability</strong> - Append-only operations are highly scalable</li>
          </ul>

          <h3>Issues and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Important Considerations:</strong>
            <ul>
              <li><strong>Eventual consistency</strong> - System is only eventually consistent when creating materialized views or replaying events</li>
              <li><strong>Event versioning</strong> - Event store is permanent, can't update events directly. Need to handle schema changes across versions</li>
              <li><strong>Event ordering</strong> - Multi-threaded applications need careful ordering with timestamps or incremental identifiers</li>
              <li><strong>Query complexity</strong> - No standard approach like SQL queries, must replay events to get current state</li>
              <li><strong>Snapshot strategy</strong> - Large event streams require snapshots at specific intervals to improve performance</li>
              <li><strong>Idempotency required</strong> - Event consumers must be idempotent (handle duplicate events)</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>You want to capture <strong>intent, purpose, or reason</strong> in the data (e.g., "Moved home", "Closed account")</li>
            <li>Vital to <strong>minimize or avoid conflicting updates</strong> to data</li>
            <li>Need to <strong>record events to replay</strong> them to restore state, roll back changes, or keep audit log</li>
            <li>Using events is a <strong>natural feature</strong> of the application</li>
            <li>Need to <strong>decouple input/update from processing tasks</strong> (e.g., integrate payroll with expense submission)</li>
            <li>Want <strong>flexibility to change materialized models</strong> if requirements change</li>
            <li>Used with CQRS and <strong>eventual consistency is acceptable</strong></li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>Applications that do not require <strong>hyper-scale or performance</strong></li>
            <li><strong>Small or simple domains</strong> with little business logic</li>
            <li><strong>Consistency and real-time updates</strong> to views are required</li>
            <li>Only a <strong>low occurrence of conflicting updates</strong> (systems that predominantly add data)</li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Capturing history facilitates state reconstruction for disaster recovery (RE:06, RE:09)</li>
            <li>‚ö° <strong>Performance Efficiency</strong> - Atomic append-only operations, avoidance of database locking improves performance (PE:08)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p>
            <strong>Azure Event Store Options:</strong>
          </p>
          <ul>
            <li><strong>Azure Cosmos DB</strong> - Change feed as event stream, append-only with TTL</li>
            <li><strong>Azure Event Hubs</strong> - High-throughput event ingestion, event retention</li>
            <li><strong>Azure SQL Database</strong> - Temporal tables for versioned history</li>
            <li><strong>Azure Table Storage</strong> - Low-cost append-only storage</li>
          </ul>

          <h3>Example: Conference Seat Reservation</h3>
          <p>
            A conference management system tracks bookings using event sourcing instead of storing total bookings:
          </p>

          <div class="mermaid">
sequenceDiagram
    participant UI as User Interface
    participant CH as Command Handler
    participant DM as Domain Model<br/>(SeatAvailability)
    participant ES as Event Store
    
    UI->>CH: Reserve 2 seats
    CH->>ES: Query events (bookings + cancellations)
    ES->>DM: Return event history
    DM->>DM: Replay events<br/>Calculate available seats
    DM->>ES: Raise SeatsReserved event (2 seats)
    ES->>ES: Append event to store
    Note over ES: Complete history preserved
          </div>

          <p><strong>Benefits:</strong></p>
          <ul>
            <li>More scalable - avoids locking on single "total bookings" row</li>
            <li>Complete audit trail of all bookings and cancellations</li>
            <li>Can query state at any point in time</li>
            <li>Immutable events prevent lost updates</li>
          </ul>

          <p><strong>Optimization:</strong> Use snapshots to avoid replaying full event history, maintain cached copy in memory</p>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#cqrs"><strong>CQRS</strong></a> - Often combined with Event Sourcing, using event store as write model</li>
            <li>üîó <a href="#materialized-view"><strong>Materialized View</strong></a> - Create read-optimized views from event store</li>
            <li>üîó <a href="#compensating-transaction"><strong>Compensating Transaction</strong></a> - Undo changes using compensating events</li>
          </ul>
        </section>

        <!-- Materialized View Pattern -->
        <section id="materialized-view" role="article">
          <h1>üëÅÔ∏è Materialized View Pattern</h1>
          <span class="badge">data-management</span>
          <span class="badge">query-performance</span>
          <span class="badge">read-optimization</span>

          <h2>Context and Problem</h2>
          <p>
            When storing data, developers often focus on <strong>how data is stored</strong> rather than how it's read. 
            The storage format is closely related to data management, size, and integrity requirements. However, this can have 
            <strong>negative effects on queries</strong>:
          </p>
          <ul>
            <li>Queries need only a <strong>subset of data</strong> but must extract all data for entities</li>
            <li>NoSQL document stores represent data as <strong>aggregates</strong>, making summary queries inefficient</li>
            <li>Must extract all order details to get a <strong>simple summary</strong> of orders for customers</li>
            <li><strong>Complex joins</strong> across normalized tables degrade performance</li>
          </ul>

          <h2>Solution</h2>
          <p>
            Generate, in advance, a <strong>view that materializes the data</strong> in a format suited to the required results set. 
            Materialized views contain data in a <strong>query-optimized format</strong>:
          </p>
          
          <div class="callout callout-info">
            <strong>üí° Key Concept:</strong> A materialized view is completely disposable because it can be entirely 
            rebuilt from source data stores. It's never updated directly by the application - it's a specialized cache.
          </div>

          <div class="mermaid">
flowchart LR
    subgraph Source["Source Data Stores"]
        DB1[(Orders DB)]
        DB2[(Products DB)]
        DB3[(Customers DB)]
    end
    
    subgraph Process["View Generation"]
        ETL[ETL Process/<br/>Event Handler]
    end
    
    subgraph Views["Materialized Views"]
        MV1[(Sales Summary<br/>by Product)]
        MV2[(Customer<br/>Purchase History)]
        MV3[(Inventory<br/>Status)]
    end
    
    DB1 --> ETL
    DB2 --> ETL
    DB3 --> ETL
    ETL --> MV1
    ETL --> MV2
    ETL --> MV3
    
    App[Application] --> |Fast Queries| Views
    
    style Views fill:#e8f5e9
    style Source fill:#fff3e0
          </div>

          <h3>View Update Strategies</h3>
          <ul>
            <li><strong>Event-driven</strong> - Regenerate in response to source data change events</li>
            <li><strong>Scheduled</strong> - Update on a regular schedule (hourly, daily, weekly)</li>
            <li><strong>Manual trigger</strong> - Regenerate when explicitly requested</li>
            <li><strong>Event Sourcing integration</strong> - Prepopulate by examining all events (necessary for event stores)</li>
          </ul>

          <h3>Issues and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Key Considerations:</strong>
            <ul>
              <li><strong>Update timing</strong> - How and when the view is updated (event, schedule, manual)</li>
              <li><strong>Rapid source changes</strong> - Can lead to excessive overhead if regenerating on every change</li>
              <li><strong>Data consistency</strong> - View may not be fully consistent with original data during updates</li>
              <li><strong>View storage location</strong> - Doesn't have to be in same store or partition as source data</li>
              <li><strong>Multiple query support</strong> - Multiple views may be needed for different query patterns</li>
              <li><strong>Storage cost</strong> - Consider trade-off between query performance and storage requirements</li>
              <li><strong>Indexing</strong> - Add indexes to materialized views for further performance improvement</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Creating views over <strong>data that's difficult to query directly</strong> (normalized, semi-structured, unstructured)</li>
            <li>Creating <strong>temporary views</strong> that dramatically improve query performance</li>
            <li>Acting as <strong>source views or DTOs</strong> for UI, reporting, or display</li>
            <li>Supporting <strong>occasionally connected scenarios</strong> - cache view locally</li>
            <li><strong>Simplifying queries</strong> for experimentation without requiring source format knowledge</li>
            <li>Providing <strong>access to specific subsets</strong> for security or privacy</li>
            <li><strong>Bridging different data stores</strong> - leverage capabilities of multiple stores</li>
            <li><strong>Microservices architecture</strong> - consolidate data from loosely coupled services</li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>Source data is <strong>simple and easy to query</strong></li>
            <li>Source data <strong>changes very quickly</strong>, or can be accessed efficiently without a view</li>
            <li><strong>Consistency is a high priority</strong> - views might not always be fully consistent</li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>‚ö° <strong>Performance Efficiency</strong> - Reduces computation by storing pre-computed results, optimizes data access (PE:08)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Services for Materialized Views:</strong></p>
          <ul>
            <li><strong>Azure Cosmos DB</strong> - Change feed triggers view updates, multiple containers for different views</li>
            <li><strong>Azure SQL Database</strong> - Native materialized view support with automatic refresh options</li>
            <li><strong>Azure Synapse Analytics</strong> - Materialized views for data warehouse queries</li>
            <li><strong>Azure Table Storage</strong> - Low-cost storage for simple materialized views</li>
            <li><strong>Azure Functions</strong> - Event-driven view generation using change feed triggers</li>
          </ul>

          <h3>Example: Sales Summary View</h3>
          <p>
            Generate a summary of sales by product from Order, OrderItem, and Customer tables in separate partitions:
          </p>

          <div class="mermaid">
graph LR
    subgraph Sources["Source Tables (Partitioned)"]
        O[(Orders)]
        OI[(OrderItems)]
        C[(Customers)]
    end
    
    subgraph View["Materialized View"]
        MV[(Electronics<br/>Sales Summary)]
    end
    
    O --> |Join| MV
    OI --> |Aggregate| MV
    C --> |Count| MV
    
    MV --> |Fast Query| Report[Sales Report]
    
    style MV fill:#c8e6c9
          </div>

          <p><strong>View Contents:</strong></p>
          <ul>
            <li>Total sales value for each product in Electronics category</li>
            <li>Count of customers who purchased each item</li>
            <li>Pre-computed aggregations and joins</li>
          </ul>

          <p><strong>Benefits:</strong></p>
          <ul>
            <li>Complex query becomes simple SELECT from single view</li>
            <li>Can be updated on schedule (e.g., weekly)</li>
            <li>Users incorporate results in dashboards or further queries</li>
          </ul>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#cqrs"><strong>CQRS</strong></a> - Use to update materialized views by responding to change events</li>
            <li>üîó <a href="#event-sourcing"><strong>Event Sourcing</strong></a> - Maintain views in conjunction with event-based systems</li>
            <li>üîó <a href="#index-table"><strong>Index Table</strong></a> - Create secondary indexes over datasets</li>
          </ul>
        </section>

        <!-- Gateway Aggregation Pattern -->
        <section id="gateway-aggregation" role="article">
          <h1>üîÄ Gateway Aggregation Pattern</h1>
          <span class="badge">design-implementation</span>
          <span class="badge">api-gateway</span>
          <span class="badge">performance</span>

          <h2>Context and Problem</h2>
          <p>
            To perform a single task, a client might need to make <strong>multiple calls to various backend services</strong>. 
            This creates several problems:
          </p>
          <ul>
            <li><strong>Chattiness</strong> - High number of cross-service calls affects performance and scale</li>
            <li><strong>Resource consumption</strong> - Each request expends resources on client and network</li>
            <li><strong>High latency</strong> - Especially problematic over cellular networks</li>
            <li><strong>Failure risk</strong> - Multiple connections increase chance of broken connectivity or incomplete requests</li>
            <li><strong>Microservice architecture challenges</strong> - Many smaller services = more cross-service calls</li>
          </ul>

          <div class="mermaid">
graph TB
    Client[Client App] --> |1. Request Service 1| S1[Service 1]
    Client --> |2. Request Service 2| S2[Service 2]
    Client --> |3. Request Service 3| S3[Service 3]
    S1 --> |4. Response| Client
    S2 --> |5. Response| Client
    S3 --> |6. Response| Client
    
    Note1[Multiple separate connections<br/>High latency over cellular network<br/>Increased failure risk]
    
    style Note1 fill:#ffebee
          </div>

          <h2>Solution</h2>
          <p>
            Use a <strong>gateway to reduce chattiness</strong> between client and services. The gateway receives client requests, 
            dispatches to various backend systems, <strong>aggregates the results</strong>, and sends them back.
          </p>

          <div class="callout callout-info">
            <strong>üí° Key Concept:</strong> Client makes ONE request containing a package of multiple requests. 
            Gateway handles decomposition, parallel processing, and aggregation.
          </div>

          <div class="mermaid">
graph TB
    Client[Client App] --> |1. Single Aggregated Request| GW[API Gateway]
    GW --> |2. Dispatch| S1[Service 1]
    GW --> |2. Dispatch| S2[Service 2]
    GW --> |2. Dispatch| S3[Service 3]
    S1 --> |3. Response| GW
    S2 --> |3. Response| GW
    S3 --> |3. Response| GW
    GW --> |4. Aggregated Response| Client
    
    Note1[ONE connection<br/>Parallel backend processing<br/>Reduced client complexity]
    
    style GW fill:#e3f2fd
    style Note1 fill:#e8f5e9
          </div>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Reduced requests</strong> - Multiple backend calls consolidated into single client request</li>
            <li>‚úÖ <strong>Lower latency</strong> - Gateway-to-service communication typically on fast network</li>
            <li>‚úÖ <strong>Simplified client</strong> - Client only needs to know one endpoint</li>
            <li>‚úÖ <strong>Improved reliability</strong> - Single connection reduces failure points</li>
            <li>‚úÖ <strong>Parallel processing</strong> - Gateway can call backend services in parallel</li>
          </ul>

          <h3>Issues and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>No service coupling</strong> - Gateway should not introduce coupling across backend services</li>
              <li><strong>Proximity to backends</strong> - Locate gateway near backend services to reduce latency</li>
              <li><strong>Single point of failure</strong> - Design for high availability requirements</li>
              <li><strong>Bottleneck risk</strong> - Ensure gateway can scale to meet growth</li>
              <li><strong>Resilient design</strong> - Use bulkheads, circuit breakers, retry, timeouts</li>
              <li><strong>Timeout strategy</strong> - Return partial data if some services take too long</li>
              <li><strong>Asynchronous I/O</strong> - Prevent backend delays from causing performance issues</li>
              <li><strong>Distributed tracing</strong> - Use correlation IDs to track individual calls</li>
              <li><strong>Failover strategy</strong> - Consider returning cached data on failures</li>
              <li><strong>Resource requirements</strong> - Aggregation may need different resources than routing/offloading</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Client needs to <strong>communicate with multiple backend services</strong> for an operation</li>
            <li>Client uses <strong>networks with significant latency</strong> (cellular networks)</li>
            <li>Want to <strong>reduce chattiness</strong> between client and backends</li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>Reducing calls between client and <strong>single service</strong> (consider batch operation instead)</li>
            <li>Client/application is <strong>located near backend services</strong> and latency isn't significant</li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Centralized transient fault handling (RE:07)</li>
            <li>üîí <strong>Security</strong> - Reduces client touchpoints, smaller attack surface (SE:04, SE:08)</li>
            <li>üîß <strong>Operational Excellence</strong> - Backend evolution independent of clients (OE:04)</li>
            <li>‚ö° <strong>Performance Efficiency</strong> - Lower latency, caching opportunities (PE:03, PE:08)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Services:</strong></p>
          <ul>
            <li><strong>Azure Application Gateway</strong> - Regional Layer 7 load balancer with aggregation capabilities</li>
            <li><strong>Azure API Management</strong> - Full-featured API gateway with policy-based aggregation</li>
            <li><strong>Azure Front Door</strong> - Global Layer 7 load balancer for multi-region aggregation</li>
            <li><strong>Azure Functions</strong> - Custom aggregation logic with HTTP triggers</li>
          </ul>

          <h3>Example: NGINX Lua Aggregation</h3>
          <pre><code class="language-lua">worker_processes  4;

events {
  worker_connections 1024;
}

http {
  server {
    listen 80;

    location = /batch {
      content_by_lua '
        ngx.req.read_body()

        -- read json body content
        local cjson = require "cjson"
        local batch = cjson.decode(ngx.req.get_body_data())["batch"]

        -- create capture_multi table
        local requests = {}
        for i, item in ipairs(batch) do
          table.insert(requests, {item.relative_url, { method = ngx.HTTP_GET}})
        end

        -- execute batch requests in parallel
        local results = {}
        local resps = { ngx.location.capture_multi(requests) }
        for i, res in ipairs(resps) do
          table.insert(results, {
            status = res.status, 
            body = cjson.decode(res.body), 
            header = res.header
          })
        end

        ngx.say(cjson.encode({results = results}))
      ';
    }

    location = /service1 {
      default_type application/json;
      echo '{"attr1":"val1"}';
    }

    location = /service2 {
      default_type application/json;
      echo '{"attr2":"val2"}';
    }
  }
}</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#backends-frontends"><strong>Backends for Frontends</strong></a> - Different aggregations for different client types</li>
            <li>üîó <a href="#gateway-offloading"><strong>Gateway Offloading</strong></a> - Offload cross-cutting concerns to gateway</li>
            <li>üîó <a href="#gateway-routing"><strong>Gateway Routing</strong></a> - Route aggregated requests to appropriate services</li>
          </ul>
        </section>

        <!-- Gateway Offloading Pattern -->
        <section id="gateway-offloading" role="article">
          <h1>üì§ Gateway Offloading Pattern</h1>
          <span class="badge">design-implementation</span>
          <span class="badge">gateway</span>
          <span class="badge">cross-cutting</span>

          <h2>Context and Problem</h2>
          <p>
            Some features are <strong>commonly used across multiple services</strong> and require configuration, management, 
            and maintenance. Distributing these features creates problems:
          </p>
          <ul>
            <li><strong>Administrative overhead</strong> - Shared service distributed with every app deployment</li>
            <li><strong>Deployment errors</strong> - Increases likelihood of configuration mistakes</li>
            <li><strong>Update challenges</strong> - Updates to shared features must be deployed across all services</li>
            <li><strong>Specialized skills</strong> - Security issues (SSL, certificates, encryption) require expert knowledge</li>
            <li><strong>Difficult management</strong> - Certificate management, authentication, authorization, logging, monitoring across many deployments</li>
          </ul>

          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Problem:</strong> Common certificate that expires must be updated, tested, and verified on 
            EVERY application deployment.
          </div>

          <h2>Solution</h2>
          <p>
            <strong>Offload features to a gateway</strong>, particularly <strong>cross-cutting concerns</strong> such as:
          </p>
          <ul>
            <li>üîê Certificate management</li>
            <li>üîë Authentication and authorization</li>
            <li>üîí SSL termination</li>
            <li>üìä Monitoring and logging</li>
            <li>üîÑ Protocol translation</li>
            <li>‚è±Ô∏è Throttling and rate limiting</li>
          </ul>

          <div class="mermaid">
graph LR
    Client[Clients] --> |HTTPS| GW[API Gateway]
    GW --> |SSL Terminated<br/>Authentication Done<br/>HTTP| S1[Service 1]
    GW --> |HTTP| S2[Service 2]
    GW --> |HTTP| S3[Service 3]
    
    GW -.-> |Logging<br/>Monitoring| Mon[Monitoring System]
    
    Note1[Gateway handles:<br/>‚úì SSL termination<br/>‚úì Authentication<br/>‚úì Logging<br/>‚úì Monitoring]
    
    style GW fill:#e1f5fe
    style Note1 fill:#f3e5f5
          </div>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Simplified development</strong> - Remove need to distribute supporting resources (certificates, config)</li>
            <li>‚úÖ <strong>Easier management</strong> - Simpler configuration, better scalability, simpler upgrades</li>
            <li>‚úÖ <strong>Specialized expertise</strong> - Dedicated teams can implement security features</li>
            <li>‚úÖ <strong>Consistency</strong> - Minimum level of monitoring and logging even if services aren't instrumented</li>
            <li>‚úÖ <strong>Single update point</strong> - Update shared functionality once at gateway instead of all services</li>
          </ul>

          <h3>Issues and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Key Considerations:</strong>
            <ul>
              <li><strong>High availability</strong> - Gateway must be highly available and resilient to failure</li>
              <li><strong>Capacity planning</strong> - Design for application capacity and scaling requirements</li>
              <li><strong>Avoid bottlenecks</strong> - Ensure gateway doesn't limit application performance</li>
              <li><strong>Appropriate offloading</strong> - Only offload features used by entire application (security, data transfer)</li>
              <li><strong>No business logic</strong> - Business logic should never be offloaded to gateway</li>
              <li><strong>Correlation IDs</strong> - Generate for logging if tracking transactions</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Application deployment has <strong>shared concern</strong> (SSL certificates, encryption)</li>
            <li>Feature is <strong>common across deployments</strong> with different resource requirements</li>
            <li>Want to move responsibility for <strong>network security, throttling</strong> to specialized team</li>
            <li>Need <strong>centralized management</strong> of cross-cutting concerns</li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>It introduces <strong>coupling across services</strong></li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Reduces code complexity, replaces with reliable platform features (RE:01)</li>
            <li>üîí <strong>Security</strong> - Centralized security controls (WAF, TLS), enhanced platform security (SE:06, SE:08)</li>
            <li>üí∞ <strong>Cost Optimization</strong> - Redirect costs from per-node to gateway, often cheaper centralized model (CO:14)</li>
            <li>üîß <strong>Operational Excellence</strong> - Single point configuration instead of multiple nodes (OE:04)</li>
            <li>‚ö° <strong>Performance Efficiency</strong> - Fewer resources per-node, optimized centralized functionality (PE:03)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Services:</strong></p>
          <ul>
            <li><strong>Azure Application Gateway</strong> - SSL termination, WAF, authentication offloading</li>
            <li><strong>Azure API Management</strong> - Authentication, rate limiting, protocol transformation, logging</li>
            <li><strong>Azure Front Door</strong> - Global SSL termination, WAF, caching, routing</li>
            <li><strong>Azure Load Balancer</strong> - Basic connection offloading</li>
          </ul>

          <h3>Example: NGINX SSL Offload</h3>
          <pre><code class="language-nginx">upstream iis {
    server  10.3.0.10    max_fails=3    fail_timeout=15s;
    server  10.3.0.20    max_fails=3    fail_timeout=15s;
    server  10.3.0.30    max_fails=3    fail_timeout=15s;
}

server {
    listen 443;
    ssl on;
    ssl_certificate /etc/nginx/ssl/domain.cer;
    ssl_certificate_key /etc/nginx/ssl/domain.key;

    location / {
        set $targ iis;
        proxy_pass http://$targ;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto https;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header Host $host;
    }
}</code></pre>

          <p>
            <strong>Azure Implementation:</strong> On Azure, achieve this by 
            <a href="https://learn.microsoft.com/en-us/azure/application-gateway/tutorial-ssl-cli" target="_blank">setting up SSL termination on Application Gateway</a>.
          </p>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#backends-frontends"><strong>Backends for Frontends</strong></a> - BFF pattern can offload client-specific concerns</li>
            <li>üîó <a href="#gateway-aggregation"><strong>Gateway Aggregation</strong></a> - Combine with aggregation for comprehensive gateway capabilities</li>
            <li>üîó <a href="#gateway-routing"><strong>Gateway Routing</strong></a> - Routing often combined with offloading</li>
          </ul>
        </section>

        <!-- Gateway Routing Pattern -->
        <section id="gateway-routing" role="article">
          <h1>üîÄ Gateway Routing Pattern</h1>
          <span class="badge">design-implementation</span>
          <span class="badge">gateway</span>
          <span class="badge">routing</span>

          <h2>Context and Problem</h2>
          <p>
            When clients need to consume multiple services or multiple instances of services, managing endpoints creates challenges:
          </p>

          <h3>Scenario 1: Multiple Disparate Services</h3>
          <ul>
            <li>E-commerce app provides services: <strong>search, reviews, cart, checkout, order history</strong></li>
            <li>Each service has <strong>different API</strong> and endpoint</li>
            <li>Client must know about <strong>each endpoint</strong> to connect</li>
            <li>If API changes, <strong>client must be updated</strong></li>
            <li>Refactoring a service into two = <strong>code changes in both service and client</strong></li>
          </ul>

          <h3>Scenario 2: Multiple Instances of Same Service</h3>
          <ul>
            <li>Multiple instances for <strong>load balancing</strong> or <strong>availability</strong></li>
            <li>Instances in <strong>same or different regions</strong></li>
            <li>Instance spun up/down to match demand</li>
            <li>Client must be <strong>updated each time</strong></li>
          </ul>

          <h3>Scenario 3: Multiple Versions of Same Service</h3>
          <ul>
            <li><strong>Blue-green deployments</strong> - new version alongside existing</li>
            <li>Client must be updated when <strong>traffic percentage changes</strong></li>
          </ul>

          <h2>Solution</h2>
          <p>
            Place a <strong>gateway in front of services</strong> using <strong>Application Layer 7 routing</strong>. 
            Client only needs to know about and communicate with <strong>single endpoint</strong>.
          </p>

          <div class="callout callout-info">
            <strong>üí° Key Concept:</strong> Gateway routing pattern is useful where service consolidation, decomposition, 
            or replacement happens. Client continues making requests to gateway, only the routing changes.
          </div>

          <h3>Scenario 1: Multiple Disparate Services</h3>
          <div class="mermaid">
graph TB
    Client[Client] --> |Single Endpoint| GW[API Gateway]
    GW --> |Route by URL| Search[Search Service]
    GW --> |Route by URL| Checkout[Checkout Service]
    GW --> |Route by URL| History[Order History Service]
    GW --> |Route by URL| Cart[Cart Service]
    GW --> |Route by URL| Reviews[Reviews Service]
    
    Note1[Client calls gateway.com/search,<br/>gateway.com/checkout, etc.<br/>Gateway routes to appropriate service]
    
    style GW fill:#e1f5fe
    style Note1 fill:#fff3e0
          </div>

          <h3>Scenario 2: Multiple Instances (Multi-Region)</h3>
          <div class="mermaid">
graph TB
    Client[Client] --> GW[API Gateway]
    GW --> |Geode Pattern<br/>Low Latency| R1[Search Service<br/>Region 1]
    GW --> |Geo Routing<br/>High Availability| R2[Search Service<br/>Region 2]
    
    Note2[Gateway routes to nearest region<br/>Automatic failover between regions<br/>Client unaware of instance changes]
    
    style GW fill:#e1f5fe
    style Note2 fill:#e8f5e9
          </div>

          <h3>Scenario 3: Multiple Versions (Blue-Green)</h3>
          <div class="mermaid">
graph TB
    Client[Client] --> GW[API Gateway]
    GW --> |90% Traffic| V1[Search Service<br/>Version 1.0]
    GW --> |10% Traffic| V2[Search Service<br/>Version 1.1]
    
    Note3[Gateway controls traffic split<br/>Gradual rollout via configuration<br/>Quick rollback on issues]
    
    style GW fill:#e1f5fe
    style V2 fill:#c8e6c9
    style Note3 fill:#fff9c4
          </div>

          <h3>Issues and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Single point of failure</strong> - Design for availability requirements with resiliency and fault tolerance</li>
              <li><strong>Bottleneck risk</strong> - Ensure adequate performance to handle load and scale with growth</li>
              <li><strong>Load testing</strong> - Test to ensure no cascading failures for services</li>
              <li><strong>Layer 7 routing</strong> - Based on IP, port, header, or URL</li>
              <li><strong>Global vs Regional</strong> - Azure Front Door (global) vs Application Gateway (regional)</li>
              <li><strong>Public endpoint security</strong> - Consider limiting backend access to gateway only or via private network</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Client needs to <strong>consume multiple services</strong> behind gateway</li>
            <li>Want to <strong>simplify client apps</strong> with single endpoint</li>
            <li>Need to <strong>route externally addressable endpoints to internal virtual endpoints</strong></li>
            <li>Client needs services in <strong>multiple regions</strong> (latency/availability)</li>
            <li>Client needs <strong>variable number of service instances</strong></li>
            <li>Implement <strong>deployment strategy</strong> where clients access multiple versions</li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>Simple application using only <strong>one or two services</strong></li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Routes traffic to healthy nodes only (RE:05, RE:10)</li>
            <li>üîß <strong>Operational Excellence</strong> - Decouples requests from backends, advanced deployment models (OE:04, OE:11)</li>
            <li>‚ö° <strong>Performance Efficiency</strong> - Distributes traffic across nodes for load balancing (PE:05)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Services:</strong></p>
          <ul>
            <li><strong>Azure Application Gateway</strong> - Regional Layer 7 routing, URL path-based routing, multi-site hosting</li>
            <li><strong>Azure Front Door</strong> - Global Layer 7 routing, multi-region traffic management, fast failover</li>
            <li><strong>Azure Traffic Manager</strong> - DNS-based routing, geographic/priority routing</li>
            <li><strong>Azure API Management</strong> - Advanced API routing with policies</li>
          </ul>

          <h3>Example: NGINX Configuration</h3>
          <pre><code class="language-nginx">server {
    listen 80;
    server_name domain.com;

    location /app1 {
        proxy_pass http://10.0.3.10:80;
    }

    location /app2 {
        proxy_pass http://10.0.3.20:80;
    }

    location /app3 {
        proxy_pass http://10.0.3.30:80;
    }
}</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#backends-frontends"><strong>Backends for Frontends</strong></a> - Different routing for different client types</li>
            <li>üîó <a href="#gateway-aggregation"><strong>Gateway Aggregation</strong></a> - Combine routing with aggregation</li>
            <li>üîó <a href="#gateway-offloading"><strong>Gateway Offloading</strong></a> - Combine routing with cross-cutting concern offloading</li>
            <li>üîó <a href="#geode"><strong>Geode</strong></a> - Multi-region active-active deployment for low latency</li>
          </ul>
        </section>

        <!-- Sidecar Pattern -->
        <section id="sidecar" role="article">
          <h1>üèçÔ∏è Sidecar Pattern</h1>
          <span class="badge">design-implementation</span>
          <span class="badge">containers</span>
          <span class="badge">isolation</span>

          <h2>Context and Problem</h2>
          <p>
            Applications often require <strong>related functionality</strong> such as monitoring, logging, configuration, and networking. 
            Two approaches exist, each with trade-offs:
          </p>

          <h3>Tightly Integrated Approach</h3>
          <ul>
            <li>‚úÖ Runs in same process, efficient use of shared resources</li>
            <li>‚ùå Not well isolated - outage in component affects entire application</li>
            <li>‚ùå Must use same language as parent application</li>
            <li>‚ùå Close interdependence between component and application</li>
          </ul>

          <h3>Separate Services Approach</h3>
          <ul>
            <li>‚úÖ Each service can use different languages and technologies</li>
            <li>‚ùå Each component has own dependencies</li>
            <li>‚ùå Requires language-specific libraries for each platform</li>
            <li>‚ùå Adds latency to application</li>
            <li>‚ùå Complex code and dependency management</li>
          </ul>

          <h2>Solution</h2>
          <p>
            <strong>Co-locate a cohesive set of tasks</strong> with the primary application, but place them in their 
            <strong>own process or container</strong>, providing a <strong>homogeneous interface</strong> across languages.
          </p>

          <div class="callout callout-info">
            <strong>üí° Motorcycle Analogy:</strong> On a motorcycle, the sidecar is attached to one motorcycle, and each 
            motorcycle can have its own sidecar. Similarly, a sidecar service shares the fate of its parent application - 
            for each instance of the application, an instance of the sidecar is deployed and hosted alongside it.
          </div>

          <div class="mermaid">
graph LR
    subgraph Pod["Application Pod/Host"]
        App[Primary<br/>Application]
        Sidecar[Sidecar<br/>Service]
    end
    
    App <--> |Shared Resources<br/>Low Latency| Sidecar
    Sidecar --> |Logging| LogSys[Logging System]
    Sidecar --> |Monitoring| MonSys[Monitoring System]
    Sidecar --> |Config| ConfigStore[Config Store]
    
    style Pod fill:#e3f2fd
    style Sidecar fill:#fff3e0
          </div>

          <h3>Advantages</h3>
          <ul>
            <li>‚úÖ <strong>Language independence</strong> - Don't need to develop one sidecar per language</li>
            <li>‚úÖ <strong>Shared resources</strong> - Sidecar can access same resources as primary application</li>
            <li>‚úÖ <strong>Low latency</strong> - Proximity to primary app means no significant communication latency</li>
            <li>‚úÖ <strong>Extensibility</strong> - Can extend functionality even when app doesn't provide extensibility mechanism</li>
            <li>‚úÖ <strong>Isolation</strong> - Runs in own process, failures isolated from main app</li>
          </ul>

          <h3>Issues and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Key Considerations:</strong>
            <ul>
              <li><strong>Deployment format</strong> - Consider packaging format (containers particularly well suited)</li>
              <li><strong>Interprocess communication</strong> - Use language/framework-agnostic technologies unless performance requires otherwise</li>
              <li><strong>Separate service evaluation</strong> - Consider if functionality would work better as separate service or daemon</li>
              <li><strong>Library alternative</strong> - Could functionality be implemented as library or traditional extension?</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Primary app uses <strong>heterogeneous languages and frameworks</strong></li>
            <li>Component <strong>owned by remote team or different organization</strong></li>
            <li>Component must be <strong>co-located on same host</strong> as application</li>
            <li>Need service that <strong>shares lifecycle</strong> but can be independently updated</li>
            <li>Need <strong>fine-grained resource limits</strong> for specific component (e.g., memory management)</li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li><strong>Interprocess communication needs to be optimized</strong> - Latency in calls might not be acceptable</li>
            <li><strong>Small applications</strong> - Resource cost of sidecar per instance isn't worth isolation advantage</li>
            <li>Service needs to <strong>scale differently</strong> than main applications</li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üîí <strong>Security</strong> - Reduces surface area of sensitive processes, adds cross-cutting security controls (SE:04, SE:07)</li>
            <li>üîß <strong>Operational Excellence</strong> - Flexible tool integration without direct dependencies, independent lifecycle (OE:04, OE:07)</li>
            <li>‚ö° <strong>Performance Efficiency</strong> - Single process scales across multiple instances, reduces duplication (PE:07)</li>
          </ul>

          <h3>Common Sidecar Examples</h3>
          <ul>
            <li><strong>Infrastructure API</strong> - Common layer for infrastructure services (logging, config, discovery, health checks)</li>
            <li><strong>Manage NGINX/HAProxy</strong> - Monitor environment, update config, recycle process on state changes</li>
            <li><strong>Ambassador sidecar</strong> - Handle request logging, routing, circuit breaking, connectivity features</li>
            <li><strong>Offload proxy</strong> - Handle static file content serving</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Services Supporting Sidecar:</strong></p>
          <ul>
            <li><strong>Azure Kubernetes Service (AKS)</strong> - Native multi-container pods</li>
            <li><strong>Azure Container Apps</strong> - Sidecar containers in same container app</li>
            <li><strong>Azure Container Instances</strong> - Container groups with multiple containers</li>
            <li><strong>Azure Service Fabric</strong> - Guest executables as sidecars</li>
          </ul>

          <h3>Example: Kubernetes Pod</h3>
          <pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-sidecar
spec:
  containers:
  - name: main-app
    image: myapp:1.0
    ports:
    - containerPort: 8080
  
  - name: logging-sidecar
    image: fluentd:latest
    volumeMounts:
    - name: logs
      mountPath: /var/log/app
  
  volumes:
  - name: logs
    emptyDir: {}</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#ambassador"><strong>Ambassador</strong></a> - Specific type of sidecar for network communication</li>
          </ul>
        </section>

        <!-- Strangler Fig Pattern -->
        <section id="strangler-fig" role="article">
          <h1>üåø Strangler Fig Pattern</h1>
          <span class="badge">design-implementation</span>
          <span class="badge">legacy-migration</span>
          <span class="badge">modernization</span>

          <h2>Context and Problem</h2>
          <p>
            As systems age, their development tools, hosting technology, and architectures become <strong>obsolete</strong>. 
            As new features are added, applications become more <strong>complex and harder to maintain</strong>. However:
          </p>
          <ul>
            <li>‚ùå <strong>Replacing entire complex system</strong> is a huge undertaking</li>
            <li>‚ö†Ô∏è Running <strong>two separate versions</strong> forces clients to track which version has which features</li>
            <li>‚ö†Ô∏è Every feature migration requires <strong>directing clients to new location</strong></li>
            <li>‚ö†Ô∏è Need approach that supports <strong>incremental migration</strong> with minimal client disruption</li>
          </ul>

          <h2>Solution</h2>
          <p>
            Use an <strong>incremental process</strong> to replace specific pieces of functionality with new applications. 
            Customers continue using the <strong>same interface</strong>, unaware of the migration.
          </p>

          <div class="callout callout-info">
            <strong>üí° Pattern Name Origin:</strong> Named after the strangler fig vine that grows around a tree, 
            eventually replacing it. The pattern gradually "strangles" the legacy system.
          </div>

          <h3>Four-Phase Approach</h3>
          <div class="mermaid">
graph TB
    subgraph Phase1["Phase 1: Introduce Fa√ßade"]
        Client1[Client App] --> Facade1[Fa√ßade/Proxy]
        Facade1 --> |Most Requests| Legacy1[Legacy System]
        Facade1 --> |Few Requests| New1[New System]
    end
    
    subgraph Phase2["Phase 2: Incremental Migration"]
        Client2[Client App] --> Facade2[Fa√ßade/Proxy]
        Facade2 --> |Some Requests| Legacy2[Legacy System]
        Facade2 --> |More Requests| New2[New System]
    end
    
    subgraph Phase3["Phase 3: Complete Migration"]
        Client3[Client App] --> Facade3[Fa√ßade/Proxy]
        Facade3 --> |All Requests| New3[New System]
        Legacy3[Legacy System<br/>DECOMMISSIONED]
    end
    
    subgraph Phase4["Phase 4: Remove Fa√ßade"]
        Client4[Client App] --> New4[New System]
        Note4[Direct connection<br/>Migration complete]
    end
    
    Phase1 --> Phase2
    Phase2 --> Phase3
    Phase3 --> Phase4
    
    style Legacy1 fill:#ffebee
    style Legacy2 fill:#ffcdd2
    style Legacy3 fill:#e0e0e0
    style New1 fill:#e8f5e9
    style New2 fill:#c8e6c9
    style New3 fill:#a5d6a7
    style New4 fill:#81c784
          </div>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Controlled and phased</strong> - Incremental approach reduces risks</li>
            <li>‚úÖ <strong>No client changes</strong> - Fa√ßade maintains same interface during migration</li>
            <li>‚úÖ <strong>Flexible pace</strong> - Move at a pace that suits project complexity</li>
            <li>‚úÖ <strong>Stable system</strong> - System remains functional throughout migration</li>
            <li>‚úÖ <strong>Manageable stages</strong> - Address complexities and dependencies incrementally</li>
          </ul>

          <h3>Problems and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Shared resources</strong> - Handle services and data stores used by both systems</li>
              <li><strong>Future-proofing</strong> - Structure new apps so they can be intercepted in future migrations</li>
              <li><strong>Fa√ßade removal</strong> - Typically remove fa√ßade after migration, but can maintain as adapter</li>
              <li><strong>Keep fa√ßade current</strong> - Must keep up with migration progress</li>
              <li><strong>Avoid bottleneck</strong> - Fa√ßade shouldn't become single point of failure or performance bottleneck</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Gradually migrating <strong>back-end to new architecture</strong></li>
            <li>Replacing <strong>large systems, key components, complex features</strong></li>
            <li>Original system can <strong>continue for extended period</strong> during migration</li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li><strong>Requests can't be intercepted</strong> to back-end system</li>
            <li>Migrating a <strong>small system</strong> - replacing whole system is simple</li>
            <li>Need to <strong>fully decommission quickly</strong></li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Incremental approach mitigates risks vs large systemic changes (RE:08)</li>
            <li>üí∞ <strong>Cost Optimization</strong> - Maximize use of existing investments while modernizing incrementally (CO:07, CO:08)</li>
            <li>üîß <strong>Operational Excellence</strong> - Continuous improvement, small changes over time (OE:06, OE:11)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Services for Fa√ßade:</strong></p>
          <ul>
            <li><strong>Azure Application Gateway</strong> - URL path-based routing to legacy vs new systems</li>
            <li><strong>Azure Front Door</strong> - Global routing with rules engine for migration routing</li>
            <li><strong>Azure API Management</strong> - Policy-based routing, version management, traffic splitting</li>
            <li><strong>Azure Traffic Manager</strong> - DNS-based routing for gradual traffic shifting</li>
          </ul>

          <h3>Example: Database Migration</h3>
          <div class="mermaid">
sequenceDiagram
    participant Client
    participant NewSystem
    participant LegacyDB
    participant NewDB
    
    Note over Client,NewDB: Phase 1: New system, legacy DB
    Client->>NewSystem: Request
    NewSystem->>LegacyDB: Read/Write
    
    Note over Client,NewDB: Phase 2: ETL, shadow writes
    Client->>NewSystem: Request
    NewSystem->>LegacyDB: Read
    NewSystem->>NewDB: Shadow Write
    NewSystem->>LegacyDB: Write
    Note over NewDB: Synchronized via ETL
    
    Note over Client,NewDB: Phase 3: New DB active
    Client->>NewSystem: Request
    NewSystem->>NewDB: Read/Write
    Note over LegacyDB: Deprecated
          </div>

          <p><strong>Migration Steps:</strong></p>
          <ol>
            <li>New system introduced, still uses legacy database</li>
            <li>New database introduced, data synchronized via ETL, shadow writes to both DBs</li>
            <li>New database becomes system of record, legacy DB deprecated</li>
          </ol>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#messaging-bridge"><strong>Messaging Bridge</strong></a> - Bridge messaging systems during migration</li>
          </ul>
        </section>

        <!-- External Configuration Store Pattern -->
        <section id="external-config" role="article">
          <h1>‚öôÔ∏è External Configuration Store</h1>
          <div class="badges">
            <span class="badge badge-design">Design & Implementation</span>
            <span class="badge badge-operational">Operational Excellence</span>
          </div>

          <h2>Context & Problem</h2>
          <p>Most application runtime environments include configuration information held in files deployed with the application. It's possible to edit these files to change application behavior after it's deployed, but configuration changes require redeployment, often resulting in unacceptable downtime and administrative overhead.</p>
          
          <p>Local configuration files also limit the configuration to a single application, but sometimes it would be useful to share configuration settings across multiple applications. Configuration stored in environment variables is difficult to manage and is not easy to audit.</p>

          <h2>Solution</h2>
          <p>Store the configuration information in external storage and provide an interface that can be used to quickly and efficiently read and update configuration settings. The type of external store depends on the hosting and runtime environment of the application.</p>

          <div class="mermaid">
graph TB
    App1[Application Instance 1]
    App2[Application Instance 2]
    App3[Application Instance 3]
    ConfigStore[(External Configuration Store)]
    Cache1[Local Cache]
    Cache2[Local Cache]
    Cache3[Local Cache]
    Admin[Configuration Admin]
    
    Admin -->|Update Config| ConfigStore
    ConfigStore -->|Read Config| App1
    ConfigStore -->|Read Config| App2
    ConfigStore -->|Read Config| App3
    App1 -.->|Optional Cache| Cache1
    App2 -.->|Optional Cache| Cache2
    App3 -.->|Optional Cache| Cache3
    
    style ConfigStore fill:#4CAF50
    style Admin fill:#2196F3
    style Cache1 fill:#FFF59D
    style Cache2 fill:#FFF59D
    style Cache3 fill:#FFF59D
          </div>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Centralized management</strong> - Single source of truth for configuration across multiple apps</li>
            <li>‚úÖ <strong>No redeployment</strong> - Update settings without restarting applications</li>
            <li>‚úÖ <strong>Environment-specific</strong> - Easy to manage dev, staging, production configurations</li>
            <li>‚úÖ <strong>Version control</strong> - Track configuration changes over time</li>
            <li>‚úÖ <strong>Shared settings</strong> - Multiple applications can share common configuration</li>
            <li>‚úÖ <strong>Access control</strong> - Centralized security and audit capabilities</li>
          </ul>

          <h3>Problems and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Backing store choice</strong> - Must be accessible, provide acceptable performance, high availability</li>
              <li><strong>Schema flexibility</strong> - Decide on schema enforcement vs. free-form key-value pairs</li>
              <li><strong>Physical capabilities</strong> - Consider size limits, data types, versioning support</li>
              <li><strong>Scope and access control</strong> - Determine who can read/write configurations</li>
              <li><strong>Error handling</strong> - Handle connection failures, use cached or default values</li>
              <li><strong>Protection</strong> - Encrypt sensitive data (connection strings, credentials)</li>
              <li><strong>Change management</strong> - Track changes, implement approval workflows</li>
              <li><strong>Caching strategy</strong> - Use local caching with expiration to reduce latency</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Configuration settings are <strong>shared across multiple applications</strong> and instances</li>
            <li>Need to enforce <strong>standard configurations</strong> across apps</li>
            <li>Configuration store is <strong>complementary</strong> to existing settings mechanisms</li>
            <li>Want to <strong>simplify administration</strong> across multiple apps and environments</li>
            <li>Need <strong>audit trail</strong> for configuration changes</li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>Configuration rarely changes and <strong>local files are sufficient</strong></li>
            <li><strong>Performance requirements</strong> don't allow external store latency</li>
            <li>Configuration contains sensitive data that <strong>cannot be externalized</strong></li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üîß <strong>Operational Excellence</strong> - Environment-specific configuration without code changes (OE:10)</li>
            <li>üîß <strong>Operational Excellence</strong> - Configuration versioning and safe deployment practices (OE:11)</li>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Centralized management reduces configuration drift (RE:07)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure App Configuration</strong> is a managed service for centralizing application settings and feature flags:</p>
          
          <ul>
            <li><strong>Key-value pairs</strong> - Store configuration as key-value pairs with labels</li>
            <li><strong>Namespacing</strong> - Organize settings hierarchically with key prefixes</li>
            <li><strong>Point-in-time snapshots</strong> - Create configuration snapshots for rollback</li>
            <li><strong>Feature management</strong> - Built-in support for feature flags</li>
            <li><strong>Client libraries</strong> - SDKs for .NET, Java Spring, Python, JavaScript/Node.js</li>
            <li><strong>Integration</strong> - Works with Azure Key Vault for sensitive data</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>.NET Example with Custom Storage Implementation:</strong></p>
          <pre><code>// Settings store interface
public interface ISettingsStore
{
    Task&lt;string&gt; GetVersionAsync();
    Task&lt;Dictionary&lt;string, string&gt;&gt; FindAllAsync();
}

// Blob storage implementation
public class BlobSettingsStore : ISettingsStore
{
    private readonly BlobClient blobClient;

    public async Task&lt;string&gt; GetVersionAsync()
    {
        var properties = await blobClient.GetPropertiesAsync();
        return properties.Value.ETag.ToString();
    }

    public async Task&lt;Dictionary&lt;string, string&gt;&gt; FindAllAsync()
    {
        var content = await blobClient.DownloadContentAsync();
        return JsonSerializer.Deserialize&lt;Dictionary&lt;string, string&gt;&gt;(
            content.Value.Content.ToString());
    }
}

// Configuration manager with change notification
public class ExternalConfigurationManager
{
    private readonly ISettingsStore settingsStore;
    private Dictionary&lt;string, string&gt; settings;
    private string currentVersion;

    public ExternalConfigurationManager(ISettingsStore store)
    {
        settingsStore = store;
        LoadSettings();
        
        // Poll for changes every 30 seconds
        Observable.Interval(TimeSpan.FromSeconds(30))
            .Subscribe(_ => CheckForUpdates());
    }

    private async void CheckForUpdates()
    {
        var version = await settingsStore.GetVersionAsync();
        if (version != currentVersion)
        {
            await LoadSettings();
            OnSettingsChanged?.Invoke(this, EventArgs.Empty);
        }
    }

    public event EventHandler OnSettingsChanged;
}</code></pre>

          <p><strong>Azure App Configuration Example:</strong></p>
          <pre><code>// Install: Azure.Data.AppConfiguration
var client = new ConfigurationClient(connectionString);

// Set configuration
await client.SetConfigurationSettingAsync("AppSettings:MaxRetries", "3");
await client.SetConfigurationSettingAsync(
    "ConnectionStrings:Database", 
    keyVaultReference, 
    label: "Production");

// Get configuration
var setting = await client.GetConfigurationSettingAsync("AppSettings:MaxRetries");
Console.WriteLine($"Max Retries: {setting.Value.Value}");

// Use in ASP.NET Core
builder.Configuration.AddAzureAppConfiguration(options =>
{
    options.Connect(connectionString)
        .ConfigureRefresh(refresh =>
        {
            refresh.Register("AppSettings:Sentinel", refreshAll: true)
                .SetCacheExpiration(TimeSpan.FromMinutes(5));
        })
        .UseFeatureFlags();
});</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#valet-key"><strong>Valet Key</strong></a> - Grant limited access to configuration store</li>
            <li>üîó <strong>Runtime Reconfiguration</strong> - Update configuration without restart</li>
          </ul>
        </section>

        <!-- Leader Election Pattern -->
        <section id="leader-election" role="article">
          <h1>üëë Leader Election</h1>
          <div class="badges">
            <span class="badge badge-design">Design & Implementation</span>
            <span class="badge badge-reliability">Reliability</span>
          </div>

          <h2>Context & Problem</h2>
          <p>A distributed application has multiple instances running, and each instance is capable of doing the same work. However, sometimes one instance needs to coordinate the actions of the others or access shared resources that could become bottlenecks.</p>
          
          <p>The instances are peers and there is no natural leader that can be assigned the role of coordinator. If all instances try to coordinate work, race conditions and resource contention can occur.</p>

          <h2>Solution</h2>
          <p>A single task instance should be elected to act as the leader, and this instance should coordinate the actions of the other subordinate task instances. If all of the task instances are running the same code, they are each capable of acting as the leader.</p>

          <div class="mermaid">
sequenceDiagram
    participant I1 as Instance 1
    participant I2 as Instance 2
    participant I3 as Instance 3
    participant Lock as Distributed Lock
    participant Resource as Shared Resource
    
    Note over I1,Resource: Election Phase
    I1->>Lock: Try Acquire
    I2->>Lock: Try Acquire
    I3->>Lock: Try Acquire
    Lock-->>I1: ‚úì Acquired (Leader)
    Lock-->>I2: ‚úó Failed
    Lock-->>I3: ‚úó Failed
    
    Note over I1,Resource: Leadership Phase
    I1->>Resource: Coordinate Work
    I1->>I2: Send Tasks
    I1->>I3: Send Tasks
    I2->>Resource: Execute Task
    I3->>Resource: Execute Task
    
    Note over I1,Resource: Leader Renewal
    I1->>Lock: Renew Lease
    Lock-->>I1: ‚úì Renewed
    
    Note over I1,Resource: Leader Failure
    I1-xI1: Crashes
    Lock->>Lock: Lease Expires
    I2->>Lock: Try Acquire
    Lock-->>I2: ‚úì Acquired (New Leader)
          </div>

          <h3>Election Strategies</h3>
          <ul>
            <li><strong>Racing for distributed mutex</strong> - First instance to acquire lock becomes leader</li>
            <li><strong>Bully Algorithm</strong> - Highest priority instance becomes leader</li>
            <li><strong>Raft Consensus</strong> - Majority vote determines leader with term-based leadership</li>
            <li><strong>Ring Algorithm</strong> - Token passing in logical ring structure</li>
          </ul>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Single coordinator</strong> - One instance manages shared resources or orchestration</li>
            <li>‚úÖ <strong>Prevents conflicts</strong> - Eliminates race conditions and resource contention</li>
            <li>‚úÖ <strong>Automatic failover</strong> - New leader elected if current leader fails</li>
            <li>‚úÖ <strong>Dynamic scaling</strong> - Works with horizontal scaling and instance changes</li>
            <li>‚úÖ <strong>No hard-coding</strong> - Leader is elected dynamically, not configured statically</li>
          </ul>

          <h3>Problems and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Resilience to failures</strong> - Election mechanism must be robust and handle leader crashes</li>
              <li><strong>Detection timing</strong> - Balance between fast detection and avoiding false positives</li>
              <li><strong>Autoscaling termination</strong> - Handle graceful shutdown when leader is terminated</li>
              <li><strong>External service dependency</strong> - Election mechanism relies on external coordination service</li>
              <li><strong>Dedicated process consideration</strong> - Separate election from business logic when appropriate</li>
              <li><strong>Bottleneck avoidance</strong> - Leader shouldn't become single point of failure for performance</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Tasks in distributed application need <strong>careful coordination</strong></li>
            <li>There is <strong>no natural leader</strong> among task instances</li>
            <li>Need to manage <strong>shared resources</strong> or singleton operations</li>
            <li>Implementing <strong>distributed workflows</strong> requiring orchestration</li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>There is a <strong>natural leader</strong> that can always act as coordinator</li>
            <li><strong>Lightweight coordination</strong> via locks or semaphores is sufficient</li>
            <li>Third-party solution like <strong>Apache Zookeeper</strong> is more appropriate</li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Mitigates single node malfunction through consensus (RE:05)</li>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Automatic failover to new leader ensures continuity (RE:07)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Blob Lease Mechanism:</strong> Use blob leases as a distributed lock for leader election.</p>
          
          <ul>
            <li><strong>Blob lease</strong> - Acquire exclusive lease on a blob (15-60 seconds or infinite)</li>
            <li><strong>Automatic expiration</strong> - Lease expires if not renewed, enabling re-election</li>
            <li><strong>Lease ID</strong> - Unique identifier proves leadership</li>
            <li><strong>Renewal loop</strong> - Leader periodically renews lease to maintain leadership</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>Distributed Mutex with Blob Lease:</strong></p>
          <pre><code>public class BlobDistributedMutex
{
    private readonly BlobClient blobClient;
    private BlobLease currentLease;
    private CancellationTokenSource renewalCts;

    public BlobDistributedMutex(string connectionString, string blobName)
    {
        var client = new BlobServiceClient(connectionString);
        var container = client.GetBlobContainerClient("leases");
        container.CreateIfNotExists();
        blobClient = container.GetBlobClient(blobName);
        
        // Ensure blob exists
        if (!blobClient.Exists())
        {
            blobClient.Upload(new BinaryData(""));
        }
    }

    public async Task&lt;bool&gt; RunTaskWhenMutexAcquired(
        Func&lt;CancellationToken, Task&gt; task, 
        CancellationToken cancellationToken)
    {
        try
        {
            // Try to acquire lease (become leader)
            var leaseClient = blobClient.GetBlobLeaseClient();
            currentLease = await leaseClient.AcquireAsync(
                TimeSpan.FromSeconds(15), 
                cancellationToken: cancellationToken);

            // Start lease renewal in background
            renewalCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);
            _ = KeepRenewingLease(leaseClient, renewalCts.Token);

            // Run the leader task
            await task(cancellationToken);

            return true;
        }
        catch (RequestFailedException ex) when (ex.Status == 409)
        {
            // Another instance holds the lease
            return false;
        }
        finally
        {
            // Release lease when done
            renewalCts?.Cancel();
            if (currentLease != null)
            {
                await blobClient.GetBlobLeaseClient(currentLease.LeaseId)
                    .ReleaseAsync();
            }
        }
    }

    private async Task KeepRenewingLease(
        BlobLeaseClient leaseClient, 
        CancellationToken cancellationToken)
    {
        while (!cancellationToken.IsCancellationRequested)
        {
            await Task.Delay(TimeSpan.FromSeconds(10), cancellationToken);
            
            try
            {
                await leaseClient.RenewAsync(cancellationToken: cancellationToken);
            }
            catch (Exception ex)
            {
                // Log error and exit - will cause leader task to stop
                Console.WriteLine($"Failed to renew lease: {ex.Message}");
                throw;
            }
        }
    }
}

// Usage in conference management system
var mutex = new BlobDistributedMutex(
    connectionString, 
    "MyLeaderCoordinatorTask");

while (!cancellationToken.IsCancellationRequested)
{
    var isLeader = await mutex.RunTaskWhenMutexAcquired(async (ct) =>
    {
        Console.WriteLine("I am the leader!");
        
        // Coordinate other instances
        await CoordinateWorkAsync(ct);
        
        // Leader work continues until cancelled or lease lost
        await Task.Delay(Timeout.Infinite, ct);
    }, cancellationToken);

    if (!isLeader)
    {
        Console.WriteLine("Another instance is the leader.");
        await Task.Delay(TimeSpan.FromSeconds(30), cancellationToken);
    }
}</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#scheduler-agent"><strong>Scheduler Agent Supervisor</strong></a> - Coordinate distributed workflows</li>
            <li>üîó <a href="#competing-consumers"><strong>Competing Consumers</strong></a> - Distribute work across instances</li>
          </ul>
        </section>

        <!-- Static Content Hosting Pattern -->
        <section id="static-content" role="article">
          <h1>üì¶ Static Content Hosting</h1>
          <div class="badges">
            <span class="badge badge-design">Design & Implementation</span>
            <span class="badge badge-performance">Performance</span>
            <span class="badge badge-cost">Cost Optimization</span>
          </div>

          <h2>Context & Problem</h2>
          <p>Web applications typically include some elements of static content such as HTML pages, images, stylesheets, client-side scripts, and documents. These static resources must be served to clients along with dynamic content.</p>
          
          <p>Web servers are optimized for dynamic rendering, but they must also handle requests for static content. This consumes processing cycles that could be better used handling dynamic requests.</p>

          <h2>Solution</h2>
          <p>Deploy the static content to a storage service that can deliver them directly to the client. This can reduce the need for expensive compute instances and offload static content serving to a cost-effective storage solution.</p>

          <div class="mermaid">
graph TB
    Client[Web Browser]
    AppService[Web App<br/>Compute Service]
    Storage[(Static Content<br/>Storage Service)]
    CDN[Content Delivery Network]
    
    Client -->|1. Request page| AppService
    AppService -->|2. Return HTML with<br/>storage URLs| Client
    Client -->|3. Request CSS/JS/Images| CDN
    CDN -->|4. Fetch if not cached| Storage
    Storage -->|5. Return content| CDN
    CDN -->|6. Return content| Client
    
    style Storage fill:#4CAF50
    style CDN fill:#2196F3
    style AppService fill:#FF9800
    
    Note1[Dynamic Content]
    Note2[Static Assets]
    Note1 -.-> AppService
    Note2 -.-> Storage
          </div>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Reduced hosting costs</strong> - Storage is cheaper than compute instances</li>
            <li>‚úÖ <strong>Offload processing</strong> - Free compute resources for dynamic content</li>
            <li>‚úÖ <strong>Global performance</strong> - Combine with CDN for worldwide low latency</li>
            <li>‚úÖ <strong>Scalability</strong> - Storage services handle massive concurrent requests</li>
            <li>‚úÖ <strong>Availability</strong> - Storage services offer high durability and redundancy</li>
            <li>‚úÖ <strong>Simplified deployment</strong> - Deploy static content independently of application</li>
          </ul>

          <h3>Problems and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>HTTP/HTTPS endpoint</strong> - Storage service must expose content via web protocols</li>
              <li><strong>CDN integration</strong> - Use CDN to minimize latency for geographically distributed users</li>
              <li><strong>Geo-replication</strong> - Replicate storage across regions for high availability</li>
              <li><strong>Deployment complexity</strong> - Coordinate deployment of dynamic code and static content</li>
              <li><strong>Custom domain limitations</strong> - May require CNAME or CDN for custom domains</li>
              <li><strong>Public access</strong> - Content is public by default, use signed URLs for private content</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Minimize hosting costs for sites with <strong>large amounts of static content</strong></li>
            <li>Host <strong>static-only websites</strong> (blogs, documentation, portfolios)</li>
            <li>Expose <strong>static resources</strong> (downloads, media files) for other applications</li>
            <li>Serve content to <strong>multiple geographic locations</strong> efficiently</li>
            <li>Monitor and control <strong>costs separately</strong> for compute vs storage</li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>Static content requires <strong>processing before delivery</strong> (resizing, transformation)</li>
            <li>Volume of static content is <strong>very small</strong> - simplicity favors single deployment</li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üí∞ <strong>Cost Optimization</strong> - Storage is significantly cheaper than compute (CO:09)</li>
            <li>üí∞ <strong>Cost Optimization</strong> - Optimize data storage costs with appropriate tiers (CO:10)</li>
            <li>‚ö° <strong>Performance Efficiency</strong> - Offload from application platform improves scalability (PE:07)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Storage Static Website Hosting:</strong></p>
          
          <ul>
            <li><strong>Built-in web server</strong> - Blob storage exposes static content via HTTP/HTTPS</li>
            <li><strong>Custom domain</strong> - CNAME to storage endpoint or use Azure CDN</li>
            <li><strong>Index document</strong> - Configure default document (index.html)</li>
            <li><strong>Error document</strong> - Custom 404 page support</li>
            <li><strong>Azure CDN integration</strong> - Enable CDN for global distribution and caching</li>
            <li><strong>Shared access signatures</strong> - Generate temporary URLs for private content</li>
            <li><strong>User delegation SAS</strong> - Use Azure AD credentials for enhanced security</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>ASP.NET Core Helper for Static Content URLs:</strong></p>
          <pre><code>public static class StaticContentUrlHtmlHelper
{
    public static string StaticContentUrl(
        this IHtmlHelper helper, 
        string contentPath)
    {
        if (contentPath.StartsWith("~"))
        {
            contentPath = contentPath.Substring(1);
        }

        var configuration = helper.ViewContext.HttpContext
            .RequestServices.GetService&lt;IConfiguration&gt;();
        
        var storageAccountUrl = configuration["StaticContent:StorageAccountUrl"];
        
        return $"{storageAccountUrl}{contentPath}";
    }
}

// In appsettings.json
{
  "StaticContent": {
    "StorageAccountUrl": "https://myaccount.blob.core.windows.net/static"
  }
}

// Usage in Razor view
&lt;img src="@Html.StaticContentUrl("~/images/logo.png")" alt="Logo" /&gt;
&lt;link rel="stylesheet" href="@Html.StaticContentUrl("~/css/site.css")" /&gt;</code></pre>

          <p><strong>Enable Static Website Hosting (Azure CLI):</strong></p>
          <pre><code># Enable static website hosting
az storage blob service-properties update \
    --account-name mystorageaccount \
    --static-website \
    --index-document index.html \
    --404-document 404.html

# Get the static website URL
az storage account show \
    --name mystorageaccount \
    --query "primaryEndpoints.web" \
    --output tsv

# Upload content
az storage blob upload-batch \
    --account-name mystorageaccount \
    --source ./dist \
    --destination '$web' \
    --pattern "*"

# Enable CDN
az cdn endpoint create \
    --resource-group myResourceGroup \
    --profile-name myCDNProfile \
    --name myEndpoint \
    --origin mystorageaccount.z13.web.core.windows.net \
    --origin-host-header mystorageaccount.z13.web.core.windows.net</code></pre>

          <p><strong>Generate Shared Access Signature for Private Content:</strong></p>
          <pre><code>var blobClient = new BlobClient(connectionString, containerName, blobName);

// Generate SAS token valid for 1 hour
var sasBuilder = new BlobSasBuilder
{
    BlobContainerName = containerName,
    BlobName = blobName,
    Resource = "b", // Blob
    StartsOn = DateTimeOffset.UtcNow,
    ExpiresOn = DateTimeOffset.UtcNow.AddHours(1)
};

sasBuilder.SetPermissions(BlobSasPermissions.Read);

var sasToken = blobClient.GenerateSasUri(sasBuilder);
Console.WriteLine($"SAS URL: {sasToken}");</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#cache-aside"><strong>Cache-Aside</strong></a> - Cache frequently accessed static content</li>
            <li>üîó <a href="#valet-key"><strong>Valet Key</strong></a> - Provide direct access to specific resources</li>
            <li>üîó <a href="#gateway-offloading"><strong>Gateway Offloading</strong></a> - Offload functionality to a gateway proxy</li>
          </ul>
        </section>

        <!-- Throttling Pattern -->
        <section id="throttling" role="article">
          <h1>üö¶ Throttling</h1>
          <div class="badges">
            <span class="badge badge-performance">Performance</span>
            <span class="badge badge-reliability">Reliability</span>
            <span class="badge badge-cost">Cost Optimization</span>
          </div>

          <h2>Context & Problem</h2>
          <p>The load on a cloud application typically varies over time based on the number of active users or the types of activities they're performing. There might be peak times when many users are active, or there might be expensive computational operations that compete for the same shared resources.</p>
          
          <p>If the system doesn't have capacity to handle this load, it can suffer poor performance, fail to meet SLAs, or fail completely. While autoscaling can add resources, it's not instantaneous. During the time it takes to start additional resources, the system could be overwhelmed.</p>

          <h2>Solution</h2>
          <p>An alternative strategy to autoscaling is to allow applications to use resources only up to a limit, and then throttle them when this limit is reached. The system should monitor how it's using resources so that, when usage exceeds the threshold, it can throttle requests from one or more users.</p>

          <div class="mermaid">
graph TB
    subgraph "System Capacity"
    T1[Time T1<br/>Threshold Reached]
    T2[Time T2<br/>Capacity Available]
    end
    
    FeatureA[Feature A]
    FeatureB[Feature B - Throttled]
    FeatureC[Feature C]
    Capacity[Resource Capacity]
    
    FeatureA -->|Normal Load| Capacity
    FeatureB -->|Temporarily Disabled T1-T2| Capacity
    FeatureC -->|Normal Load| Capacity
    
    T1 -.->|Threshold Exceeded| FeatureB
    T2 -.->|Restored| FeatureB
    
    style FeatureB fill:#ffcdd2
    style Capacity fill:#4CAF50
    style T1 fill:#FFC107
    style T2 fill:#4CAF50
          </div>

          <h3>Throttling Strategies</h3>
          <ul>
            <li><strong>Reject requests</strong> - Return error to user (HTTP 429 Too Many Requests)</li>
            <li><strong>Disable or degrade non-essential services</strong> - Turn off lower priority features temporarily</li>
            <li><strong>Use Queue-Based Load Leveling</strong> - Buffer requests to smooth out spikes</li>
            <li><strong>Defer operations for specific tenants</strong> - Prioritize premium customers over free tier</li>
            <li><strong>Protect 3rd-party services</strong> - Respect rate limits of external APIs</li>
          </ul>

          <h3>Combining with Autoscaling</h3>
          <p>Throttling can be used as a temporary measure while the system autoscales:</p>
          <ul>
            <li>Apply <strong>soft throttling limits</strong> when scaling out begins</li>
            <li>Prevents system failure during scale-out delay</li>
            <li><strong>Relax throttling</strong> as additional resources become available</li>
            <li>Hard limits remain as absolute protection against overload</li>
          </ul>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Maintain SLAs</strong> - Ensure system stays within service level targets</li>
            <li>‚úÖ <strong>Prevent resource exhaustion</strong> - Protect system from being overwhelmed</li>
            <li>‚úÖ <strong>Control costs</strong> - Cap maximum resource consumption</li>
            <li>‚úÖ <strong>Fair resource allocation</strong> - Prevent one tenant from monopolizing resources</li>
            <li>‚úÖ <strong>Graceful degradation</strong> - System continues functioning under load</li>
          </ul>

          <h3>Problems and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Architectural decision</strong> - Must be designed into the system from the start</li>
              <li><strong>Performance overhead</strong> - Throttling logic must be fast, not add significant latency</li>
              <li><strong>Error codes</strong> - Use HTTP 429 (Too Many Requests) or 503 (Service Unavailable) with Retry-After header</li>
              <li><strong>Temporary measure</strong> - Should complement but not replace autoscaling</li>
              <li><strong>Normalize operation costs</strong> - Expensive operations should count more against limits</li>
              <li><strong>Dynamic configuration</strong> - Use External Configuration Store for threshold adjustments</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Ensure system continues to <strong>meet service level agreements</strong></li>
            <li>Prevent a single tenant from <strong>monopolizing resources</strong> in multi-tenant system</li>
            <li>Handle <strong>bursts of activity</strong> gracefully</li>
            <li>Optimize costs by setting <strong>upper bounds on resource utilization</strong></li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>Few users or applications access the system (low contention)</li>
            <li>System has <strong>excess capacity</strong> most of the time</li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Prevent resource exhaustion through self-preservation (RE:07)</li>
            <li>üîí <strong>Security</strong> - Protect against automated attacks and abuse (SE:06, SE:08)</li>
            <li>üí∞ <strong>Cost Optimization</strong> - Define cost model and set upper bounds on utilization (CO:02, CO:12)</li>
            <li>‚ö° <strong>Performance Efficiency</strong> - Capacity planning and scaling strategy (PE:02, PE:05)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure API Management - Rate Limiting:</strong></p>
          <ul>
            <li><strong>rate-limit policy</strong> - Limit calls per subscription per period</li>
            <li><strong>rate-limit-by-key</strong> - Throttle by custom key (user ID, IP address)</li>
            <li><strong>quota</strong> - Renewable bandwidth/call quotas per period</li>
            <li><strong>quota-by-key</strong> - Per-key renewable quotas</li>
          </ul>

          <p><strong>Azure Front Door - Rate Limiting:</strong></p>
          <ul>
            <li><strong>WAF rate limit rules</strong> - Block requests exceeding threshold per client IP</li>
            <li><strong>Custom rules</strong> - Match conditions with rate limit actions</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>Multi-Tenant Survey Application with Rate Limiting:</strong></p>
          <pre><code>public class RateLimitingMiddleware
{
    private readonly RequestDelegate next;
    private readonly IDistributedCache cache;
    private readonly IConfiguration config;

    public async Task InvokeAsync(HttpContext context)
    {
        var tenantId = context.User.FindFirst("tenantId")?.Value;
        if (string.IsNullOrEmpty(tenantId))
        {
            await next(context);
            return;
        }

        // Get rate limit for this tenant (requests per minute)
        var rateLimit = config.GetValue&lt;int&gt;($"RateLimits:{tenantId}", 100);
        var cacheKey = $"ratelimit:{tenantId}:{DateTime.UtcNow:yyyyMMddHHmm}";

        // Increment request counter
        var currentCount = await cache.GetStringAsync(cacheKey);
        var count = string.IsNullOrEmpty(currentCount) ? 1 : int.Parse(currentCount) + 1;

        if (count > rateLimit)
        {
            context.Response.StatusCode = 429; // Too Many Requests
            context.Response.Headers["Retry-After"] = "60";
            await context.Response.WriteAsync("Rate limit exceeded. Please try again later.");
            return;
        }

        // Update counter with 1 minute expiration
        await cache.SetStringAsync(
            cacheKey, 
            count.ToString(), 
            new DistributedCacheEntryOptions 
            { 
                AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(1) 
            });

        await next(context);
    }
}

// Azure API Management Policy Example
&lt;policies&gt;
    &lt;inbound&gt;
        &lt;!-- Rate limit by subscription key: 100 calls per minute --&gt;
        &lt;rate-limit calls="100" renewal-period="60" /&gt;
        
        &lt;!-- Rate limit by user ID: 1000 calls per hour --&gt;
        &lt;rate-limit-by-key calls="1000" 
                           renewal-period="3600" 
                           counter-key="@(context.Request.Headers.GetValueOrDefault("user-id",""))" /&gt;
        
        &lt;!-- Quota: 10000 calls per month --&gt;
        &lt;quota calls="10000" renewal-period="2592000" /&gt;
    &lt;/inbound&gt;
&lt;/policies&gt;</code></pre>

          <p><strong>Instrumentation and Monitoring:</strong></p>
          <pre><code>// Log throttling events for monitoring
public class ThrottlingTelemetry
{
    private readonly TelemetryClient telemetry;

    public void TrackThrottled(string tenantId, string endpoint)
    {
        var properties = new Dictionary&lt;string, string&gt;
        {
            { "TenantId", tenantId },
            { "Endpoint", endpoint },
            { "Action", "Throttled" }
        };

        telemetry.TrackEvent("RateLimitExceeded", properties);
        
        // Also track as metric for dashboards
        telemetry.GetMetric("ThrottledRequests", "TenantId")
            .TrackValue(1, tenantId);
    }
}</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#queue-load-leveling"><strong>Queue-Based Load Leveling</strong></a> - Buffer requests during spikes</li>
            <li>üîó <a href="#external-config"><strong>External Configuration Store</strong></a> - Dynamically adjust throttling thresholds</li>
            <li>üîó <a href="#priority-queue"><strong>Priority Queue</strong></a> - Process requests based on priority</li>
          </ul>
        </section>

        <!-- Messaging Bridge Pattern -->
        <section id="messaging-bridge" role="article">
          <h1>üåâ Messaging Bridge</h1>
          <div class="badges">
            <span class="badge badge-messaging">Messaging</span>
            <span class="badge badge-operational">Operational Excellence</span>
          </div>

          <h2>Context & Problem</h2>
          <p>Organizations often have multiple messaging infrastructures in place, whether due to mergers and acquisitions, a mixture of on-premises and cloud systems, or different technology choices made over time. Examples include MSMQ, RabbitMQ, Azure Service Bus, Amazon SQS, and others.</p>
          
          <p>Integrating these systems typically requires building HTTP-based APIs or webhooks, which involves modifying the existing applications. This approach adds complexity, requires hosting HTTP endpoints, and may face challenges with network connectivity and security.</p>

          <h2>Solution</h2>
          <p>Use a messaging bridge component that connects to multiple messaging infrastructures simultaneously. The bridge pulls messages from one messaging system and pushes them to another without changing the message payload. This enables integration without modifying the source or target applications.</p>

          <div class="mermaid">
graph LR
    subgraph "On-Premises"
    App1[Legacy App<br/>.NET with MSMQ]
    MSMQ[(MSMQ Queue)]
    end
    
    subgraph "Bridge Layer"
    Bridge[Messaging Bridge<br/>Component]
    end
    
    subgraph "Azure Cloud"
    ServiceBus[(Service Bus Queue)]
    App2[Cloud App<br/>Azure Functions]
    end
    
    App1 -->|Send| MSMQ
    MSMQ -->|Pull| Bridge
    Bridge -->|Push| ServiceBus
    ServiceBus -->|Receive| App2
    
    App2 -->|Send| ServiceBus
    ServiceBus -->|Pull| Bridge
    Bridge -->|Push| MSMQ
    MSMQ -->|Receive| App1
    
    style Bridge fill:#4CAF50
    style MSMQ fill:#FF9800
    style ServiceBus fill:#2196F3
          </div>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>No system modification</strong> - Existing applications remain unchanged</li>
            <li>‚úÖ <strong>More reliable than HTTP</strong> - Leverages at-least-once delivery guarantees</li>
            <li>‚úÖ <strong>Network resilience</strong> - Handles intermittent connectivity better than synchronous calls</li>
            <li>‚úÖ <strong>Flexible migration</strong> - Gradual transition from one messaging system to another</li>
            <li>‚úÖ <strong>Technology independence</strong> - Systems unaware they're communicating across different platforms</li>
          </ul>

          <h3>Drawbacks</h3>
          <ul>
            <li>‚ùå <strong>Feature limitations</strong> - Advanced features of one system may not be available in the other</li>
            <li>‚ùå <strong>Size constraints</strong> - Limited by minimum max message size across both systems</li>
            <li>‚ùå <strong>Additional component</strong> - Bridge must be deployed, monitored, and maintained</li>
          </ul>

          <h3>Problems and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Distributed transactions</strong> - Can't guarantee exactly-once delivery; implement deduplication logic</li>
              <li><strong>Legacy system integration</strong> - May need to emulate queues using SQL Server change data capture</li>
              <li><strong>Queue topology</strong> - Single queue on both sides or multiple queues with routing</li>
              <li><strong>Scale out</strong> - Use Competing Consumers pattern for multiple bridge instances</li>
              <li><strong>Retry policy</strong> - Different from regular components; use Circuit Breaker for external systems</li>
              <li><strong>Poison messages</strong> - Handle messages that repeatedly fail processing</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Need to integrate systems with <strong>minimal modification</strong></li>
            <li>Connecting <strong>legacy on-premises</strong> applications with cloud services</li>
            <li>Working with systems that have <strong>unstable or unreliable internet connectivity</strong></li>
            <li>Performing <strong>incremental migration</strong> from one messaging platform to another</li>
            <li>Both systems already use <strong>asynchronous messaging</strong></li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>Source or target systems <strong>depend on advanced features</strong> not available in both platforms</li>
            <li>Need <strong>synchronous communication</strong> with immediate responses</li>
            <li>Messages contain sensitive data requiring <strong>specific security or privacy controls</strong></li>
            <li>Message volume or latency requirements make bridge <strong>cost-prohibitive</strong></li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üí∞ <strong>Cost Optimization</strong> - Extend system longevity without rewrites (CO:07)</li>
            <li>üîß <strong>Operational Excellence</strong> - Flexibility to work with heterogeneous systems (OE:06)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Bridge Component Options:</strong></p>
          <ul>
            <li><strong>Azure Functions</strong> - Serverless bridge with timer or queue triggers</li>
            <li><strong>Azure Container Apps</strong> - Containerized bridge with KEDA scaling</li>
            <li><strong>Azure Logic Apps</strong> - Low-code integration workflows</li>
            <li><strong>Custom service</strong> - Hosted in App Service or AKS</li>
          </ul>

          <p><strong>On-Premises Connectivity:</strong></p>
          <ul>
            <li><strong>Azure Hybrid Connections</strong> - Secure tunnel without VPN</li>
            <li><strong>VPN Gateway</strong> - Site-to-site or point-to-site VPN</li>
            <li><strong>ExpressRoute</strong> - Private dedicated connection</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>MSMQ to Azure Service Bus Bridge (C#):</strong></p>
          <pre><code>public class MessagingBridge
{
    private readonly MessageQueue msmqQueue;
    private readonly ServiceBusClient serviceBusClient;
    private readonly ServiceBusSender sender;
    private readonly CancellationToken cancellationToken;

    public MessagingBridge(
        string msmqPath, 
        string serviceBusConnection, 
        string queueName,
        CancellationToken ct)
    {
        msmqQueue = new MessageQueue(msmqPath);
        msmqQueue.Formatter = new XmlMessageFormatter(new[] { typeof(string) });
        
        serviceBusClient = new ServiceBusClient(serviceBusConnection);
        sender = serviceBusClient.CreateSender(queueName);
        cancellationToken = ct;
    }

    public async Task RunAsync()
    {
        while (!cancellationToken.IsCancellationRequested)
        {
            try
            {
                // Pull from MSMQ (with timeout)
                var msmqMessage = msmqQueue.Receive(TimeSpan.FromSeconds(5));
                
                if (msmqMessage != null)
                {
                    var body = msmqMessage.Body as string;
                    
                    // Push to Service Bus
                    var sbMessage = new ServiceBusMessage(body)
                    {
                        MessageId = msmqMessage.Id,
                        CorrelationId = msmqMessage.CorrelationId,
                        ContentType = "application/json"
                    };
                    
                    await sender.SendMessageAsync(sbMessage, cancellationToken);
                    
                    // Remove from MSMQ after successful send
                    // (Message already removed by Receive)
                    Console.WriteLine($"Bridged message: {msmqMessage.Id}");
                }
            }
            catch (MessageQueueException ex) when (ex.MessageQueueErrorCode == 
                MessageQueueErrorCode.IOTimeout)
            {
                // No messages available, continue polling
            }
            catch (Exception ex)
            {
                Console.WriteLine($"Error bridging message: {ex.Message}");
                await Task.Delay(TimeSpan.FromSeconds(5), cancellationToken);
            }
        }
    }
}

// Reverse direction: Service Bus to MSMQ
public class ReverseMessagingBridge
{
    private readonly MessageQueue msmqQueue;
    private readonly ServiceBusProcessor processor;

    public ReverseMessagingBridge(
        string msmqPath, 
        string serviceBusConnection, 
        string queueName)
    {
        msmqQueue = new MessageQueue(msmqPath);
        
        var client = new ServiceBusClient(serviceBusConnection);
        processor = client.CreateProcessor(queueName, new ServiceBusProcessorOptions
        {
            MaxConcurrentCalls = 1,
            AutoCompleteMessages = false
        });
        
        processor.ProcessMessageAsync += ProcessMessageAsync;
        processor.ProcessErrorAsync += ProcessErrorAsync;
    }

    private async Task ProcessMessageAsync(ProcessMessageEventArgs args)
    {
        try
        {
            var body = args.Message.Body.ToString();
            
            // Send to MSMQ
            var msmqMessage = new Message(body)
            {
                Label = args.Message.MessageId,
                Recoverable = true
            };
            
            msmqQueue.Send(msmqMessage);
            
            // Complete the Service Bus message
            await args.CompleteMessageAsync(args.Message);
            
            Console.WriteLine($"Bridged message: {args.Message.MessageId}");
        }
        catch (Exception ex)
        {
            Console.WriteLine($"Error: {ex.Message}");
            // Message will be retried or moved to dead letter queue
        }
    }

    private Task ProcessErrorAsync(ProcessErrorEventArgs args)
    {
        Console.WriteLine($"Error: {args.Exception.Message}");
        return Task.CompletedTask;
    }

    public async Task StartAsync() => await processor.StartProcessingAsync();
    public async Task StopAsync() => await processor.StopProcessingAsync();
}</code></pre>

          <p><strong>Deployment as Azure Function:</strong></p>
          <pre><code>[FunctionName("MsmqToServiceBusBridge")]
public async Task Run(
    [TimerTrigger("*/30 * * * * *")] TimerInfo timer,
    ILogger log)
{
    // Runs every 30 seconds
    var bridge = new MessagingBridge(
        msmqPath: "FormatName:Direct=OS:server\\private$\\myqueue",
        serviceBusConnection: Environment.GetEnvironmentVariable("ServiceBusConnection"),
        queueName: "cloudqueue",
        ct: CancellationToken.None);
    
    await bridge.RunAsync();
}</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#competing-consumers"><strong>Competing Consumers</strong></a> - Scale out bridge with multiple instances</li>
            <li>üîó <a href="#circuit-breaker"><strong>Circuit Breaker</strong></a> - Handle external system failures gracefully</li>
            <li>üîó <a href="#claim-check"><strong>Claim Check</strong></a> - Handle large messages by storing in external storage</li>
          </ul>
        </section>

        <!-- Pipes and Filters Pattern -->
        <section id="pipes-filters" role="article">
          <h1>üîß Pipes and Filters</h1>
          <div class="badges">
            <span class="badge badge-messaging">Messaging</span>
            <span class="badge badge-reliability">Reliability</span>
          </div>

          <h2>Context & Problem</h2>
          <p>An application needs to perform a variety of tasks of varying complexity on the information that it processes. A straightforward but inflexible approach is to implement this processing as a monolithic module. However, this approach is likely to reduce the opportunities for refactoring, optimizing, or reusing code.</p>
          
          <p>This monolithic approach makes it difficult to independently scale parts of the processing, reorder tasks, or insert new processing steps without modifying multiple sections of the codebase.</p>

          <h2>Solution</h2>
          <p>Break down the processing required for each stream into a set of separate components (filters), each performing a single task. By standardizing the format of the data that each component receives and sends, these filters can be combined into a pipeline. This helps avoid duplicating code and makes it easy to update, replace, or add filters.</p>

          <div class="mermaid">
graph LR
    Input[Image Upload]
    Q1[Queue 1]
    F1[Content<br/>Moderation]
    Q2[Queue 2]
    F2[Resize<br/>Images]
    Q3[Queue 3]
    F3[Add<br/>Watermark]
    Q4[Queue 4]
    F4[Remove<br/>EXIF Data]
    Q5[Queue 5]
    F5[Publish<br/>to CDN]
    Output[CDN]
    
    Input -->|Raw Image| Q1
    Q1 --> F1
    F1 -->|Approved| Q2
    Q2 --> F2
    F2 -->|Resized| Q3
    Q3 --> F3
    F3 -->|Watermarked| Q4
    Q4 --> F4
    F4 -->|Clean| Q5
    Q5 --> F5
    F5 --> Output
    
    style F1 fill:#4CAF50
    style F2 fill:#2196F3
    style F3 fill:#9C27B0
    style F4 fill:#FF9800
    style F5 fill:#F44336
    style Q1 fill:#FFF59D
    style Q2 fill:#FFF59D
    style Q3 fill:#FFF59D
    style Q4 fill:#FFF59D
    style Q5 fill:#FFF59D
          </div>

          <h3>Key Characteristics</h3>
          <ul>
            <li><strong>Filters</strong> - Independent components that perform a single task</li>
            <li><strong>Pipes</strong> - Message channels (queues) connecting filters</li>
            <li><strong>Loose coupling</strong> - Filters only know about input/output format</li>
            <li><strong>Self-contained</strong> - Each filter runs independently</li>
            <li><strong>Stateless</strong> - No shared state between filter invocations</li>
          </ul>

          <h3>Performance Optimization</h3>
          <p>The slowest filter in the pipeline determines the overall throughput:</p>
          <ul>
            <li><strong>Parallel instances</strong> - Run multiple instances of bottleneck filters</li>
            <li><strong>Different compute</strong> - Deploy filters on different-sized instances</li>
            <li><strong>Geographic distribution</strong> - Place filters closer to data sources</li>
            <li><strong>Partition data</strong> - Process different data subsets in parallel</li>
          </ul>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Loose coupling</strong> - Filters are independent and replaceable</li>
            <li>‚úÖ <strong>Reusability</strong> - Create new pipelines by combining existing filters</li>
            <li>‚úÖ <strong>Update individual filters</strong> - Change one step without affecting others</li>
            <li>‚úÖ <strong>Reorder filters</strong> - Easily change processing sequence</li>
            <li>‚úÖ <strong>Run on different hardware</strong> - Scale and optimize each filter independently</li>
            <li>‚úÖ <strong>Parallel execution</strong> - Process multiple messages simultaneously</li>
          </ul>

          <h3>Problems and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Complexity</strong> - Many filters can make system difficult to understand end-to-end</li>
              <li><strong>Reliability</strong> - Ensure messages aren't lost between filters</li>
              <li><strong>Idempotency required</strong> - Filters must handle duplicate messages gracefully</li>
              <li><strong>Repeated messages</strong> - Implement duplicate detection if needed</li>
              <li><strong>Context/state overhead</strong> - Passing large context through pipeline impacts performance</li>
              <li><strong>Message tolerance</strong> - Filters must handle malformed messages</li>
              <li><strong>Error handling</strong> - Decide on retry, dead-letter, or compensation strategies</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Processing can be broken into <strong>independent steps</strong></li>
            <li>Steps have <strong>different scalability requirements</strong></li>
            <li>Need <strong>flexibility to reorder</strong> processing steps</li>
            <li>Want to <strong>distribute processing</strong> across different locations or platforms</li>
            <li>Need to minimize <strong>impact of individual step failures</strong> on overall system</li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>Implementing <strong>request-response pattern</strong> where result must be returned immediately</li>
            <li>Processing <strong>must complete within the initial request</strong></li>
            <li>Steps are <strong>not independent</strong> and share significant state</li>
            <li>Context or state passed between steps is <strong>excessively large</strong></li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Single responsibility and background jobs pattern (RE:01, RE:07)</li>
            <li>‚ö° <strong>Performance Efficiency</strong> - Independent scaling and optimization per component (PE:05)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Services for Pipes and Filters:</strong></p>
          
          <p><strong>Pipes (Message Channels):</strong></p>
          <ul>
            <li><strong>Azure Storage Queues</strong> - Simple, cost-effective queues</li>
            <li><strong>Azure Service Bus Queues</strong> - Advanced messaging features (sessions, transactions)</li>
            <li><strong>Azure Event Grid</strong> - Event-driven routing</li>
          </ul>

          <p><strong>Filters (Processing Components):</strong></p>
          <ul>
            <li><strong>Azure Functions</strong> - Serverless compute with queue triggers and bindings</li>
            <li><strong>Azure Logic Apps</strong> - Visual workflow designer</li>
            <li><strong>Azure Container Apps</strong> - Containerized microservices with KEDA scaling</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>Image Processing Pipeline with Azure Functions:</strong></p>
          <pre><code>// Filter 1: Content Moderation
[FunctionName("ContentModerationFilter")]
public async Task Run(
    [QueueTrigger("raw-images")] string imageUrl,
    [Queue("moderated-images")] IAsyncCollector&lt;ImageMessage&gt; outputQueue,
    ILogger log)
{
    var client = new ContentModeratorClient(credentials);
    var result = await client.ImageModeration.EvaluateUrlInputAsync(imageUrl);
    
    if (!result.IsImageAdultClassified)
    {
        await outputQueue.AddAsync(new ImageMessage 
        { 
            Url = imageUrl,
            Stage = "Moderated"
        });
        log.LogInformation($"Image approved: {imageUrl}");
    }
    else
    {
        log.LogWarning($"Image rejected: {imageUrl}");
    }
}

// Filter 2: Resize Images
[FunctionName("ResizeFilter")]
public async Task Run(
    [QueueTrigger("moderated-images")] ImageMessage message,
    [Queue("resized-images")] IAsyncCollector&lt;ImageMessage&gt; outputQueue,
    [Blob("images/{Url}", FileAccess.Read)] Stream inputBlob,
    [Blob("resized/{Url}", FileAccess.Write)] Stream outputBlob,
    ILogger log)
{
    using var image = await Image.LoadAsync(inputBlob);
    
    // Resize to multiple sizes
    image.Mutate(x => x.Resize(new ResizeOptions
    {
        Size = new Size(800, 600),
        Mode = ResizeMode.Max
    }));
    
    await image.SaveAsync(outputBlob, new JpegEncoder());
    
    message.Stage = "Resized";
    message.Url = $"resized/{message.Url}";
    await outputQueue.AddAsync(message);
    
    log.LogInformation($"Image resized: {message.Url}");
}

// Filter 3: Add Watermark
[FunctionName("WatermarkFilter")]
public async Task Run(
    [QueueTrigger("resized-images")] ImageMessage message,
    [Queue("watermarked-images")] IAsyncCollector&lt;ImageMessage&gt; outputQueue,
    [Blob("{Url}", FileAccess.Read)] Stream inputBlob,
    [Blob("watermarked/{Url}", FileAccess.Write)] Stream outputBlob,
    ILogger log)
{
    using var image = await Image.LoadAsync(inputBlob);
    
    // Add watermark
    var watermark = await Image.LoadAsync("watermark.png");
    image.Mutate(x => x.DrawImage(
        watermark, 
        new Point(image.Width - watermark.Width - 10, image.Height - watermark.Height - 10),
        opacity: 0.5f));
    
    await image.SaveAsync(outputBlob, new JpegEncoder());
    
    message.Stage = "Watermarked";
    message.Url = $"watermarked/{message.Url}";
    await outputQueue.AddAsync(message);
}

// Filter 4: Remove EXIF Data
[FunctionName("ExifRemovalFilter")]
public async Task Run(
    [QueueTrigger("watermarked-images")] ImageMessage message,
    [Queue("processed-images")] IAsyncCollector&lt;ImageMessage&gt; outputQueue,
    [Blob("{Url}", FileAccess.Read)] Stream inputBlob,
    [Blob("clean/{Url}", FileAccess.Write)] Stream outputBlob,
    ILogger log)
{
    using var image = await Image.LoadAsync(inputBlob);
    
    // Remove all metadata
    image.Metadata.ExifProfile = null;
    image.Metadata.IptcProfile = null;
    image.Metadata.XmpProfile = null;
    
    await image.SaveAsync(outputBlob, new JpegEncoder());
    
    message.Stage = "Clean";
    message.Url = $"clean/{message.Url}";
    await outputQueue.AddAsync(message);
}

// Filter 5: Publish to CDN
[FunctionName("PublishFilter")]
public async Task Run(
    [QueueTrigger("processed-images")] ImageMessage message,
    [Blob("{Url}", FileAccess.Read)] Stream inputBlob,
    ILogger log)
{
    // Upload to CDN origin (blob with CDN enabled)
    var cdnClient = new BlobClient(cdnConnectionString, "cdn", message.Url);
    await cdnClient.UploadAsync(inputBlob, overwrite: true);
    
    // Purge CDN cache
    await PurgeCdnCache(message.Url);
    
    log.LogInformation($"Image published to CDN: {message.Url}");
}

public class ImageMessage
{
    public string Url { get; set; }
    public string Stage { get; set; }
    public DateTime Timestamp { get; set; } = DateTime.UtcNow;
}</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#competing-consumers"><strong>Competing Consumers</strong></a> - Scale filters with multiple instances</li>
            <li>üîó <a href="#claim-check"><strong>Claim Check</strong></a> - Reduce message size by storing large data externally</li>
            <li>üîó <a href="#choreography"><strong>Choreography</strong></a> - Coordinate filters through events</li>
            <li>üîó <a href="#compensating-transaction"><strong>Compensating Transaction</strong></a> - Undo failed pipeline operations</li>
          </ul>
        </section>

        <!-- Priority Queue Pattern -->
        <section id="priority-queue" role="article">
          <h1>üéØ Priority Queue</h1>
          <div class="badges">
            <span class="badge badge-messaging">Messaging</span>
            <span class="badge badge-performance">Performance</span>
          </div>

          <h2>Context & Problem</h2>
          <p>Applications can delegate specific tasks to other services through message-based communication. In the cloud, a message queue is typically used to communicate tasks to backend services. In many cases, tasks are processed in the order they are received (FIFO).</p>
          
          <p>However, some business operations require specific messages or events to be processed before others. These operations don't account for the priority or importance of messages, potentially causing high-priority messages to wait behind lower-priority ones, negatively affecting performance and SLAs.</p>

          <h2>Solution</h2>
          <p>Prioritize requests sent to services so that requests with higher priority are received and processed more quickly than those with lower priority. This pattern is useful in applications that offer different service level guarantees to individual clients.</p>

          <div class="mermaid">
graph TB
    subgraph "Approach 1: Single Queue with Priority"
    App1[Application]
    PQ[Priority Queue<br/>Ordered by Priority]
    Consumer1[Single Consumer Pool]
    
    App1 -->|High Priority Msg| PQ
    App1 -->|Low Priority Msg| PQ
    PQ -->|Process by Priority| Consumer1
    end
    
    subgraph "Approach 2: Multiple Queues + Multiple Pools"
    App2[Application]
    HQ[High Priority Queue]
    LQ[Low Priority Queue]
    HC[High Priority<br/>Consumer Pool]
    LC[Low Priority<br/>Consumer Pool]
    
    App2 -->|High Priority| HQ
    App2 -->|Low Priority| LQ
    HQ --> HC
    LQ --> LC
    end
    
    subgraph "Approach 3: Multiple Queues + Single Pool"
    App3[Application]
    HQ2[High Priority Queue]
    LQ2[Low Priority Queue]
    SC[Shared<br/>Consumer Pool]
    
    App3 -->|High Priority| HQ2
    App3 -->|Low Priority| LQ2
    HQ2 -->|Process First| SC
    LQ2 -->|Process After| SC
    end
    
    style PQ fill:#4CAF50
    style HQ fill:#F44336
    style LQ fill:#2196F3
    style HQ2 fill:#F44336
    style LQ2 fill:#2196F3
          </div>

          <h3>Implementation Approaches</h3>
          
          <h4>1. Single Queue with Priority Ordering</h4>
          <ul>
            <li>Messages ordered by priority value in the queue</li>
            <li>Consumers process messages in priority order</li>
            <li>Simplest implementation but limited scalability</li>
          </ul>

          <h4>2. Multiple Queues + Multiple Consumer Pools</h4>
          <ul>
            <li>Separate queue for each priority level</li>
            <li>Dedicated consumer pool per queue</li>
            <li>Strict performance guarantees per priority</li>
            <li>High reliability and independent scaling</li>
            <li>More complex and higher cost</li>
          </ul>

          <h4>3. Multiple Queues + Single Consumer Pool</h4>
          <ul>
            <li>Separate queue for each priority level</li>
            <li>Shared consumer pool checks higher priority queues first</li>
            <li>Simpler management than multiple pools</li>
            <li>Risk of low-priority message starvation</li>
          </ul>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Meet SLAs</strong> - Ensure critical operations complete within time constraints</li>
            <li>‚úÖ <strong>Business alignment</strong> - Match processing priority to business value</li>
            <li>‚úÖ <strong>Resource optimization</strong> - Allocate resources based on importance</li>
            <li>‚úÖ <strong>Improved responsiveness</strong> - High-priority requests processed immediately</li>
            <li>‚úÖ <strong>Flexible prioritization</strong> - Different strategies for different workloads</li>
          </ul>

          <h3>Problems and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Define priorities clearly</strong> - Establish business rules for assigning priority levels</li>
              <li><strong>Prevent starvation</strong> - Ensure low-priority messages eventually get processed (age-based promotion)</li>
              <li><strong>Adjust dynamically</strong> - Monitor queue depths and adjust consumer pools based on load</li>
              <li><strong>Consider costs</strong> - Multiple queues and consumer pools increase infrastructure costs</li>
              <li><strong>Monitor processing speeds</strong> - Track metrics per priority level to ensure SLAs are met</li>
              <li><strong>Implement preemption carefully</strong> - If needed, allow high-priority work to interrupt low-priority tasks</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>System handles tasks with <strong>varying levels of urgency</strong></li>
            <li>Different users or tenants have <strong>different service level agreements</strong></li>
            <li>Need to <strong>manage workload</strong> by prioritizing processing of certain messages</li>
            <li>Want to ensure <strong>critical operations</strong> aren't delayed by routine tasks</li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>All tasks have <strong>equal priority</strong></li>
            <li>Processing order <strong>must be strictly FIFO</strong></li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Focus resources on critical flows (RE:02, RE:07)</li>
            <li>‚ö° <strong>Performance Efficiency</strong> - Optimize for time-sensitive work (PE:09)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Service Bus with Priority Property:</strong></p>
          
          <p>Service Bus doesn't have built-in priority ordering, but you can implement priority queues using:</p>
          <ul>
            <li><strong>Multiple queues</strong> - Create separate queues for each priority level</li>
            <li><strong>Custom priority property</strong> - Add priority metadata to messages</li>
            <li><strong>Topic filters</strong> - Use subscriptions with filters to route by priority</li>
            <li><strong>Scheduled messages</strong> - Delay low-priority messages to give priority to urgent ones</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>Multiple Queues Approach with Azure Functions:</strong></p>
          <pre><code>// Send messages to appropriate queue based on priority
public class MessageSender
{
    private readonly ServiceBusClient client;
    private readonly ServiceBusSender highPrioritySender;
    private readonly ServiceBusSender lowPrioritySender;

    public MessageSender(string connectionString)
    {
        client = new ServiceBusClient(connectionString);
        highPrioritySender = client.CreateSender("high-priority-queue");
        lowPrioritySender = client.CreateSender("low-priority-queue");
    }

    public async Task SendAsync(string messageBody, Priority priority)
    {
        var message = new ServiceBusMessage(messageBody)
        {
            MessageId = Guid.NewGuid().ToString(),
            Subject = priority.ToString()
        };

        var sender = priority switch
        {
            Priority.High => highPrioritySender,
            Priority.Low => lowPrioritySender,
            _ => lowPrioritySender
        };

        await sender.SendMessageAsync(message);
    }
}

public enum Priority
{
    Low,
    Normal,
    High
}

// High priority consumer - processes critical messages
[FunctionName("PriorityQueueConsumerHigh")]
public async Task RunHighPriority(
    [ServiceBusTrigger("high-priority-queue", Connection = "ServiceBusConnection")] 
    ServiceBusReceivedMessage message,
    ILogger log)
{
    log.LogInformation($"Processing HIGH priority message: {message.MessageId}");
    
    // Process high-priority message with guaranteed resources
    await ProcessMessageAsync(message.Body.ToString(), Priority.High);
    
    log.LogInformation($"Completed HIGH priority message: {message.MessageId}");
}

// Low priority consumer - processes routine messages
[FunctionName("PriorityQueueConsumerLow")]
public async Task RunLowPriority(
    [ServiceBusTrigger("low-priority-queue", Connection = "ServiceBusConnection")] 
    ServiceBusReceivedMessage message,
    ILogger log)
{
    log.LogInformation($"Processing LOW priority message: {message.MessageId}");
    
    // Process low-priority message (might be deferred if high-priority load is high)
    await ProcessMessageAsync(message.Body.ToString(), Priority.Low);
    
    log.LogInformation($"Completed LOW priority message: {message.MessageId}");
}</code></pre>

          <p><strong>Single Consumer Pool with Priority Checking:</strong></p>
          <pre><code>public class PriorityQueueProcessor
{
    private readonly ServiceBusClient client;
    private readonly ServiceBusReceiver highPriorityReceiver;
    private readonly ServiceBusReceiver lowPriorityReceiver;

    public PriorityQueueProcessor(string connectionString)
    {
        client = new ServiceBusClient(connectionString);
        highPriorityReceiver = client.CreateReceiver("high-priority-queue");
        lowPriorityReceiver = client.CreateReceiver("low-priority-queue");
    }

    public async Task ProcessMessagesAsync(CancellationToken cancellationToken)
    {
        while (!cancellationToken.IsCancellationRequested)
        {
            // Always check high-priority queue first
            var highPriorityMessage = await highPriorityReceiver.ReceiveMessageAsync(
                maxWaitTime: TimeSpan.FromSeconds(1), 
                cancellationToken: cancellationToken);

            if (highPriorityMessage != null)
            {
                await ProcessMessageAsync(highPriorityMessage, Priority.High);
                await highPriorityReceiver.CompleteMessageAsync(
                    highPriorityMessage, 
                    cancellationToken: cancellationToken);
                continue; // Process another high-priority message immediately
            }

            // Only process low-priority when no high-priority messages available
            var lowPriorityMessage = await lowPriorityReceiver.ReceiveMessageAsync(
                maxWaitTime: TimeSpan.FromSeconds(1), 
                cancellationToken: cancellationToken);

            if (lowPriorityMessage != null)
            {
                await ProcessMessageAsync(lowPriorityMessage, Priority.Low);
                await lowPriorityReceiver.CompleteMessageAsync(
                    lowPriorityMessage, 
                    cancellationToken: cancellationToken);
            }

            // Small delay if no messages in either queue
            if (highPriorityMessage == null && lowPriorityMessage == null)
            {
                await Task.Delay(TimeSpan.FromSeconds(2), cancellationToken);
            }
        }
    }

    private async Task ProcessMessageAsync(
        ServiceBusReceivedMessage message, 
        Priority priority)
    {
        // Process based on priority
        Console.WriteLine($"Processing {priority} priority: {message.MessageId}");
        await Task.Delay(TimeSpan.FromSeconds(priority == Priority.High ? 1 : 5));
    }
}</code></pre>

          <p><strong>Age-Based Priority Promotion (Prevent Starvation):</strong></p>
          <pre><code>// Promote old low-priority messages to high priority
public class MessageAgeMonitor
{
    private readonly ServiceBusAdministrationClient adminClient;

    public async Task PromoteOldMessagesAsync()
    {
        var queueProps = await adminClient.GetQueueRuntimePropertiesAsync("low-priority-queue");
        
        if (queueProps.Value.ActiveMessageCount > 0)
        {
            var receiver = client.CreateReceiver("low-priority-queue");
            var sender = client.CreateSender("high-priority-queue");

            // Peek messages to check age
            var messages = await receiver.PeekMessagesAsync(maxMessages: 100);
            
            foreach (var message in messages)
            {
                var age = DateTime.UtcNow - message.EnqueuedTime;
                
                // Promote messages older than 10 minutes
                if (age.TotalMinutes > 10)
                {
                    var fullMessage = await receiver.ReceiveMessageAsync();
                    
                    // Move to high-priority queue
                    var promotedMessage = new ServiceBusMessage(fullMessage.Body)
                    {
                        MessageId = fullMessage.MessageId,
                        Subject = "Promoted-" + fullMessage.Subject
                    };
                    
                    await sender.SendMessageAsync(promotedMessage);
                    await receiver.CompleteMessageAsync(fullMessage);
                }
            }
        }
    }
}</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#competing-consumers"><strong>Competing Consumers</strong></a> - Scale out message processing</li>
            <li>üîó <a href="#queue-load-leveling"><strong>Queue-Based Load Leveling</strong></a> - Buffer requests to smooth load</li>
            <li>üîó <a href="#throttling"><strong>Throttling</strong></a> - Control resource consumption by priority</li>
          </ul>
        </section>

        <!-- Publisher-Subscriber Pattern -->
        <section id="pub-sub" role="article">
          <h1>üì¢ Publisher-Subscriber</h1>
          <div class="badges">
            <span class="badge badge-messaging">Messaging</span>
            <span class="badge badge-reliability">Reliability</span>
          </div>

          <h2>Context & Problem</h2>
          <p>In cloud-based and distributed applications, components of the system often need to provide information to other components as events happen. Asynchronous messaging is an effective way to decouple senders from consumers and avoid blocking the sender to wait for a response.</p>
          
          <p>However, using a dedicated message queue for each consumer does not effectively scale to many consumers. Also, some of the consumers might be interested in only a subset of the information. How can the sender announce events to all interested consumers without knowing their identities?</p>

          <h2>Solution</h2>
          <p>Introduce an asynchronous messaging subsystem that includes an input messaging channel used by the sender (publisher), one output messaging channel per consumer (subscriber), and a mechanism for copying each message from the input channel to the output channels for all interested subscribers.</p>

          <div class="mermaid">
graph LR
    Publisher[Publisher<br/>Application]
    Broker[Message Broker<br/>Topic/Event Grid]
    Sub1[Subscriber 1<br/>Inventory Service]
    Sub2[Subscriber 2<br/>Email Service]
    Sub3[Subscriber 3<br/>Analytics Service]
    
    Publisher -->|Publish Event| Broker
    Broker -->|Deliver| Sub1
    Broker -->|Deliver| Sub2
    Broker -->|Deliver| Sub3
    
    style Broker fill:#4CAF50
    style Publisher fill:#2196F3
    style Sub1 fill:#FF9800
    style Sub2 fill:#9C27B0
    style Sub3 fill:#F44336
          </div>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Decoupling</strong> - Subsystems managed independently, messages delivered even if receivers offline</li>
            <li>‚úÖ <strong>Scalability</strong> - Sender can quickly publish single message, infrastructure handles delivery</li>
            <li>‚úÖ <strong>Reliability</strong> - Asynchronous messaging handles increased loads and intermittent failures</li>
            <li>‚úÖ <strong>Deferred processing</strong> - Subscribers can wait until off-peak hours to process</li>
            <li>‚úÖ <strong>Integration</strong> - Simple integration between systems with different platforms and languages</li>
            <li>‚úÖ <strong>Asynchronous workflows</strong> - Facilitates enterprise-wide async workflows</li>
            <li>‚úÖ <strong>Testability</strong> - Channels can be monitored, messages inspected for testing</li>
            <li>‚úÖ <strong>Separation of concerns</strong> - Each application focuses on core capabilities</li>
          </ul>

          <h3>Problems and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Use existing technologies</strong> - Strongly recommended to use Service Bus, Event Hubs, Event Grid rather than building your own</li>
              <li><strong>Subscription handling</strong> - Provide mechanisms for consumers to subscribe/unsubscribe</li>
              <li><strong>Security</strong> - Restrict message channel access to prevent eavesdropping</li>
              <li><strong>Message subsets</strong> - Use topics and content filtering for subscribers interested in specific messages</li>
              <li><strong>Wildcard subscribers</strong> - Allow subscriptions to multiple topics via wildcards</li>
              <li><strong>Bi-directional communication</strong> - Use Request/Reply pattern if subscribers need to send acknowledgment</li>
              <li><strong>Message ordering</strong> - Ensure message processing is idempotent as order isn't guaranteed</li>
              <li><strong>Message priority</strong> - Use Priority Queue pattern for ordered processing</li>
              <li><strong>Poison messages</strong> - Capture and store malformed messages in dead-letter queue</li>
              <li><strong>Repeated messages</strong> - Implement duplicate detection or ensure idempotent processing</li>
              <li><strong>Message expiration</strong> - Messages may have limited lifetime</li>
              <li><strong>Message scheduling</strong> - Support embargoed messages not available until specific time</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Application needs to <strong>broadcast information</strong> to significant number of consumers</li>
            <li>Need to communicate with <strong>independently developed applications or services</strong> using different platforms</li>
            <li>Application can send information <strong>without requiring real-time responses</strong></li>
            <li>Systems integrated are designed for <strong>eventual consistency</strong></li>
            <li>Need to communicate to multiple consumers with <strong>different availability requirements</strong></li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>Application has only a <strong>few consumers</strong> who need significantly different information</li>
            <li>Application requires <strong>near real-time interaction</strong> with consumers</li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Decoupling enables independent reliability targets, removes direct dependencies (RE:03, RE:07)</li>
            <li>üîí <strong>Security</strong> - Introduces segmentation boundary enabling network isolation (SE:04)</li>
            <li>üí∞ <strong>Cost Optimization</strong> - Event-driven approach couples with consumption-based billing (CO:05, CO:12)</li>
            <li>üîß <strong>Operational Excellence</strong> - Enables safe changes without coordinating both components (OE:06, OE:11)</li>
            <li>‚ö° <strong>Performance Efficiency</strong> - Optimize compute and code for specific consumer tasks (PE:02, PE:05)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Messaging Services for Pub/Sub:</strong></p>
          
          <p><strong>Azure Service Bus Topics:</strong></p>
          <ul>
            <li>Supports multiple subscribers per topic</li>
            <li>Filter rules on subscriptions for message routing</li>
            <li>Guaranteed message delivery with transactions</li>
            <li>Session support for ordered message processing</li>
          </ul>

          <p><strong>Azure Event Grid:</strong></p>
          <ul>
            <li>Event-driven architecture with built-in publisher-subscriber</li>
            <li>Push model - events delivered to subscribers</li>
            <li>Advanced filtering on event properties</li>
            <li>Integrates with 20+ Azure services as sources</li>
          </ul>

          <p><strong>Azure Event Hubs:</strong></p>
          <ul>
            <li>Big data streaming platform and event ingestion service</li>
            <li>Millions of events per second</li>
            <li>Pull model - consumers read at their own pace</li>
            <li>Capture events to Azure Storage or Data Lake</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>Service Bus Topic Publisher:</strong></p>
          <pre><code>public class OrderEventPublisher
{
    private readonly ServiceBusClient client;
    private readonly ServiceBusSender sender;

    public OrderEventPublisher(string connectionString, string topicName)
    {
        client = new ServiceBusClient(connectionString);
        sender = client.CreateSender(topicName);
    }

    public async Task PublishOrderCreatedAsync(Order order)
    {
        var orderEvent = new
        {
            EventType = "OrderCreated",
            OrderId = order.Id,
            CustomerId = order.CustomerId,
            TotalAmount = order.TotalAmount,
            Timestamp = DateTime.UtcNow
        };

        var message = new ServiceBusMessage(JsonSerializer.Serialize(orderEvent))
        {
            ContentType = "application/json",
            Subject = "OrderCreated",
            MessageId = Guid.NewGuid().ToString(),
            CorrelationId = order.Id.ToString()
        };

        // Add custom properties for filtering
        message.ApplicationProperties["OrderType"] = order.Type;
        message.ApplicationProperties["TotalAmount"] = order.TotalAmount;

        await sender.SendMessageAsync(message);
        Console.WriteLine($"Published OrderCreated event for order {order.Id}");
    }
}</code></pre>

          <p><strong>Service Bus Topic Subscribers:</strong></p>
          <pre><code>// Inventory Service - subscribes to all orders
[FunctionName("InventorySubscriber")]
public async Task ProcessInventoryUpdate(
    [ServiceBusTrigger("orders-topic", "inventory-subscription", 
        Connection = "ServiceBusConnection")] 
    ServiceBusReceivedMessage message,
    ILogger log)
{
    var orderEvent = JsonSerializer.Deserialize&lt;OrderEvent&gt;(message.Body.ToString());
    log.LogInformation($"Inventory: Processing order {orderEvent.OrderId}");
    
    // Update inventory levels
    await UpdateInventoryAsync(orderEvent);
}

// Email Service - subscribes only to high-value orders (filter rule)
[FunctionName("EmailSubscriber")]
public async Task SendOrderConfirmation(
    [ServiceBusTrigger("orders-topic", "email-subscription", 
        Connection = "ServiceBusConnection")] 
    ServiceBusReceivedMessage message,
    ILogger log)
{
    // Subscription has filter: TotalAmount > 1000
    var orderEvent = JsonSerializer.Deserialize&lt;OrderEvent&gt;(message.Body.ToString());
    log.LogInformation($"Email: Sending confirmation for order {orderEvent.OrderId}");
    
    await SendEmailAsync(orderEvent);
}

// Analytics Service - subscribes to all orders for reporting
[FunctionName("AnalyticsSubscriber")]
public async Task RecordOrderMetrics(
    [ServiceBusTrigger("orders-topic", "analytics-subscription", 
        Connection = "ServiceBusConnection")] 
    ServiceBusReceivedMessage message,
    ILogger log)
{
    var orderEvent = JsonSerializer.Deserialize&lt;OrderEvent&gt;(message.Body.ToString());
    log.LogInformation($"Analytics: Recording metrics for order {orderEvent.OrderId}");
    
    await RecordMetricsAsync(orderEvent);
}</code></pre>

          <p><strong>Event Grid Publisher and Subscriber:</strong></p>
          <pre><code>// Publisher using Event Grid
public class EventGridPublisher
{
    private readonly EventGridPublisherClient client;

    public EventGridPublisher(string topicEndpoint, AzureKeyCredential credential)
    {
        client = new EventGridPublisherClient(new Uri(topicEndpoint), credential);
    }

    public async Task PublishOrderEventAsync(Order order)
    {
        var cloudEvent = new CloudEvent(
            source: "orders/api",
            type: "Orders.OrderCreated",
            jsonSerializableData: new
            {
                orderId = order.Id,
                customerId = order.CustomerId,
                totalAmount = order.TotalAmount
            })
        {
            Id = Guid.NewGuid().ToString(),
            Time = DateTime.UtcNow,
            Subject = $"orders/{order.Id}"
        };

        await client.SendEventAsync(cloudEvent);
    }
}

// Subscriber using Azure Function with Event Grid trigger
[FunctionName("EventGridSubscriber")]
public async Task ProcessOrderEvent(
    [EventGridTrigger] EventGridEvent eventGridEvent,
    ILogger log)
{
    log.LogInformation($"Received event: {eventGridEvent.EventType}");
    log.LogInformation($"Subject: {eventGridEvent.Subject}");
    log.LogInformation($"Data: {eventGridEvent.Data}");
    
    if (eventGridEvent.EventType == "Orders.OrderCreated")
    {
        var orderData = JsonSerializer.Deserialize&lt;OrderData&gt;(
            eventGridEvent.Data.ToString());
        await ProcessOrderAsync(orderData);
    }
}</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#event-driven-arch"><strong>Event-Driven Architecture</strong></a> - Architecture style using pub/sub messaging</li>
            <li>üîó <a href="#competing-consumers"><strong>Competing Consumers</strong></a> - Scale out subscribers with multiple instances</li>
            <li>üîó <a href="#priority-queue"><strong>Priority Queue</strong></a> - Process messages based on priority</li>
          </ul>
        </section>

        <!-- Queue-Based Load Leveling Pattern -->
        <section id="queue-load-leveling" role="article">
          <h1>‚öñÔ∏è Queue-Based Load Leveling</h1>
          <div class="badges">
            <span class="badge badge-messaging">Messaging</span>
            <span class="badge badge-reliability">Reliability</span>
            <span class="badge badge-performance">Performance</span>
          </div>

          <h2>Context & Problem</h2>
          <p>Many solutions in the cloud involve running tasks that invoke services. If a service is subjected to intermittent heavy loads, it can cause performance or reliability issues. A service might experience peaks in demand that cause it to overload and be unable to respond to requests in a timely manner.</p>
          
          <p>Flooding a service with a large number of concurrent requests can result in the service failing if it's unable to handle the contention these requests cause. When multiple tasks run concurrently and use the same service, predicting the volume of requests at any time becomes difficult.</p>

          <h2>Solution</h2>
          <p>Refactor the solution and introduce a queue between the task and the service. The task and the service run asynchronously. The task posts a message containing the data required by the service to a queue, which acts as a buffer. The service retrieves messages from the queue and processes them at its own pace.</p>

          <div class="mermaid">
graph LR
    subgraph "Without Queue"
    T1[Task 1]
    T2[Task 2]
    T3[Task 3]
    T4[Task 4]
    S1[Service<br/>‚ö†Ô∏è Overwhelmed]
    
    T1 --> S1
    T2 --> S1
    T3 --> S1
    T4 --> S1
    end
    
    subgraph "With Queue-Based Load Leveling"
    TA1[Task A]
    TA2[Task A]
    TA3[Task A]
    TA4[Task A]
    Queue[Queue<br/>Buffer]
    Func[Function App<br/>Controlled Rate]
    Service[Service<br/>‚úì Stable]
    
    TA1 --> Queue
    TA2 --> Queue
    TA3 --> Queue
    TA4 --> Queue
    Queue --> Func
    Func -->|Throttled| Service
    end
    
    style S1 fill:#ffcdd2
    style Queue fill:#4CAF50
    style Service fill:#c8e6c9
          </div>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Maximize availability</strong> - Delays in services don't immediately impact application</li>
            <li>‚úÖ <strong>Maximize scalability</strong> - Both queues and services can be varied to meet demand</li>
            <li>‚úÖ <strong>Control costs</strong> - Service instances only need to meet average load, not peak load</li>
            <li>‚úÖ <strong>Smooth spikes</strong> - Buffer absorbs sudden bursts of activity</li>
            <li>‚úÖ <strong>Decouple components</strong> - Application continues posting messages even if service is down</li>
          </ul>

          <h3>Problems and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Control processing rate</strong> - Implement logic to prevent overwhelming target resource</li>
              <li><strong>Test under load</strong> - Ensure system provides required leveling with appropriate queue/service count</li>
              <li><strong>Response mechanism</strong> - If task expects reply, implement async response pattern</li>
              <li><strong>Autoscaling caution</strong> - Can increase contention for shared resources, diminish effectiveness</li>
              <li><strong>Traffic variability</strong> - Consider if always trailing behind due to continuous high load</li>
              <li><strong>Queue persistence</strong> - Risk of data loss if queue crashes or drops messages</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Application uses services subject to <strong>overloading</strong></li>
            <li>Need to handle <strong>intermittent heavy loads</strong> gracefully</li>
            <li>Want to <strong>smooth out spikes</strong> in demand</li>
            <li>Can tolerate <strong>asynchronous processing</strong></li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>Application expects <strong>response with minimal latency</strong></li>
            <li>Service must respond <strong>within the initial request</strong></li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Resilience against demand spikes, isolates processing malfunctions (RE:06, RE:07)</li>
            <li>üí∞ <strong>Cost Optimization</strong> - Reduce need to overprovision for peak load (CO:12)</li>
            <li>‚ö° <strong>Performance Efficiency</strong> - Intentional throughput design decoupled from intake rate (PE:05)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Services for Load Leveling:</strong></p>
          
          <p><strong>Queue Options:</strong></p>
          <ul>
            <li><strong>Azure Storage Queues</strong> - Simple, cost-effective, large volumes (500 TB capacity)</li>
            <li><strong>Azure Service Bus Queues</strong> - Advanced features (sessions, transactions, duplicate detection)</li>
          </ul>

          <p><strong>Processing Options:</strong></p>
          <ul>
            <li><strong>Azure Functions</strong> - Serverless, automatic scaling, queue triggers</li>
            <li><strong>Azure Logic Apps</strong> - Visual workflow designer</li>
            <li><strong>Azure Container Apps</strong> - KEDA-based queue scaling</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>Web Application Posting to Queue:</strong></p>
          <pre><code>public class OrderController : ControllerBase
{
    private readonly QueueClient queueClient;

    public OrderController(string connectionString)
    {
        queueClient = new QueueClient(connectionString, "order-processing-queue");
        queueClient.CreateIfNotExists();
    }

    [HttpPost("api/orders")]
    public async Task&lt;IActionResult&gt; CreateOrder([FromBody] OrderRequest order)
    {
        // Validate order
        if (!ModelState.IsValid)
            return BadRequest(ModelState);

        // Create message with order data
        var orderMessage = new OrderMessage
        {
            OrderId = Guid.NewGuid(),
            CustomerId = order.CustomerId,
            Items = order.Items,
            Timestamp = DateTime.UtcNow
        };

        var messageJson = JsonSerializer.Serialize(orderMessage);
        var messageBytes = Encoding.UTF8.GetBytes(messageJson);
        var base64Message = Convert.ToBase64String(messageBytes);

        // Post to queue (doesn't wait for processing)
        await queueClient.SendMessageAsync(base64Message);

        // Return immediately with order ID
        return Accepted(new 
        { 
            orderId = orderMessage.OrderId,
            message = "Order submitted for processing"
        });
    }
}

public class OrderMessage
{
    public Guid OrderId { get; set; }
    public string CustomerId { get; set; }
    public List&lt;OrderItem&gt; Items { get; set; }
    public DateTime Timestamp { get; set; }
}</code></pre>

          <p><strong>Azure Function Processing Queue at Controlled Rate:</strong></p>
          <pre><code>[FunctionName("ProcessOrderQueue")]
public async Task Run(
    [QueueTrigger("order-processing-queue", Connection = "StorageConnection")] 
    string queueMessage,
    ILogger log)
{
    log.LogInformation($"Processing order message: {queueMessage}");

    try
    {
        var orderMessage = JsonSerializer.Deserialize&lt;OrderMessage&gt;(queueMessage);

        // Control rate: Add deliberate delay if needed to throttle processing
        // This prevents overwhelming the downstream service
        await ProcessOrderWithRateLimitAsync(orderMessage);

        log.LogInformation($"Successfully processed order {orderMessage.OrderId}");
    }
    catch (Exception ex)
    {
        log.LogError($"Error processing order: {ex.Message}");
        throw; // Message will be retried or moved to poison queue
    }
}

private static readonly SemaphoreSlim rateLimiter = new SemaphoreSlim(10, 10); // Max 10 concurrent

private async Task ProcessOrderWithRateLimitAsync(OrderMessage order)
{
    await rateLimiter.WaitAsync();
    
    try
    {
        // Call downstream service at controlled rate
        await orderService.SaveOrderAsync(order);
        
        // Artificial delay to prevent overwhelming service
        await Task.Delay(TimeSpan.FromMilliseconds(100));
    }
    finally
    {
        rateLimiter.Release();
    }
}</code></pre>

          <p><strong>Service Bus with Throttling:</strong></p>
          <pre><code>public class ThrottledServiceBusProcessor
{
    private readonly ServiceBusProcessor processor;
    private readonly int maxConcurrentCalls;
    private readonly TimeSpan minProcessingTime;

    public ThrottledServiceBusProcessor(
        string connectionString, 
        string queueName,
        int maxConcurrentCalls = 5,
        TimeSpan? minProcessingTime = null)
    {
        this.maxConcurrentCalls = maxConcurrentCalls;
        this.minProcessingTime = minProcessingTime ?? TimeSpan.FromMilliseconds(200);

        var client = new ServiceBusClient(connectionString);
        processor = client.CreateProcessor(queueName, new ServiceBusProcessorOptions
        {
            MaxConcurrentCalls = maxConcurrentCalls,
            AutoCompleteMessages = false,
            PrefetchCount = 0 // Disable prefetch to control rate more precisely
        });

        processor.ProcessMessageAsync += ProcessMessageAsync;
        processor.ProcessErrorAsync += ProcessErrorAsync;
    }

    private async Task ProcessMessageAsync(ProcessMessageEventArgs args)
    {
        var startTime = DateTime.UtcNow;
        
        try
        {
            var message = args.Message;
            Console.WriteLine($"Processing: {message.MessageId}");

            // Process message
            await ProcessBusinessLogicAsync(message.Body.ToString());

            // Enforce minimum processing time to throttle rate
            var elapsed = DateTime.UtcNow - startTime;
            if (elapsed < minProcessingTime)
            {
                await Task.Delay(minProcessingTime - elapsed);
            }

            // Complete message
            await args.CompleteMessageAsync(message);
        }
        catch (Exception ex)
        {
            Console.WriteLine($"Error: {ex.Message}");
            // Abandon message for retry
            await args.AbandonMessageAsync(args.Message);
        }
    }

    private Task ProcessErrorAsync(ProcessErrorEventArgs args)
    {
        Console.WriteLine($"Error: {args.Exception.Message}");
        return Task.CompletedTask;
    }

    public async Task StartAsync() => await processor.StartProcessingAsync();
    public async Task StopAsync() => await processor.StopProcessingAsync();
}</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#competing-consumers"><strong>Competing Consumers</strong></a> - Multiple instances processing queue</li>
            <li>üîó <a href="#throttling"><strong>Throttling</strong></a> - Implement throttling with queue-based approach</li>
            <li>üîó <a href="#priority-queue"><strong>Priority Queue</strong></a> - Process high-priority messages first</li>
          </ul>
        </section>

        <!-- Scheduler Agent Supervisor Pattern -->
        <section id="scheduler-agent" role="article">
          <h1>üìã Scheduler Agent Supervisor</h1>
          <div class="badges">
            <span class="badge badge-reliability">Reliability</span>
            <span class="badge badge-messaging">Messaging</span>
          </div>

          <h2>Context & Problem</h2>
          <p>An application performs tasks that include multiple steps, some of which might invoke remote services or access remote resources. The individual steps might be independent of each other, but they are orchestrated by the application logic that implements the task.</p>
          
          <p>The application should ensure that the task runs to completion and resolve any failures that might occur when accessing remote services or resources. Failures can occur for many reasons (network down, communications interrupted, remote service unresponsive or unstable, resource temporarily inaccessible). The application must be able to restore the system to a consistent state and ensure integrity of the entire operation.</p>

          <h2>Solution</h2>
          <p>The Scheduler Agent Supervisor pattern defines three actors that orchestrate the steps to be performed as part of the overall task:</p>

          <div class="mermaid">
graph TB
    App[Application]
    Scheduler[Scheduler<br/>Orchestrates Workflow]
    StateStore[(State Store<br/>Durable Storage)]
    Agent1[Agent 1<br/>Remote Service Call]
    Agent2[Agent 2<br/>Resource Access]
    Supervisor[Supervisor<br/>Monitors & Recovers]
    RemoteService[Remote Service]
    Resource[Remote Resource]
    
    App -->|Submit Task| Scheduler
    Scheduler -->|Update State| StateStore
    Scheduler -->|Invoke| Agent1
    Scheduler -->|Invoke| Agent2
    Agent1 -->|Call| RemoteService
    Agent2 -->|Access| Resource
    Agent1 -->|Response| Scheduler
    Agent2 -->|Response| Scheduler
    Supervisor -->|Monitor| StateStore
    Supervisor -->|Recover Failed Steps| Scheduler
    
    style Scheduler fill:#2196F3
    style Agent1 fill:#4CAF50
    style Agent2 fill:#4CAF50
    style Supervisor fill:#FF9800
    style StateStore fill:#9C27B0
          </div>

          <h3>Key Actors</h3>
          
          <h4>Scheduler</h4>
          <ul>
            <li>Arranges steps to be executed and orchestrates workflow operation</li>
            <li>Records state of workflow (step not started, running, completed)</li>
            <li>Tracks complete-by time for each step (upper limit for completion)</li>
            <li>Invokes Agents using asynchronous request/response messaging (queues)</li>
            <li>Similar to Process Manager in enterprise integration patterns</li>
          </ul>

          <h4>Agent</h4>
          <ul>
            <li>Contains logic encapsulating call to remote service or resource access</li>
            <li>Wraps calls to single service/resource with error handling and retry logic</li>
            <li>Must complete work before complete-by time expires</li>
            <li>Returns response to Scheduler upon successful completion</li>
            <li>Stops work if timeout occurs (no response sent)</li>
          </ul>

          <h4>Supervisor</h4>
          <ul>
            <li>Monitors status of steps being performed by Scheduler</li>
            <li>Runs periodically examining state maintained in state store</li>
            <li>Detects timed-out or failed steps</li>
            <li>Arranges for recovery or remedial action (retry, compensating transaction)</li>
            <li>Doesn't implement recovery itself - requests Scheduler/Agents to perform actions</li>
          </ul>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Resilience</strong> - System resilient to unexpected temporary or unrecoverable failures</li>
            <li>‚úÖ <strong>Self-healing</strong> - Can recover from Agent or Scheduler failures automatically</li>
            <li>‚úÖ <strong>Automatic recovery</strong> - New instances started, tasks resumed from failure point</li>
            <li>‚úÖ <strong>Consistent state</strong> - System can restore to consistent state after failures</li>
            <li>‚úÖ <strong>Fault isolation</strong> - Individual step failures don't break entire workflow</li>
          </ul>

          <h3>Problems and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Complex implementation</strong> - Difficult to implement, requires thorough testing of all failure modes</li>
              <li><strong>Complex recovery logic</strong> - Scheduler logic depends on state store, may need compensating transactions</li>
              <li><strong>Supervisor frequency</strong> - Must run often enough to prevent blocking, but not so often it becomes overhead</li>
              <li><strong>Idempotency required</strong> - Steps might run more than once, logic must be idempotent</li>
              <li><strong>State store reliability</strong> - State store should be durable, possibly replicated</li>
              <li><strong>Coordination overhead</strong> - Multiple Supervisors must coordinate using Leader Election pattern</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Process running in <strong>distributed environment must be resilient</strong> to failures</li>
            <li>Tasks involve <strong>multiple steps with remote services or resources</strong></li>
            <li>Need to ensure <strong>tasks run to completion</strong> despite transient failures</li>
            <li>Must maintain <strong>consistent state</strong> across distributed operations</li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>Tasks <strong>don't invoke remote services</strong> or access remote resources</li>
            <li>All operations are <strong>local and synchronous</strong></li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Health metrics detect failures, reroute to healthy agents (RE:05, RE:07)</li>
            <li>‚ö° <strong>Performance Efficiency</strong> - Performance metrics route tasks to agents with capacity (PE:05, PE:09)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Services for Pattern Implementation:</strong></p>
          
          <ul>
            <li><strong>Scheduler</strong> - Azure Durable Functions (orchestration functions)</li>
            <li><strong>Agents</strong> - Azure Functions (activity functions) or separate microservices</li>
            <li><strong>Supervisor</strong> - Timer-triggered Azure Function or Durable Functions monitor</li>
            <li><strong>State Store</strong> - Azure Cosmos DB, Azure Table Storage, or Durable Functions built-in state</li>
            <li><strong>Messaging</strong> - Azure Service Bus queues for request/response between Scheduler and Agents</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>Durable Functions Implementation:</strong></p>
          <pre><code>// Orchestrator (Scheduler)
[FunctionName("OrderProcessingOrchestrator")]
public async Task&lt;string&gt; RunOrchestrator(
    [OrchestrationTrigger] IDurableOrchestrationContext context,
    ILogger log)
{
    var orderId = context.GetInput&lt;string&gt;();
    log = context.CreateReplaySafeLogger(log);
    
    try
    {
        // Step 1: Validate order (with timeout)
        await context.CallActivityWithRetryAsync&lt;bool&gt;(
            "ValidateOrder",
            new RetryOptions(TimeSpan.FromSeconds(30), 3),
            orderId);
        
        // Step 2: Reserve inventory (Agent call)
        var inventoryReserved = await context.CallActivityWithRetryAsync&lt;bool&gt;(
            "ReserveInventory",
            new RetryOptions(TimeSpan.FromSeconds(30), 3),
            orderId);

        if (!inventoryReserved)
        {
            throw new InvalidOperationException("Insufficient inventory");
        }
        
        // Step 3: Process payment (Agent call with timeout)
        using (var cts = new CancellationTokenSource())
        {
            var paymentTask = context.CallActivityAsync&lt;bool&gt;("ProcessPayment", orderId);
            var timeoutTask = context.CreateTimer(
                context.CurrentUtcDateTime.AddMinutes(5), 
                cts.Token);
            
            var winner = await Task.WhenAny(paymentTask, timeoutTask);
            
            if (winner == timeoutTask)
            {
                // Payment timed out - compensate
                await context.CallActivityAsync("ReleaseInventory", orderId);
                throw new TimeoutException("Payment processing timed out");
            }
            
            cts.Cancel(); // Cancel timeout timer
        }
        
        // Step 4: Ship order
        await context.CallActivityAsync("ShipOrder", orderId);
        
        return $"Order {orderId} processed successfully";
    }
    catch (Exception ex)
    {
        log.LogError($"Order {orderId} failed: {ex.Message}");
        
        // Supervisor will detect failure and decide on recovery
        await context.CallActivityAsync("RecordOrderFailure", 
            new { orderId, error = ex.Message });
        
        throw;
    }
}

// Agent: Reserve Inventory
[FunctionName("ReserveInventory")]
public async Task&lt;bool&gt; ReserveInventory(
    [ActivityTrigger] string orderId,
    ILogger log)
{
    log.LogInformation($"Reserving inventory for order {orderId}");
    
    try
    {
        // Call external inventory service
        var inventoryClient = new InventoryServiceClient();
        var result = await inventoryClient.ReserveAsync(orderId);
        
        return result.Success;
    }
    catch (Exception ex)
    {
        log.LogError($"Failed to reserve inventory: {ex.Message}");
        throw;
    }
}

// Agent: Process Payment
[FunctionName("ProcessPayment")]
public async Task&lt;bool&gt; ProcessPayment(
    [ActivityTrigger] string orderId,
    ILogger log)
{
    log.LogInformation($"Processing payment for order {orderId}");
    
    try
    {
        // Call external payment service with retry logic
        var paymentClient = new PaymentServiceClient();
        
        for (int attempt = 1; attempt &lt;= 3; attempt++)
        {
            try
            {
                var result = await paymentClient.ChargeAsync(orderId);
                return result.Success;
            }
            catch (TransientException)
            {
                if (attempt &lt; 3)
                {
                    await Task.Delay(TimeSpan.FromSeconds(Math.Pow(2, attempt)));
                    continue;
                }
                throw;
            }
        }
        
        return false;
    }
    catch (Exception ex)
    {
        log.LogError($"Payment failed: {ex.Message}");
        throw;
    }
}

// Supervisor: Monitor orchestrations
[FunctionName("OrderProcessingSupervisor")]
public async Task MonitorOrchestrations(
    [TimerTrigger("0 */5 * * * *")] TimerInfo timer, // Every 5 minutes
    [DurableClient] IDurableOrchestrationClient client,
    ILogger log)
{
    log.LogInformation("Supervisor checking orchestration status");
    
    var statusQueryResult = await client.ListInstancesAsync(
        new OrchestrationStatusQueryCondition
        {
            RuntimeStatus = new[]
            {
                OrchestrationRuntimeStatus.Running,
                OrchestrationRuntimeStatus.Pending
            }
        },
        CancellationToken.None);

    foreach (var instance in statusQueryResult.DurableOrchestrationState)
    {
        var status = await client.GetStatusAsync(instance.InstanceId);
        
        // Check if orchestration has been running too long
        var runningTime = DateTime.UtcNow - status.CreatedTime;
        
        if (runningTime > TimeSpan.FromMinutes(30))
        {
            log.LogWarning($"Orchestration {instance.InstanceId} exceeded timeout");
            
            // Terminate and restart
            await client.TerminateAsync(instance.InstanceId, "Timeout exceeded");
            
            // Could restart with new instance if needed
            // await client.StartNewAsync("OrderProcessingOrchestrator", orderId);
        }
    }
}</code></pre>

          <p><strong>Traditional Queue-Based Implementation:</strong></p>
          <pre><code>// State Store Model
public class WorkflowState
{
    public string WorkflowId { get; set; }
    public string OrderId { get; set; }
    public string LockedBy { get; set; } // Scheduler instance ID
    public DateTime CompleteBy { get; set; }
    public WorkflowStatus ProcessState { get; set; }
    public int FailureCount { get; set; }
    public List&lt;StepState&gt; Steps { get; set; }
}

public class StepState
{
    public string StepName { get; set; }
    public StepStatus Status { get; set; } // Pending, Running, Completed, Failed
    public DateTime CompleteBy { get; set; }
    public int RetryCount { get; set; }
}

// Scheduler
public class WorkflowScheduler
{
    private readonly IStateStore stateStore;
    private readonly ServiceBusClient serviceBus;

    public async Task ExecuteWorkflowAsync(string orderId)
    {
        var workflowId = Guid.NewGuid().ToString();
        var instanceId = Environment.MachineName;

        // Create workflow state
        var state = new WorkflowState
        {
            WorkflowId = workflowId,
            OrderId = orderId,
            LockedBy = instanceId,
            CompleteBy = DateTime.UtcNow.AddMinutes(30),
            ProcessState = WorkflowStatus.Running,
            Steps = new List&lt;StepState&gt;
            {
                new StepState { StepName = "ValidateOrder", Status = StepStatus.Pending },
                new StepState { StepName = "ReserveInventory", Status = StepStatus.Pending },
                new StepState { StepName = "ProcessPayment", Status = StepStatus.Pending }
            }
        };

        await stateStore.SaveAsync(state);

        // Execute steps
        foreach (var step in state.Steps)
        {
            step.Status = StepStatus.Running;
            step.CompleteBy = DateTime.UtcNow.AddMinutes(5);
            await stateStore.UpdateAsync(state);

            // Send message to agent
            var sender = serviceBus.CreateSender($"{step.StepName}-queue");
            await sender.SendMessageAsync(new ServiceBusMessage(JsonSerializer.Serialize(new
            {
                workflowId,
                orderId,
                stepName = step.StepName,
                completeBy = step.CompleteBy
            })));
        }
    }
}

// Supervisor
public class WorkflowSupervisor
{
    private readonly IStateStore stateStore;

    [FunctionName("WorkflowSupervisor")]
    public async Task Run([TimerTrigger("0 */1 * * * *")] TimerInfo timer)
    {
        // Find workflows with expired steps
        var expiredWorkflows = await stateStore.FindExpiredWorkflowsAsync();

        foreach (var workflow in expiredWorkflows)
        {
            workflow.FailureCount++;

            if (workflow.FailureCount &lt; 3)
            {
                // Retry: Reset state and reschedule
                workflow.LockedBy = null;
                workflow.ProcessState = WorkflowStatus.Pending;
                await stateStore.UpdateAsync(workflow);
            }
            else
            {
                // Max retries exceeded - mark as failed
                workflow.ProcessState = WorkflowStatus.Failed;
                await stateStore.UpdateAsync(workflow);
                
                // Trigger compensating transactions if needed
                await TriggerCompensationAsync(workflow);
            }
        }
    }
}</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#retry"><strong>Retry</strong></a> - Agents use retry pattern for transient failures</li>
            <li>üîó <a href="#circuit-breaker"><strong>Circuit Breaker</strong></a> - Agents use circuit breaker for persistent failures</li>
            <li>üîó <a href="#compensating-transaction"><strong>Compensating Transaction</strong></a> - Supervisor triggers compensation for failed workflows</li>
            <li>üîó <a href="#leader-election"><strong>Leader Election</strong></a> - Coordinate multiple Supervisor instances</li>
          </ul>
        </section>

        <!-- Sequential Convoy Pattern -->
        <section id="sequential-convoy" role="article">
          <h1>üöÇ Sequential Convoy</h1>
          <div class="badges">
            <span class="badge badge-messaging">Messaging</span>
            <span class="badge badge-reliability">Reliability</span>
          </div>

          <h2>Context & Problem</h2>
          <p>Applications often need to process a sequence of messages in the order they arrive, while still being able to scale out to handle increased load. In a distributed architecture, processing these messages in order isn't straightforward, because the workers can scale independently and often pull messages independently using a Competing Consumers pattern.</p>
          
          <p>For example, an order tracking system receives a ledger containing orders and relevant operations. These operations must be performed in first-in-first-out (FIFO) manner, but only at the order level. However, the initial queue receives a ledger containing transactions for many orders, which might be interleaved.</p>

          <h2>Solution</h2>
          <p>Push related messages into categories within the queuing system, and have the queue listeners lock and pull only from one category, one message at a time. This ensures FIFO processing within each category while allowing parallel processing across different categories.</p>

          <div class="mermaid">
graph TB
    subgraph "Incoming Messages - Interleaved"
    M1[Order A - Create]
    M2[Order B - Create]
    M3[Order A - Update]
    M4[Order C - Create]
    M5[Order B - Update]
    M6[Order A - Complete]
    end
    
    subgraph "Categorized Processing"
    QA[Session A<br/>Order A Messages]
    QB[Session B<br/>Order B Messages]
    QC[Session C<br/>Order C Messages]
    end
    
    subgraph "Consumers - Parallel Processing"
    C1[Consumer 1<br/>Processing Session A]
    C2[Consumer 2<br/>Processing Session B]
    C3[Consumer 3<br/>Processing Session C]
    end
    
    M1 --> QA
    M3 --> QA
    M6 --> QA
    M2 --> QB
    M5 --> QB
    M4 --> QC
    
    QA -->|FIFO within session| C1
    QB -->|FIFO within session| C2
    QC -->|FIFO within session| C3
    
    style QA fill:#4CAF50
    style QB fill:#2196F3
    style QC fill:#FF9800
          </div>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Ordered processing</strong> - Messages within same category processed in order</li>
            <li>‚úÖ <strong>Parallel scaling</strong> - Different categories processed concurrently</li>
            <li>‚úÖ <strong>Eliminates race conditions</strong> - No conflicts from out-of-order processing</li>
            <li>‚úÖ <strong>Flexible categorization</strong> - Scale unit determined by business logic</li>
            <li>‚úÖ <strong>Simplified logic</strong> - No complex ordering workarounds needed</li>
          </ul>

          <h3>Problems and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Category/scale unit</strong> - Identify property to scale on (e.g., order ID, customer ID)</li>
              <li><strong>Throughput limits</strong> - FIFO requirement limits scaling; very high throughput may require reconsidering requirements</li>
              <li><strong>Service capabilities</strong> - Message bus must support one-at-a-time processing within categories</li>
              <li><strong>Evolvability</strong> - Plan for adding new message categories</li>
              <li><strong>Out-of-order arrival</strong> - Use sequence numbers to verify ordering despite network latency</li>
              <li><strong>End-of-sequence indicators</strong> - Consider special flags for last message in transaction</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Messages arrive in order and <strong>must be processed in same order</strong></li>
            <li>Messages can be <strong>categorized</strong> such that category becomes scale unit</li>
            <li>Need to <strong>maintain ordering guarantees</strong> while scaling horizontally</li>
            <li>Different categories can be <strong>processed independently in parallel</strong></li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li><strong>Extremely high throughput</strong> scenarios (millions of messages/minute)</li>
            <li>Messages <strong>cannot be categorized</strong> meaningfully</li>
            <li><strong>No ordering requirements</strong> exist</li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Eliminates race conditions and incorrect message ordering (RE:02, RE:07)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Service Bus Message Sessions:</strong></p>
          
          <ul>
            <li><strong>Sessions</strong> - Group related messages using SessionId property</li>
            <li><strong>FIFO guarantee</strong> - Messages within same session processed in order</li>
            <li><strong>Session locking</strong> - One consumer processes one session at a time</li>
            <li><strong>Peek-lock mode</strong> - Ensures reliable message processing</li>
          </ul>

          <p><strong>Consumer Options:</strong></p>
          <ul>
            <li><strong>Azure Functions</strong> - Service Bus trigger with session enabled</li>
            <li><strong>Logic Apps</strong> - Service Bus peek-lock connector</li>
            <li><strong>Custom applications</strong> - Service Bus SDK with session receiver</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>Ledger Processor - Fan Out to Sessions:</strong></p>
          <pre><code>public class LedgerProcessor
{
    private readonly ServiceBusClient client;
    private readonly ServiceBusSender orderQueueSender;

    public LedgerProcessor(string connectionString)
    {
        client = new ServiceBusClient(connectionString);
        orderQueueSender = client.CreateSender("order-transactions-queue");
    }

    [FunctionName("ProcessLedger")]
    public async Task ProcessLedgerMessages(
        [ServiceBusTrigger("ledger-queue", Connection = "ServiceBusConnection")] 
        ServiceBusReceivedMessage ledgerMessage,
        ILogger log)
    {
        // Ledger contains multiple transactions for different orders
        var ledger = JsonSerializer.Deserialize&lt;Ledger&gt;(ledgerMessage.Body.ToString());
        
        log.LogInformation($"Processing ledger with {ledger.Transactions.Count} transactions");

        // Fan out: Send each transaction to order queue with session ID = order ID
        foreach (var transaction in ledger.Transactions)
        {
            var message = new ServiceBusMessage(JsonSerializer.Serialize(transaction))
            {
                SessionId = transaction.OrderId.ToString(), // Key: Set session to order ID
                MessageId = Guid.NewGuid().ToString(),
                ContentType = "application/json"
            };

            // Add sequence number to verify ordering
            message.ApplicationProperties["SequenceNumber"] = transaction.SequenceNumber;
            message.ApplicationProperties["TransactionType"] = transaction.Type;

            await orderQueueSender.SendMessageAsync(message);
            
            log.LogInformation(
                $"Sent transaction {transaction.Id} for order {transaction.OrderId} " +
                $"to session {message.SessionId}");
        }
    }
}

public class Ledger
{
    public List&lt;OrderTransaction&gt; Transactions { get; set; }
}

public class OrderTransaction
{
    public Guid Id { get; set; }
    public Guid OrderId { get; set; }
    public string Type { get; set; } // Create, Update, Complete, Cancel
    public int SequenceNumber { get; set; }
    public decimal Amount { get; set; }
    public DateTime Timestamp { get; set; }
}</code></pre>

          <p><strong>Order Processor - Session-based Consumer (Azure Functions):</strong></p>
          <pre><code>[FunctionName("ProcessOrderTransactions")]
public async Task ProcessInOrder(
    [ServiceBusTrigger(
        "order-transactions-queue",
        Connection = "ServiceBusConnection",
        IsSessionsEnabled = true)] // Enable session processing
    ServiceBusReceivedMessage message,
    ServiceBusSessionMessageActions sessionActions,
    ILogger log)
{
    var transaction = JsonSerializer.Deserialize&lt;OrderTransaction&gt;(
        message.Body.ToString());
    
    var sessionId = message.SessionId;
    var sequenceNumber = (int)message.ApplicationProperties["SequenceNumber"];
    
    log.LogInformation(
        $"Processing transaction {transaction.Id} for order {sessionId} " +
        $"(sequence: {sequenceNumber})");

    try
    {
        // Get session state to track last processed sequence
        var sessionState = await sessionActions.GetSessionStateAsync();
        int lastSequence = 0;
        
        if (sessionState != null)
        {
            lastSequence = BitConverter.ToInt32(sessionState.ToArray(), 0);
        }

        // Verify sequential processing
        if (sequenceNumber != lastSequence + 1)
        {
            log.LogWarning(
                $"Out of sequence! Expected {lastSequence + 1}, got {sequenceNumber}");
            // Could defer message or handle as needed
        }

        // Process the transaction in order
        await ProcessTransactionAsync(transaction);

        // Update session state with latest sequence
        var newState = new BinaryData(BitConverter.GetBytes(sequenceNumber));
        await sessionActions.SetSessionStateAsync(newState);
        
        log.LogInformation($"Completed transaction {transaction.Id} for order {sessionId}");
    }
    catch (Exception ex)
    {
        log.LogError($"Error processing transaction: {ex.Message}");
        throw; // Will dead-letter after retries
    }
}

private async Task ProcessTransactionAsync(OrderTransaction transaction)
{
    // Business logic to process transaction
    switch (transaction.Type)
    {
        case "Create":
            await CreateOrderAsync(transaction);
            break;
        case "Update":
            await UpdateOrderAsync(transaction);
            break;
        case "Complete":
            await CompleteOrderAsync(transaction);
            break;
        case "Cancel":
            await CancelOrderAsync(transaction);
            break;
    }
}</code></pre>

          <p><strong>Manual Session Processing (SDK):</strong></p>
          <pre><code>public class SessionProcessor
{
    private readonly ServiceBusClient client;

    public async Task ProcessSessionsAsync(CancellationToken cancellationToken)
    {
        var processor = client.CreateSessionProcessor("order-transactions-queue", 
            new ServiceBusSessionProcessorOptions
            {
                MaxConcurrentSessions = 10, // Process 10 orders concurrently
                MaxConcurrentCallsPerSession = 1, // But only 1 message per order at a time
                AutoCompleteMessages = false,
                SessionIdleTimeout = TimeSpan.FromMinutes(1)
            });

        processor.ProcessMessageAsync += async args =>
        {
            var message = args.Message;
            var sessionId = message.SessionId;
            
            Console.WriteLine($"[Session {sessionId}] Processing message {message.MessageId}");
            
            try
            {
                var transaction = JsonSerializer.Deserialize&lt;OrderTransaction&gt;(
                    message.Body.ToString());
                
                await ProcessTransactionAsync(transaction);
                
                // Complete message after successful processing
                await args.CompleteMessageAsync(message);
                
                Console.WriteLine($"[Session {sessionId}] Completed message {message.MessageId}");
            }
            catch (Exception ex)
            {
                Console.WriteLine($"[Session {sessionId}] Error: {ex.Message}");
                await args.AbandonMessageAsync(message);
            }
        };

        processor.ProcessErrorAsync += args =>
        {
            Console.WriteLine($"Error: {args.Exception.Message}");
            return Task.CompletedTask;
        };

        await processor.StartProcessingAsync(cancellationToken);
        
        // Process until cancelled
        await Task.Delay(Timeout.Infinite, cancellationToken);
        
        await processor.StopProcessingAsync();
    }
}</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#competing-consumers"><strong>Competing Consumers</strong></a> - Process messages in parallel across categories</li>
            <li>üîó <a href="#priority-queue"><strong>Priority Queue</strong></a> - Combine with priority for ordered priority processing</li>
            <li>üîó <a href="#claim-check"><strong>Claim Check</strong></a> - Handle large messages in sequential processing</li>
          </ul>
        </section>

        <!-- Health Endpoint Monitoring Pattern -->
        <section id="health-monitoring" role="article">
          <h1>üè• Health Endpoint Monitoring</h1>
          <div class="badges">
            <span class="badge badge-reliability">Reliability</span>
            <span class="badge badge-operational">Operational Excellence</span>
          </div>

          <h2>Context & Problem</h2>
          <p>It's good practice to monitor web applications and back-end services to ensure they're available and performing correctly. However, monitoring cloud services is more difficult than on-premises services because you don't have full control of the hosting environment.</p>
          
          <p>Many factors affect cloud-hosted applications including network latency, performance and availability of underlying systems, and network bandwidth. Services can fail entirely or partially due to any of these factors. You must verify at regular intervals that your service performs correctly to meet required availability levels and SLAs.</p>

          <h2>Solution</h2>
          <p>Implement health monitoring by sending requests to an endpoint on your application. The application should perform the necessary checks and return an indication of its status. A health monitoring check typically combines two factors: checks performed by the application in response to the request, and analysis of results by the monitoring tool.</p>

          <div class="mermaid">
graph TB
    subgraph "External Monitoring"
    Monitor[Monitoring Tool<br/>Azure Monitor]
    TM[Traffic Manager /<br/>Load Balancer]
    end
    
    subgraph "Application"
    Endpoint["/health endpoint"]
    App[Application Logic]
    DB[(Database)]
    Cache[(Cache)]
    Storage[(Storage)]
    External[External API]
    end
    
    Monitor -->|Periodic Probe| Endpoint
    TM -->|Health Check| Endpoint
    Endpoint -->|Check| App
    Endpoint -->|Verify| DB
    Endpoint -->|Test| Cache
    Endpoint -->|Validate| Storage
    Endpoint -->|Ping| External
    
    Endpoint -->|200 OK / 503 Unavailable| Monitor
    Endpoint -->|Health Status| TM
    
    style Endpoint fill:#4CAF50
    style Monitor fill:#2196F3
    style TM fill:#FF9800
          </div>

          <h3>Types of Health Checks</h3>
          
          <h4>Liveness Probe</h4>
          <ul>
            <li>Determines if application is running</li>
            <li>Returns 200 OK if process is alive</li>
            <li>Minimal checks, fast response</li>
          </ul>

          <h4>Readiness Probe</h4>
          <ul>
            <li>Determines if application is ready to handle requests</li>
            <li>Checks dependencies (database, cache, external services)</li>
            <li>Returns 200 OK only when fully ready</li>
            <li>Used by load balancers to route traffic</li>
          </ul>

          <h4>Startup Probe</h4>
          <ul>
            <li>Indicates application initialization complete</li>
            <li>Used for slow-starting applications</li>
            <li>Prevents premature restarts during startup</li>
          </ul>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Availability verification</strong> - Confirm services are running and accessible</li>
            <li>‚úÖ <strong>Performance monitoring</strong> - Measure response times and latency</li>
            <li>‚úÖ <strong>Dependency validation</strong> - Check external dependencies and resources</li>
            <li>‚úÖ <strong>Automatic remediation</strong> - Enable self-healing through automated responses</li>
            <li>‚úÖ <strong>Load balancer integration</strong> - Remove unhealthy instances from rotation</li>
            <li>‚úÖ <strong>Regional monitoring</strong> - Test from multiple geographic locations</li>
          </ul>

          <h3>Problems and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Response validation</strong> - Determine if 200 OK is sufficient or if content validation needed</li>
              <li><strong>Multiple endpoints</strong> - Consider separate endpoints for core vs. lower-priority services</li>
              <li><strong>Endpoint design</strong> - Decide if same endpoint for monitoring and general access</li>
              <li><strong>Information to collect</strong> - Balance detail with performance impact</li>
              <li><strong>Caching endpoint status</strong> - Avoid excessive processing on every check</li>
              <li><strong>Security</strong> - Protect endpoints from public access, use authentication or obscure paths</li>
              <li><strong>Monitoring agent validation</strong> - Ensure monitoring system itself performs correctly</li>
              <li><strong>Check frequency</strong> - Balance between rapid detection and overhead</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use for:</strong></p>
          <ul>
            <li>Monitoring <strong>websites and web applications</strong> to verify availability</li>
            <li>Checking for <strong>correct operation</strong> beyond just process running</li>
            <li>Monitoring <strong>middle-tier or shared services</strong> to detect failures</li>
            <li><strong>Complementing instrumentation</strong> like performance counters and error handlers</li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Support alerting, dashboarding, and self-healing (RE:07, RE:10)</li>
            <li>üîß <strong>Operational Excellence</strong> - Standardize health endpoints for triage (OE:07)</li>
            <li>‚ö° <strong>Performance Efficiency</strong> - Improve load balancing by routing to healthy nodes only (PE:05)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Services for Health Monitoring:</strong></p>
          
          <ul>
            <li><strong>Azure Monitor</strong> - Comprehensive monitoring with alert rules</li>
            <li><strong>Application Insights</strong> - Availability tests and monitoring</li>
            <li><strong>Azure App Service</strong> - Built-in health check feature</li>
            <li><strong>Azure Traffic Manager</strong> - Health probes for endpoint routing</li>
            <li><strong>Azure Front Door</strong> - Health probes with global routing</li>
            <li><strong>Azure Load Balancer</strong> - Health probes for backend pools</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>ASP.NET Core Health Checks:</strong></p>
          <pre><code>// Program.cs or Startup.cs
var builder = WebApplication.CreateBuilder(args);

// Add health checks
builder.Services.AddHealthChecks()
    .AddCheck("self", () => HealthCheckResult.Healthy("Application is running"))
    .AddSqlServer(
        connectionString: builder.Configuration.GetConnectionString("Database"),
        name: "database",
        failureStatus: HealthStatus.Degraded,
        tags: new[] { "db", "sql" })
    .AddAzureBlobStorage(
        connectionString: builder.Configuration.GetConnectionString("BlobStorage"),
        name: "blob-storage",
        tags: new[] { "storage" })
    .AddRedis(
        redisConnectionString: builder.Configuration.GetConnectionString("Redis"),
        name: "redis-cache",
        failureStatus: HealthStatus.Degraded,
        tags: new[] { "cache" })
    .AddUrlGroup(
        uri: new Uri("https://api.external-service.com/health"),
        name: "external-api",
        failureStatus: HealthStatus.Degraded,
        tags: new[] { "external" });

var app = builder.Build();

// Map health check endpoints
app.MapHealthChecks("/health/live", new HealthCheckOptions
{
    // Liveness probe - just check if app is running
    Predicate = _ => false // No checks, just return 200 OK
});

app.MapHealthChecks("/health/ready", new HealthCheckOptions
{
    // Readiness probe - check all dependencies
    Predicate = check => true, // All checks
    ResponseWriter = async (context, report) =>
    {
        context.Response.ContentType = "application/json";
        
        var result = JsonSerializer.Serialize(new
        {
            status = report.Status.ToString(),
            checks = report.Entries.Select(e => new
            {
                name = e.Key,
                status = e.Value.Status.ToString(),
                description = e.Value.Description,
                duration = e.Value.Duration.TotalMilliseconds
            }),
            totalDuration = report.TotalDuration.TotalMilliseconds
        });
        
        await context.Response.WriteAsync(result);
    }
});

app.MapHealthChecks("/health/startup", new HealthCheckOptions
{
    // Startup probe - check critical dependencies only
    Predicate = check => check.Tags.Contains("db")
});

app.Run();</code></pre>

          <p><strong>Custom Health Check Implementation:</strong></p>
          <pre><code>public class DatabaseHealthCheck : IHealthCheck
{
    private readonly IDbConnection connection;
    private readonly ILogger&lt;DatabaseHealthCheck&gt; logger;

    public DatabaseHealthCheck(IDbConnection connection, ILogger&lt;DatabaseHealthCheck&gt; logger)
    {
        this.connection = connection;
        this.logger = logger;
    }

    public async Task&lt;HealthCheckResult&gt; CheckHealthAsync(
        HealthCheckContext context,
        CancellationToken cancellationToken = default)
    {
        try
        {
            var stopwatch = Stopwatch.StartNew();
            
            // Simple query to test database connectivity
            using var command = connection.CreateCommand();
            command.CommandText = "SELECT 1";
            command.CommandTimeout = 5; // 5 second timeout
            
            await command.ExecuteScalarAsync(cancellationToken);
            
            stopwatch.Stop();
            
            var responseTime = stopwatch.ElapsedMilliseconds;
            
            if (responseTime > 1000)
            {
                return HealthCheckResult.Degraded(
                    $"Database responding slowly ({responseTime}ms)",
                    data: new Dictionary&lt;string, object&gt;
                    {
                        { "responseTime", responseTime }
                    });
            }
            
            return HealthCheckResult.Healthy(
                $"Database is healthy ({responseTime}ms)",
                data: new Dictionary&lt;string, object&gt;
                {
                    { "responseTime", responseTime }
                });
        }
        catch (Exception ex)
        {
            logger.LogError(ex, "Database health check failed");
            
            return HealthCheckResult.Unhealthy(
                "Database is unavailable",
                exception: ex);
        }
    }
}</code></pre>

          <p><strong>Azure App Service Health Check Configuration:</strong></p>
          <pre><code>// Azure CLI - Enable App Service health check
az webapp config set \
    --resource-group myResourceGroup \
    --name myWebApp \
    --health-check-path "/health/ready"

// Bicep/ARM Template
resource webApp 'Microsoft.Web/sites@2022-03-01' = {
  name: 'myWebApp'
  location: location
  properties: {
    siteConfig: {
      healthCheckPath: '/health/ready'
      // Remove unhealthy instances after 10 minutes
      healthCheckEvictionTimeInMin: 10
    }
  }
}</code></pre>

          <p><strong>Traffic Manager Health Probe:</strong></p>
          <pre><code>// Configure Traffic Manager endpoint monitoring
resource tmProfile 'Microsoft.Network/trafficmanagerprofiles@2022-04-01' = {
  name: 'myTrafficManager'
  location: 'global'
  properties: {
    trafficRoutingMethod: 'Performance'
    monitorConfig: {
      protocol: 'HTTPS'
      port: 443
      path: '/health/ready'
      intervalInSeconds: 30
      toleratedNumberOfFailures: 3
      timeoutInSeconds: 10
      expectedStatusCodeRanges: [
        {
          min: 200
          max: 202
        }
      ]
    }
  }
}</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#external-config"><strong>External Configuration Store</strong></a> - Manage health check thresholds</li>
            <li>üîó <a href="#circuit-breaker"><strong>Circuit Breaker</strong></a> - Use health checks to trigger circuit breaker</li>
            <li>üîó <a href="#gateway-routing"><strong>Gateway Routing</strong></a> - Route based on health status</li>
          </ul>
        </section>

        <!-- Retry Pattern -->
        <section id="retry" role="article">
          <h1>üîÑ Retry</h1>
          <div class="badges">
            <span class="badge badge-reliability">Reliability</span>
          </div>

          <h2>Context & Problem</h2>
          <p>An application that communicates with elements running in the cloud must be sensitive to transient faults that can occur in this environment. Faults include momentary loss of network connectivity, temporary unavailability of a service, or timeouts that occur when a service is busy.</p>
          
          <p>These faults are typically self-correcting, and if the action that triggered a fault is repeated after a suitable delay, it's likely to be successful. For example, a database service processing many concurrent requests might implement a throttling strategy that temporarily rejects requests until its workload eases.</p>

          <h2>Solution</h2>
          <p>If an application detects a failure when trying to send a request to a remote service, it can handle the failure using retry strategies. The application should wrap all attempts to access a remote service in code that implements a retry policy.</p>

          <div class="mermaid">
sequenceDiagram
    participant App as Application
    participant Retry as Retry Logic
    participant Service as Remote Service
    
    App->>Retry: Request
    Retry->>Service: Attempt 1
    Service--xRetry: Transient Failure
    Note over Retry: Wait (exponential backoff)
    
    Retry->>Service: Attempt 2
    Service--xRetry: Transient Failure
    Note over Retry: Wait (longer delay)
    
    Retry->>Service: Attempt 3
    Service-->>Retry: Success ‚úì
    Retry-->>App: Response
    
    Note over Retry: If max retries exceeded,<br/>throw exception
          </div>

          <h3>Retry Strategies</h3>
          
          <h4>Cancel</h4>
          <ul>
            <li>Fault isn't transient or unlikely to succeed if repeated</li>
            <li>Cancel operation and report exception</li>
            <li>Examples: Invalid credentials, resource not found</li>
          </ul>

          <h4>Retry Immediately</h4>
          <ul>
            <li>Fault is unusual or rare (e.g., corrupted network packet)</li>
            <li>Retry request immediately without delay</li>
            <li>Use sparingly to avoid overwhelming service</li>
          </ul>

          <h4>Retry After Delay</h4>
          <ul>
            <li>Fault caused by connectivity or busy failures</li>
            <li>Wait short period for connectivity issues or backlog to clear</li>
            <li><strong>Fixed interval:</strong> Wait same time between retries</li>
            <li><strong>Incremental interval:</strong> Increase delay linearly</li>
            <li><strong>Exponential backoff:</strong> Double delay after each attempt</li>
            <li><strong>Exponential backoff with jitter:</strong> Add randomness to prevent thundering herd</li>
          </ul>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Resilience</strong> - Handle transient faults transparently</li>
            <li>‚úÖ <strong>Improved availability</strong> - Automatic recovery from temporary issues</li>
            <li>‚úÖ <strong>Reduced errors</strong> - Minimize user-facing failures from transient faults</li>
            <li>‚úÖ <strong>Better user experience</strong> - Requests succeed without user intervention</li>
          </ul>

          <h3>Problems and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Idempotency</strong> - Ensure operations safe to retry without side effects</li>
              <li><strong>Exception types</strong> - Adjust retry policy based on exception type (transient vs. permanent)</li>
              <li><strong>Performance impact</strong> - Tune policy to match business requirements; fail fast for non-critical operations</li>
              <li><strong>Aggressive retries</strong> - Can further degrade busy service running at capacity</li>
              <li><strong>Circuit breaker</strong> - Combine with circuit breaker to prevent futile retries</li>
              <li><strong>Transaction consistency</strong> - Fine-tune for transactional operations</li>
              <li><strong>Logging</strong> - Log early failures as informational, only final failure as error</li>
              <li><strong>Nested retry policies</strong> - Avoid excessive delays from multiple retry layers</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Application could experience <strong>transient faults</strong> with remote services</li>
            <li>Faults are expected to be <strong>short-lived</strong></li>
            <li>Repeating request has <strong>reasonable chance of success</strong></li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>Fault is likely to be <strong>long-lasting</strong> - wastes time and resources</li>
            <li>Handling failures that <strong>aren't transient</strong> (business logic errors)</li>
            <li>Alternative to addressing <strong>scalability issues</strong> - scale up instead</li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Mitigate transient faults to improve resilience (RE:07)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Built-in Retry Support:</strong></p>
          
          <ul>
            <li><strong>Azure SDK</strong> - Most client libraries have built-in retry mechanisms</li>
            <li><strong>Entity Framework</strong> - Connection resiliency for database operations</li>
            <li><strong>Azure Storage</strong> - Retry policy with exponential backoff</li>
            <li><strong>Service Bus</strong> - Automatic retry for transient failures</li>
            <li><strong>Cosmos DB</strong> - Retry on throttling (429 errors)</li>
          </ul>

          <p><strong>Retry Frameworks:</strong></p>
          <ul>
            <li><strong>Polly (.NET)</strong> - Comprehensive resilience and retry library</li>
            <li><strong>Resilience4j (Java)</strong> - Fault tolerance library</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>Using Polly for Retry Logic:</strong></p>
          <pre><code>// Install: Polly
using Polly;
using Polly.Retry;

// Simple exponential backoff retry policy
var retryPolicy = Policy
    .Handle&lt;HttpRequestException&gt;()
    .Or&lt;TimeoutException&gt;()
    .WaitAndRetryAsync(
        retryCount: 3,
        sleepDurationProvider: attempt => TimeSpan.FromSeconds(Math.Pow(2, attempt)),
        onRetry: (exception, timeSpan, retryCount, context) =>
        {
            logger.LogWarning(
                $"Retry {retryCount} after {timeSpan.TotalSeconds}s delay " +
                $"due to {exception.GetType().Name}: {exception.Message}");
        });

// Use the policy
var response = await retryPolicy.ExecuteAsync(async () =>
{
    return await httpClient.GetAsync("https://api.example.com/data");
});

// Exponential backoff with jitter (recommended)
var jitteredRetryPolicy = Policy
    .Handle&lt;HttpRequestException&gt;()
    .WaitAndRetryAsync(
        retryCount: 5,
        sleepDurationProvider: (attempt, context) =>
        {
            var exponentialDelay = TimeSpan.FromSeconds(Math.Pow(2, attempt));
            var jitter = TimeSpan.FromMilliseconds(Random.Shared.Next(0, 1000));
            return exponentialDelay + jitter;
        },
        onRetry: (exception, timeSpan, retryCount, context) =>
        {
            logger.LogInformation(
                $"Attempt {retryCount} failed. Waiting {timeSpan.TotalSeconds}s before retry.");
        });

// Combine retry with circuit breaker
var circuitBreakerPolicy = Policy
    .Handle&lt;HttpRequestException&gt;()
    .CircuitBreakerAsync(
        exceptionsAllowedBeforeBreaking: 3,
        durationOfBreak: TimeSpan.FromSeconds(30),
        onBreak: (exception, duration) =>
        {
            logger.LogError("Circuit breaker opened for {Duration}s", duration.TotalSeconds);
        },
        onReset: () =>
        {
            logger.LogInformation("Circuit breaker reset");
        });

var combinedPolicy = Policy.WrapAsync(jitteredRetryPolicy, circuitBreakerPolicy);

await combinedPolicy.ExecuteAsync(async () =>
{
    return await httpClient.PostAsync("https://api.example.com/orders", content);
});</code></pre>

          <p><strong>Azure Storage SDK with Retry:</strong></p>
          <pre><code>// Azure Blob Storage with custom retry policy
var blobClientOptions = new BlobClientOptions
{
    Retry =
    {
        MaxRetries = 5,
        Delay = TimeSpan.FromSeconds(2),
        MaxDelay = TimeSpan.FromSeconds(30),
        Mode = RetryMode.Exponential,
        NetworkTimeout = TimeSpan.FromSeconds(100)
    }
};

var blobClient = new BlobServiceClient(connectionString, blobClientOptions);

// Use the client - retries handled automatically
var containerClient = blobClient.GetBlobContainerClient("mycontainer");
await containerClient.CreateIfNotExistsAsync();</code></pre>

          <p><strong>Entity Framework Core with Connection Resiliency:</strong></p>
          <pre><code>services.AddDbContext&lt;ApplicationDbContext&gt;(options =>
{
    options.UseSqlServer(
        connectionString,
        sqlServerOptionsAction: sqlOptions =>
        {
            sqlOptions.EnableRetryOnFailure(
                maxRetryCount: 5,
                maxRetryDelay: TimeSpan.FromSeconds(30),
                errorNumbersToAdd: null);
        });
});</code></pre>

          <p><strong>Custom Retry Implementation:</strong></p>
          <pre><code>public class RetryHelper
{
    public static async Task&lt;T&gt; ExecuteWithRetryAsync&lt;T&gt;(
        Func&lt;Task&lt;T&gt;&gt; operation,
        int maxRetries = 3,
        TimeSpan? initialDelay = null,
        Func&lt;Exception, bool&gt; shouldRetry = null)
    {
        var delay = initialDelay ?? TimeSpan.FromSeconds(1);
        shouldRetry ??= ex => ex is HttpRequestException || ex is TimeoutException;

        for (int attempt = 0; attempt &lt;= maxRetries; attempt++)
        {
            try
            {
                return await operation();
            }
            catch (Exception ex) when (attempt &lt; maxRetries && shouldRetry(ex))
            {
                var waitTime = TimeSpan.FromMilliseconds(
                    delay.TotalMilliseconds * Math.Pow(2, attempt));
                
                Console.WriteLine(
                    $"Attempt {attempt + 1} failed: {ex.Message}. " +
                    $"Retrying in {waitTime.TotalSeconds}s...");
                
                await Task.Delay(waitTime);
            }
        }

        throw new InvalidOperationException($"Operation failed after {maxRetries} retries");
    }
}

// Usage
var result = await RetryHelper.ExecuteWithRetryAsync(async () =>
{
    return await httpClient.GetStringAsync("https://api.example.com/data");
}, maxRetries: 5);</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#circuit-breaker"><strong>Circuit Breaker</strong></a> - Combine for comprehensive fault handling</li>
            <li>üîó <a href="#health-monitoring"><strong>Health Endpoint Monitoring</strong></a> - Monitor service health before retry</li>
            <li>üîó <a href="#throttling"><strong>Throttling</strong></a> - Services may throttle, requiring retry with backoff</li>
          </ul>
        </section>

        <!-- Saga Pattern -->
        <section id="saga" role="article">
          <h1>üìú Saga</h1>
          <div class="badges">
            <span class="badge badge-reliability">Reliability</span>
            <span class="badge badge-data">Data Management</span>
          </div>

          <h2>Context & Problem</h2>
          <p>Microservices architectures typically assign a dedicated database to each microservice for data encapsulation, appropriate technology selection, and independent scaling. However, traditional ACID transactions aren't directly applicable to multiple independently managed data stores.</p>
          
          <p>Cross-service data consistency becomes complicated. When a business transaction spans multiple services, maintaining data consistency without distributed transactions requires a different approach.</p>

          <h2>Solution</h2>
          <p>The Saga pattern manages transactions by breaking them into a sequence of local transactions. Each local transaction completes its work atomically within a single service, updates the service's database, and initiates the next transaction via an event or message. If a local transaction fails, the saga performs compensating transactions to reverse preceding changes.</p>

          <div class="mermaid">
sequenceDiagram
    participant Order as Order Service
    participant Payment as Payment Service
    participant Inventory as Inventory Service
    participant Shipping as Shipping Service
    
    Note over Order,Shipping: Happy Path - All Steps Succeed
    Order->>Order: Create Order (Compensable)
    Order->>Payment: Process Payment
    Payment->>Payment: Charge Card (Pivot - Point of No Return)
    Payment->>Inventory: Reserve Items
    Inventory->>Inventory: Update Stock (Retryable)
    Inventory->>Shipping: Ship Order
    Shipping->>Shipping: Create Shipment (Retryable)
    
    Note over Order,Shipping: Failure Scenario - Payment Fails
    Order->>Order: Create Order
    Order-xPayment: Process Payment ‚úó
    Note over Order,Payment: Compensating Transaction
    Order->>Order: Cancel Order
          </div>

          <h3>Key Concepts</h3>
          
          <h4>Compensable Transactions</h4>
          <ul>
            <li>Can be undone by other transactions with opposite effect</li>
            <li>If step fails, compensating transactions undo changes</li>
          </ul>

          <h4>Pivot Transaction</h4>
          <ul>
            <li>Point of no return in the saga</li>
            <li>After pivot succeeds, compensable transactions no longer relevant</li>
            <li>Can be last undoable transaction or first retryable operation</li>
          </ul>

          <h4>Retryable Transactions</h4>
          <ul>
            <li>Follow the pivot transaction</li>
            <li>Idempotent operations that can be retried</li>
            <li>Ensure saga reaches final consistent state</li>
          </ul>

          <h3>Implementation Approaches</h3>
          
          <h4>Choreography</h4>
          <div class="mermaid">
graph LR
    A[Service A<br/>Event: OrderCreated]
    B[Service B<br/>Event: PaymentProcessed]
    C[Service C<br/>Event: InventoryReserved]
    D[Service D<br/>Event: OrderShipped]
    
    A -->|Publishes| B
    B -->|Publishes| C
    C -->|Publishes| D
    
    style A fill:#4CAF50
    style B fill:#2196F3
    style C fill:#FF9800
    style D fill:#9C27B0
          </div>
          <p><strong>Pros:</strong> Simple workflows, no single point of failure, no coordination service required</p>
          <p><strong>Cons:</strong> Complex workflows confusing, risk of cyclic dependencies, difficult integration testing</p>

          <h4>Orchestration</h4>
          <div class="mermaid">
graph TB
    Orch[Saga Orchestrator<br/>Workflow Manager]
    A[Service A]
    B[Service B]
    C[Service C]
    D[Service D]
    
    Orch -->|Command| A
    Orch -->|Command| B
    Orch -->|Command| C
    Orch -->|Command| D
    
    A -->|Response| Orch
    B -->|Response| Orch
    C -->|Response| Orch
    D -->|Response| Orch
    
    style Orch fill:#F44336
          </div>
          <p><strong>Pros:</strong> Better for complex workflows, avoids cyclic dependencies, clear separation of responsibilities</p>
          <p><strong>Cons:</strong> Additional design complexity, orchestrator is single point of failure</p>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Data consistency</strong> - Maintain consistency across distributed services</li>
            <li>‚úÖ <strong>No distributed locks</strong> - Avoid complexity of distributed transactions</li>
            <li>‚úÖ <strong>Service autonomy</strong> - Each service manages own data</li>
            <li>‚úÖ <strong>Eventual consistency</strong> - System reaches consistent state eventually</li>
          </ul>

          <h3>Problems and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Design shift</strong> - Requires different mindset for transaction coordination</li>
              <li><strong>Debugging complexity</strong> - More complex as participating services grow</li>
              <li><strong>Irreversible changes</strong> - Can't roll back database commits</li>
              <li><strong>Idempotence required</strong> - Handle transient failures and repeated operations</li>
              <li><strong>Monitoring essential</strong> - Track saga workflow for operational oversight</li>
              <li><strong>Compensating transaction limits</strong> - Might not always succeed, leaving inconsistent state</li>
              <li><strong>Data anomalies</strong> - Lost updates, dirty reads, fuzzy reads possible without isolation</li>
            </ul>
          </div>

          <h3>Strategies to Address Data Anomalies</h3>
          <ul>
            <li><strong>Semantic lock</strong> - Use application-level locks during updates</li>
            <li><strong>Commutative updates</strong> - Design updates to work in any order</li>
            <li><strong>Pessimistic view</strong> - Reorder saga to eliminate dirty reads</li>
            <li><strong>Reread values</strong> - Confirm data unchanged before update</li>
            <li><strong>Version files</strong> - Log all operations for correct sequencing</li>
            <li><strong>Risk-based concurrency</strong> - Choose mechanism based on business risk</li>
          </ul>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Need <strong>data consistency in distributed system</strong> without tight coupling</li>
            <li>Need to <strong>roll back or compensate</strong> if operation fails</li>
            <li>Business transaction <strong>spans multiple microservices</strong></li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>Transactions are <strong>tightly coupled</strong></li>
            <li>Compensating transactions occur in <strong>earlier participants</strong></li>
            <li>There are <strong>cyclic dependencies</strong></li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Handle failures across distributed services (RE:07)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Services for Saga Pattern:</strong></p>
          
          <ul>
            <li><strong>Azure Durable Functions</strong> - Orchestration with built-in state management</li>
            <li><strong>Azure Logic Apps</strong> - Visual workflow designer for orchestration</li>
            <li><strong>Azure Service Bus</strong> - Messaging for choreography approach</li>
            <li><strong>Azure Event Grid</strong> - Event-driven choreography</li>
            <li><strong>Azure Cosmos DB</strong> - Change feed for event sourcing</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>Saga Orchestration with Azure Durable Functions:</strong></p>
          <pre><code>[FunctionName("OrderSagaOrchestrator")]
public async Task&lt;OrderResult&gt; RunOrderSaga(
    [OrchestrationTrigger] IDurableOrchestrationContext context,
    ILogger log)
{
    var order = context.GetInput&lt;Order&gt;();
    log = context.CreateReplaySafeLogger(log);
    
    string orderId = null;
    bool paymentProcessed = false;
    bool inventoryReserved = false;
    
    try
    {
        // Step 1: Create Order (Compensable)
        orderId = await context.CallActivityAsync&lt;string&gt;("CreateOrder", order);
        log.LogInformation($"Order created: {orderId}");
        
        // Step 2: Process Payment (Pivot - Point of No Return)
        paymentProcessed = await context.CallActivityAsync&lt;bool&gt;(
            "ProcessPayment",
            new { orderId, amount = order.TotalAmount });
        
        if (!paymentProcessed)
        {
            throw new PaymentFailedException("Payment processing failed");
        }
        
        log.LogInformation($"Payment processed for order {orderId}");
        
        // Step 3: Reserve Inventory (Retryable)
        inventoryReserved = await context.CallActivityWithRetryAsync&lt;bool&gt;(
            "ReserveInventory",
            new RetryOptions(TimeSpan.FromSeconds(30), 3),
            new { orderId, items = order.Items });
        
        log.LogInformation($"Inventory reserved for order {orderId}");
        
        // Step 4: Schedule Shipping (Retryable)
        await context.CallActivityWithRetryAsync(
            "ScheduleShipping",
            new RetryOptions(TimeSpan.FromSeconds(30), 3),
            orderId);
        
        log.LogInformation($"Shipping scheduled for order {orderId}");
        
        return new OrderResult
        {
            Success = true,
            OrderId = orderId,
            Message = "Order completed successfully"
        };
    }
    catch (Exception ex)
    {
        log.LogError($"Saga failed for order {orderId}: {ex.Message}");
        
        // Compensating Transactions (in reverse order)
        if (inventoryReserved)
        {
            await context.CallActivityAsync("ReleaseInventory", orderId);
            log.LogInformation($"Compensating: Inventory released for order {orderId}");
        }
        
        if (paymentProcessed)
        {
            await context.CallActivityAsync("RefundPayment", orderId);
            log.LogInformation($"Compensating: Payment refunded for order {orderId}");
        }
        
        if (!string.IsNullOrEmpty(orderId))
        {
            await context.CallActivityAsync("CancelOrder", orderId);
            log.LogInformation($"Compensating: Order cancelled {orderId}");
        }
        
        return new OrderResult
        {
            Success = false,
            OrderId = orderId,
            Message = $"Order failed: {ex.Message}"
        };
    }
}

// Activity Functions
[FunctionName("CreateOrder")]
public async Task&lt;string&gt; CreateOrder([ActivityTrigger] Order order)
{
    var orderId = Guid.NewGuid().ToString();
    await orderRepository.CreateAsync(orderId, order);
    return orderId;
}

[FunctionName("ProcessPayment")]
public async Task&lt;bool&gt; ProcessPayment([ActivityTrigger] dynamic input)
{
    return await paymentService.ChargeAsync(input.orderId, input.amount);
}

[FunctionName("ReserveInventory")]
public async Task&lt;bool&gt; ReserveInventory([ActivityTrigger] dynamic input)
{
    return await inventoryService.ReserveAsync(input.orderId, input.items);
}

[FunctionName("CancelOrder")]
public async Task CancelOrder([ActivityTrigger] string orderId)
{
    await orderRepository.UpdateStatusAsync(orderId, "Cancelled");
}

[FunctionName("RefundPayment")]
public async Task RefundPayment([ActivityTrigger] string orderId)
{
    await paymentService.RefundAsync(orderId);
}

[FunctionName("ReleaseInventory")]
public async Task ReleaseInventory([ActivityTrigger] string orderId)
{
    await inventoryService.ReleaseAsync(orderId);
}</code></pre>

          <p><strong>Saga Choreography with Events:</strong></p>
          <pre><code>// Order Service - Initiates saga
public class OrderService
{
    public async Task CreateOrderAsync(Order order)
    {
        // Save order locally
        await repository.SaveAsync(order);
        
        // Publish event to start saga
        await eventBus.PublishAsync(new OrderCreatedEvent
        {
            OrderId = order.Id,
            CustomerId = order.CustomerId,
            Items = order.Items,
            TotalAmount = order.TotalAmount
        });
    }
}

// Payment Service - Listens and publishes
public class PaymentEventHandler
{
    [FunctionName("HandleOrderCreated")]
    public async Task Handle(
        [ServiceBusTrigger("order-created", Connection = "ServiceBus")] OrderCreatedEvent evt)
    {
        try
        {
            // Process payment locally
            var success = await paymentService.ProcessAsync(evt.OrderId, evt.TotalAmount);
            
            if (success)
            {
                // Publish success event
                await eventBus.PublishAsync(new PaymentProcessedEvent
                {
                    OrderId = evt.OrderId,
                    Amount = evt.TotalAmount
                });
            }
            else
            {
                // Publish failure event to trigger compensation
                await eventBus.PublishAsync(new PaymentFailedEvent
                {
                    OrderId = evt.OrderId,
                    Reason = "Insufficient funds"
                });
            }
        }
        catch (Exception ex)
        {
            // Publish failure event
            await eventBus.PublishAsync(new PaymentFailedEvent
            {
                OrderId = evt.OrderId,
                Reason = ex.Message
            });
        }
    }
}

// Order Service - Compensation handler
[FunctionName("HandlePaymentFailed")]
public async Task HandleCompensation(
    [ServiceBusTrigger("payment-failed", Connection = "ServiceBus")] PaymentFailedEvent evt)
{
    // Compensate: Cancel the order
    await orderRepository.UpdateStatusAsync(evt.OrderId, "Cancelled");
}</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#choreography"><strong>Choreography</strong></a> - Event-driven saga coordination</li>
            <li>üîó <a href="#compensating-transaction"><strong>Compensating Transaction</strong></a> - Undo operations in saga</li>
            <li>üîó <a href="#retry"><strong>Retry</strong></a> - Handle transient failures in saga steps</li>
            <li>üîó <a href="#circuit-breaker"><strong>Circuit Breaker</strong></a> - Handle persistent failures</li>
          </ul>
        </section>

        <!-- Index Table Pattern -->
        <section id="index-table" role="article">
          <h1>üìá Index Table</h1>
          <div class="badges">
            <span class="badge badge-data">Data Management</span>
            <span class="badge badge-performance">Performance</span>
          </div>

          <h2>Context & Problem</h2>
          <p>Many data stores organize data for a collection of entities using the primary key. An application can use this key to locate and retrieve data efficiently. However, the application might not be able to use the primary key if it needs to retrieve data based on some other field.</p>
          
          <p>For example, in a customer database with Customer ID as the primary key, an application can't efficiently query customers by town without scanning every customer record. Many relational databases support secondary indexes, but some NoSQL data stores used by cloud applications don't provide an equivalent feature.</p>

          <h2>Solution</h2>
          <p>If the data store doesn't support secondary indexes, manually emulate them by creating your own index tables. An index table organizes data by a specified key, allowing applications to quickly locate data using keys other than the primary key.</p>

          <div class="mermaid">
graph TB
    subgraph "Primary Data Store"
    FactTable[Fact Table<br/>Primary Key: CustomerID<br/>Contains all customer data]
    end
    
    subgraph "Index Tables"
    TownIndex[Town Index Table<br/>Key: Town<br/>Value: CustomerID]
    NameIndex[Last Name Index Table<br/>Key: LastName<br/>Value: CustomerID]
    end
    
    subgraph "Query Patterns"
    QueryTown[Query by Town]
    QueryName[Query by Last Name]
    end
    
    QueryTown -->|1. Lookup| TownIndex
    TownIndex -->|2. Get CustomerID| FactTable
    QueryName -->|1. Lookup| NameIndex
    NameIndex -->|2. Get CustomerID| FactTable
    
    style FactTable fill:#4CAF50
    style TownIndex fill:#2196F3
    style NameIndex fill:#FF9800
          </div>

          <h3>Three Strategies for Index Tables</h3>
          
          <h4>1. Complete Denormalization</h4>
          <p>Duplicate all data in each index table organized by different keys. Best for relatively static data.</p>
          
          <h4>2. Normalized with References</h4>
          <p>Index table contains only the secondary key and primary key reference. Saves space but requires two lookups.</p>
          
          <h4>3. Partial Denormalization</h4>
          <p>Duplicate frequently retrieved fields in index table, reference fact table for other fields. Balances performance and storage.</p>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Improved query performance</strong> - Fast lookups using non-primary keys</li>
            <li>‚úÖ <strong>Support for multiple access patterns</strong> - Query data using different attributes</li>
            <li>‚úÖ <strong>Reduced scan operations</strong> - Avoid full table scans for non-primary key queries</li>
            <li>‚úÖ <strong>Composite key support</strong> - Create indexes on combination of attributes</li>
            <li>‚úÖ <strong>Sharded data optimization</strong> - Improve query performance over sharded datasets</li>
          </ul>

          <h3>Problems and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Maintenance overhead</strong> - Secondary indexes require effort to maintain consistency</li>
              <li><strong>Storage costs</strong> - Duplicating data increases storage requirements</li>
              <li><strong>Two-lookup penalty</strong> - Normalized indexes require two operations to fetch data</li>
              <li><strong>Eventual consistency</strong> - System might experience temporary inconsistency during updates</li>
              <li><strong>Write performance</strong> - Updates must be applied to multiple index tables</li>
              <li><strong>Selective creation</strong> - Only create indexes for frequently performed queries</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Application frequently needs to retrieve data using a <strong>key other than the primary key</strong></li>
            <li>Data store <strong>doesn't support secondary indexes</strong> (e.g., some NoSQL databases)</li>
            <li>Need to support <strong>multiple query patterns</strong> efficiently</li>
            <li>Working with <strong>sharded data</strong> and need fast lookups</li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>Data is <strong>highly volatile</strong> - index becomes outdated quickly</li>
            <li>Secondary key field is <strong>non-discriminating</strong> (low cardinality like gender)</li>
            <li>Data values are <strong>highly skewed</strong> (90% of records have same value)</li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Enables data partitioning strategies and failover approaches (RE:06, RE:09)</li>
            <li>‚ö° <strong>Performance Efficiency</strong> - Optimizes data access patterns and query performance (PE:05, PE:08)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Storage Tables Example:</strong></p>
          
          <p>Azure Storage Tables support sharding using partition keys. Index tables work particularly well with this model.</p>

          <h3>Example Code</h3>
          <p><strong>Cosmos DB Index Table Implementation:</strong></p>
          <pre><code>// Fact table (primary store) - Organized by Customer ID
public class Customer
{
    [JsonProperty("id")]
    public string Id { get; set; } // CustomerID
    
    [JsonProperty("firstName")]
    public string FirstName { get; set; }
    
    [JsonProperty("lastName")]
    public string LastName { get; set; }
    
    [JsonProperty("email")]
    public string Email { get; set; }
    
    [JsonProperty("town")]
    public string Town { get; set; }
    
    [JsonProperty("country")]
    public string Country { get; set; }
}

// Index table for Town-based lookups
public class CustomerTownIndex
{
    [JsonProperty("id")]
    public string Id { get; set; } // Composite: Town|CustomerId
    
    [JsonProperty("partitionKey")]
    public string PartitionKey { get; set; } // Town (for sharding)
    
    [JsonProperty("customerId")]
    public string CustomerId { get; set; }
    
    // Denormalized frequently accessed fields
    [JsonProperty("firstName")]
    public string FirstName { get; set; }
    
    [JsonProperty("lastName")]
    public string LastName { get; set; }
}

// Service for managing customers with index tables
public class CustomerService
{
    private readonly Container customersContainer;
    private readonly Container townIndexContainer;
    
    public CustomerService(CosmosClient cosmosClient, string databaseName)
    {
        var database = cosmosClient.GetDatabase(databaseName);
        customersContainer = database.GetContainer("customers");
        townIndexContainer = database.GetContainer("customers-town-index");
    }
    
    // Insert customer with index table update
    public async Task CreateCustomerAsync(Customer customer)
    {
        // Insert into main customer container
        await customersContainer.CreateItemAsync(customer, new PartitionKey(customer.Id));
        
        // Insert into town index
        var townIndex = new CustomerTownIndex
        {
            Id = $"{customer.Town}|{customer.Id}",
            PartitionKey = customer.Town,
            CustomerId = customer.Id,
            FirstName = customer.FirstName,
            LastName = customer.LastName
        };
        
        await townIndexContainer.CreateItemAsync(townIndex, new PartitionKey(customer.Town));
    }
    
    // Query by town using index table
    public async Task&lt;List&lt;Customer&gt;&gt; GetCustomersByTownAsync(string town)
    {
        var query = new QueryDefinition(
            "SELECT * FROM c WHERE c.partitionKey = @town")
            .WithParameter("@town", town);
        
        var results = new List&lt;Customer&gt;();
        
        using var iterator = townIndexContainer.GetItemQueryIterator&lt;CustomerTownIndex&gt;(
            query,
            requestOptions: new QueryRequestOptions
            {
                PartitionKey = new PartitionKey(town)
            });
        
        while (iterator.HasMoreResults)
        {
            var response = await iterator.ReadNextAsync();
            
            foreach (var indexEntry in response)
            {
                // Fetch full customer data from fact table
                var customer = await customersContainer.ReadItemAsync&lt;Customer&gt;(
                    indexEntry.CustomerId,
                    new PartitionKey(indexEntry.CustomerId));
                
                results.Add(customer.Resource);
            }
        }
        
        return results;
    }
    
    // Update customer and maintain index consistency
    public async Task UpdateCustomerAsync(Customer customer)
    {
        // Read old customer data to update indexes
        var oldCustomer = await customersContainer.ReadItemAsync&lt;Customer&gt;(
            customer.Id,
            new PartitionKey(customer.Id));
        
        // Update main customer record
        await customersContainer.ReplaceItemAsync(customer, customer.Id, new PartitionKey(customer.Id));
        
        // If town changed, update index
        if (oldCustomer.Resource.Town != customer.Town)
        {
            // Delete old town index entry
            string oldIndexId = $"{oldCustomer.Resource.Town}|{customer.Id}";
            await townIndexContainer.DeleteItemAsync&lt;CustomerTownIndex&gt;(
                oldIndexId,
                new PartitionKey(oldCustomer.Resource.Town));
            
            // Create new town index entry
            var newTownIndex = new CustomerTownIndex
            {
                Id = $"{customer.Town}|{customer.Id}",
                PartitionKey = customer.Town,
                CustomerId = customer.Id,
                FirstName = customer.FirstName,
                LastName = customer.LastName
            };
            
            await townIndexContainer.CreateItemAsync(newTownIndex, new PartitionKey(customer.Town));
        }
        else
        {
            // Update existing index entry (if denormalized fields changed)
            var indexEntry = new CustomerTownIndex
            {
                Id = $"{customer.Town}|{customer.Id}",
                PartitionKey = customer.Town,
                CustomerId = customer.Id,
                FirstName = customer.FirstName,
                LastName = customer.LastName
            };
            
            await townIndexContainer.ReplaceItemAsync(
                indexEntry,
                indexEntry.Id,
                new PartitionKey(customer.Town));
        }
    }
}</code></pre>

          <p><strong>Azure Table Storage with Composite Key Index:</strong></p>
          <pre><code>public class MovieEntity : ITableEntity
{
    public string PartitionKey { get; set; } // Genre
    public string RowKey { get; set; } // Movie name
    public string Director { get; set; }
    public int Year { get; set; }
    public DateTimeOffset? Timestamp { get; set; }
    public ETag ETag { get; set; }
}

public class ActorIndexEntity : ITableEntity
{
    public string PartitionKey { get; set; } // Actor name
    public string RowKey { get; set; } // Movie name
    public string Genre { get; set; } // For lookup back to fact table
    public string Director { get; set; } // Denormalized
    public DateTimeOffset? Timestamp { get; set; }
    public ETag ETag { get; set; }
}

public class MovieService
{
    private readonly TableClient moviesTable;
    private readonly TableClient actorIndexTable;
    
    public MovieService(TableServiceClient tableServiceClient)
    {
        moviesTable = tableServiceClient.GetTableClient("movies");
        actorIndexTable = tableServiceClient.GetTableClient("actorindex");
    }
    
    // Query movies by genre (uses primary storage)
    public async IAsyncEnumerable&lt;MovieEntity&gt; GetMoviesByGenreAsync(string genre)
    {
        await foreach (var movie in moviesTable.QueryAsync&lt;MovieEntity&gt;(
            filter: $"PartitionKey eq '{genre}'"))
        {
            yield return movie;
        }
    }
    
    // Query movies by actor (uses index table)
    public async Task&lt;List&lt;MovieEntity&gt;&gt; GetMoviesByActorAsync(string actorName)
    {
        var movies = new List&lt;MovieEntity&gt;();
        
        // Query index table
        await foreach (var indexEntry in actorIndexTable.QueryAsync&lt;ActorIndexEntity&gt;(
            filter: $"PartitionKey eq '{actorName}'"))
        {
            // Use genre and movie name to fetch from fact table
            var movie = await moviesTable.GetEntityAsync&lt;MovieEntity&gt;(
                indexEntry.Genre,
                indexEntry.RowKey);
            
            movies.Add(movie.Value);
        }
        
        return movies;
    }
}</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#sharding"><strong>Sharding</strong></a> - Index tables improve queries over sharded data</li>
            <li>üîó <a href="#materialized-view"><strong>Materialized View</strong></a> - Precomputed views for summary data</li>
            <li>üîó <a href="#cqrs"><strong>CQRS</strong></a> - Separate read models can act as specialized indexes</li>
          </ul>
        </section>

        <!-- Sharding Pattern -->
        <section id="sharding" role="article">
          <h1>üîÄ Sharding</h1>
          <div class="badges">
            <span class="badge badge-data">Data Management</span>
            <span class="badge badge-scalability">Scalability</span>
          </div>

          <h2>Context & Problem</h2>
          <p>A data store hosted by a single server faces limitations:</p>
          <ul>
            <li><strong>Storage space</strong> - Finite disk capacity limits data volume growth</li>
            <li><strong>Computing resources</strong> - Single server can't provide sufficient power for many concurrent users</li>
            <li><strong>Network bandwidth</strong> - Traffic volume might exceed network capacity</li>
            <li><strong>Geography</strong> - Legal, compliance, or performance reasons require data in specific regions</li>
          </ul>
          
          <p>Vertical scaling (adding resources to one server) only postpones these limitations temporarily. A cloud application supporting large numbers of users must be able to scale almost indefinitely.</p>

          <h2>Solution</h2>
          <p>Divide the data store into horizontal partitions or shards. Each shard has the same schema but holds its own distinct subset of data. A shard is a data store in its own right, running on a server acting as a storage node.</p>

          <div class="mermaid">
graph TB
    App[Application<br/>with Sharding Logic]
    
    subgraph "Shard Selection"
    ShardLogic[Shard Key Logic<br/>Determines Target Shard]
    end
    
    subgraph "Shards"
    Shard1[(Shard 1<br/>Customers A-H)]
    Shard2[(Shard 2<br/>Customers I-P)]
    Shard3[(Shard 3<br/>Customers Q-Z)]
    end
    
    App -->|Query with Shard Key| ShardLogic
    ShardLogic -->|Route| Shard1
    ShardLogic -->|Route| Shard2
    ShardLogic -->|Route| Shard3
    
    style App fill:#4CAF50
    style ShardLogic fill:#2196F3
    style Shard1 fill:#FF9800
    style Shard2 fill:#FF9800
    style Shard3 fill:#FF9800
          </div>

          <h3>Sharding Strategies</h3>
          
          <h4>1. Lookup Strategy</h4>
          <p>Sharding logic implements a map that routes requests to shards using the shard key. Virtual partitioning allows flexible rebalancing without code changes.</p>
          <ul>
            <li>‚úÖ More control over shard configuration</li>
            <li>‚úÖ Virtual shards reduce rebalancing impact</li>
            <li>‚ùå Additional overhead for lookup operations</li>
          </ul>

          <h4>2. Range Strategy</h4>
          <p>Groups related items together in the same shard, ordered by shard key. Useful for range queries.</p>
          <ul>
            <li>‚úÖ Easy to implement</li>
            <li>‚úÖ Works well with range queries</li>
            <li>‚úÖ Easier data management (time zone-based updates)</li>
            <li>‚ùå Doesn't provide optimal balancing - can create hotspots</li>
            <li>‚ùå Rebalancing is difficult</li>
          </ul>

          <h4>3. Hash Strategy</h4>
          <p>Distributes data using a hash function to reduce hotspots and achieve balanced load.</p>
          <ul>
            <li>‚úÖ Better chance of even data and load distribution</li>
            <li>‚úÖ Direct routing using hash function (no map needed)</li>
            <li>‚ùå Computing hash adds overhead</li>
            <li>‚ùå Rebalancing shards is difficult</li>
          </ul>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Horizontal scalability</strong> - Scale out by adding more shards</li>
            <li>‚úÖ <strong>Cost-effective</strong> - Use commodity hardware instead of specialized systems</li>
            <li>‚úÖ <strong>Reduced contention</strong> - Balanced workload across shards</li>
            <li>‚úÖ <strong>Geographic distribution</strong> - Locate shards physically close to users</li>
            <li>‚úÖ <strong>Improved availability</strong> - Failure in one shard doesn't affect others</li>
          </ul>

          <h3>Problems and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Shard key selection</strong> - Choose stable, unique keys that support common queries</li>
              <li><strong>Balanced distribution</strong> - Ensure even data distribution to avoid hotspots</li>
              <li><strong>Cross-shard queries</strong> - Minimize queries that span multiple shards</li>
              <li><strong>Referential integrity</strong> - Difficult to maintain across shards</li>
              <li><strong>Rebalancing complexity</strong> - Moving data between shards is expensive</li>
              <li><strong>Management overhead</strong> - Monitoring, backup, and maintenance across many shards</li>
              <li><strong>Eventual consistency</strong> - Design applications to handle temporary inconsistencies</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Data store needs to <strong>scale beyond single storage node</strong> resources</li>
            <li>Need to <strong>improve performance by reducing contention</strong></li>
            <li>Have <strong>geographic requirements</strong> for data location</li>
          </ul>

          <p><strong>Note:</strong> Primary focus is performance and scalability, but also improves availability as a by-product.</p>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Isolation per shard limits blast radius of failures (RE:06, RE:07)</li>
            <li>üí∞ <strong>Cost Optimization</strong> - Use multiple inexpensive resources vs single expensive one (CO:07)</li>
            <li>‚ö° <strong>Performance Efficiency</strong> - Optimizes scaling and data performance (PE:05, PE:08)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Services with Built-in Sharding:</strong></p>
          
          <ul>
            <li><strong>Azure Cosmos DB</strong> - Automatic sharding with partition keys</li>
            <li><strong>Azure SQL Database</strong> - Elastic Database tools for sharding</li>
            <li><strong>Azure Table Storage</strong> - Partition keys for automatic sharding</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>Azure SQL Elastic Database Client Library:</strong></p>
          <pre><code>// Shard map manager - tracks which data is in which shard
ShardMapManager shardMapManager = ShardMapManagerFactory.GetSqlShardMapManager(
    connectionString,
    ShardMapManagerLoadPolicy.Lazy);

// Create or get shard map
ListShardMap&lt;int&gt; shardMap = shardMapManager.GetListShardMap&lt;int&gt;("BookShardMap");

// Add shards to the map
Shard shard0 = shardMap.CreateShard(new ShardLocation("bookdbshard0.database.windows.net", "Books"));
Shard shard1 = shardMap.CreateShard(new ShardLocation("bookdbshard1.database.windows.net", "Books"));
Shard shard2 = shardMap.CreateShard(new ShardLocation("bookdbshard2.database.windows.net", "Books"));

// Create shard mappings (shard key to shard)
shardMap.CreatePointMapping(0, shard0);
shardMap.CreatePointMapping(1, shard0);
shardMap.CreatePointMapping(2, shard0);
shardMap.CreatePointMapping(3, shard1);
shardMap.CreatePointMapping(4, shard1);
shardMap.CreatePointMapping(5, shard1);
shardMap.CreatePointMapping(6, shard2);
shardMap.CreatePointMapping(7, shard2);
shardMap.CreatePointMapping(8, shard2);</code></pre>

          <p><strong>Data-Dependent Routing:</strong></p>
          <pre><code>// Book website uses ISBN check digit as shard key (0-10)
public async Task UpdateBookAsync(Book book)
{
    // Calculate shard key from ISBN check digit
    int shardKey = book.Isbn.CheckDigitAsInt;
    
    // Open connection to the correct shard
    using (SqlConnection conn = shardMap.OpenConnectionForKey(
        key: shardKey,
        connectionString: connectionStringTemplate))
    {
        SqlCommand cmd = conn.CreateCommand();
        cmd.CommandText = @"UPDATE LibraryOfCongressCatalog
                            SET ControlNumber = @lccn,
                                Classification = @lcc
                            WHERE BookID = @bookId";
        
        cmd.Parameters.AddWithValue("@lccn", book.LibraryOfCongress.Lccn);
        cmd.Parameters.AddWithValue("@lcc", book.LibraryOfCongress.Lcc);
        cmd.Parameters.AddWithValue("@bookId", book.Id);
        
        await cmd.ExecuteNonQueryAsync();
    }
}</code></pre>

          <p><strong>Multi-Shard Query (Fan-Out):</strong></p>
          <pre><code>// Query across all shards in parallel
public async Task&lt;List&lt;Book&gt;&gt; SearchBooksAcrossAllShardsAsync(string searchTerm)
{
    var results = new ConcurrentBag&lt;Book&gt;();
    
    // Get all shards
    var allShards = shardMap.GetShards();
    
    // Execute query against each shard in parallel
    await Parallel.ForEachAsync(allShards, async (shard, cancellationToken) =>
    {
        using (SqlConnection conn = shard.OpenConnection(connectionStringTemplate))
        {
            SqlCommand cmd = conn.CreateCommand();
            cmd.CommandText = @"SELECT BookID, Title, Author, ISBN
                                FROM Books
                                WHERE Title LIKE @search OR Author LIKE @search";
            cmd.Parameters.AddWithValue("@search", $"%{searchTerm}%");
            
            using (SqlDataReader reader = await cmd.ExecuteReaderAsync(cancellationToken))
            {
                while (await reader.ReadAsync(cancellationToken))
                {
                    results.Add(new Book
                    {
                        Id = reader.GetInt32(0),
                        Title = reader.GetString(1),
                        Author = reader.GetString(2),
                        ISBN = reader.GetString(3)
                    });
                }
            }
        }
    });
    
    return results.ToList();
}</code></pre>

          <p><strong>Cosmos DB Sharding with Partition Keys:</strong></p>
          <pre><code>// Cosmos DB automatically shards data based on partition key
public class Order
{
    [JsonProperty("id")]
    public string Id { get; set; }
    
    [JsonProperty("customerId")]
    public string CustomerId { get; set; } // Partition key
    
    [JsonProperty("orderDate")]
    public DateTime OrderDate { get; set; }
    
    [JsonProperty("totalAmount")]
    public decimal TotalAmount { get; set; }
}

// Container created with /customerId as partition key
var containerProperties = new ContainerProperties
{
    Id = "orders",
    PartitionKeyPath = "/customerId"
};

var container = await database.CreateContainerIfNotExistsAsync(
    containerProperties,
    throughput: 400);

// Insert order - Cosmos DB automatically routes to correct physical partition
await container.CreateItemAsync(order, new PartitionKey(order.CustomerId));

// Query within partition (efficient - single partition query)
var query = new QueryDefinition(
    "SELECT * FROM c WHERE c.customerId = @customerId")
    .WithParameter("@customerId", customerId);

var iterator = container.GetItemQueryIterator&lt;Order&gt;(
    query,
    requestOptions: new QueryRequestOptions
    {
        PartitionKey = new PartitionKey(customerId)
    });

// Cross-partition query (less efficient - queries all partitions)
var crossPartitionQuery = new QueryDefinition(
    "SELECT * FROM c WHERE c.orderDate >= @startDate")
    .WithParameter("@startDate", startDate);

var crossPartIterator = container.GetItemQueryIterator&lt;Order&gt;(crossPartitionQuery);</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#index-table"><strong>Index Table</strong></a> - Support queries not covered by shard key</li>
            <li>üîó <a href="#materialized-view"><strong>Materialized View</strong></a> - Pre-aggregate data across shards</li>
            <li>üîó <a href="#cqrs"><strong>CQRS</strong></a> - Separate read/write models for sharded data</li>
          </ul>
        </section>

        <!-- Deployment Stamps Pattern -->
        <section id="deployment-stamps" role="article">
          <h1>üì¶ Deployment Stamps</h1>
          <div class="badges">
            <span class="badge badge-scalability">Scalability</span>
            <span class="badge badge-reliability">Reliability</span>
          </div>

          <h2>Context & Problem</h2>
          <p>When hosting applications in the cloud, single-instance deployments face limitations:</p>
          <ul>
            <li><strong>Scale limits</strong> - Services have limits on connections, resources, etc.</li>
            <li><strong>Non-linear scaling</strong> - Some components don't scale linearly; costs/performance change dramatically beyond thresholds</li>
            <li><strong>Customer separation</strong> - Need to isolate certain customers' data from others</li>
            <li><strong>Mixed tenancy</strong> - Large customers need dedicated instances, small customers can share multitenant deployments</li>
            <li><strong>Controlled deployment</strong> - Need to deploy updates to different customer subsets at different times</li>
            <li><strong>Update frequency</strong> - Some customers want frequent updates, others prefer infrequent changes</li>
            <li><strong>Geographic restrictions</strong> - Latency or data sovereignty requirements</li>
          </ul>

          <h2>Solution</h2>
          <p>Provision, manage, and monitor a heterogeneous group of resources to host and operate multiple workloads or tenants. Each individual copy is called a stamp (or scale unit/service unit). Deploy multiple stamps independently to scale the solution and serve different customer subsets.</p>

          <div class="mermaid">
graph TB
    subgraph "Global Traffic Management"
    TM[Traffic Manager<br/>Azure Front Door]
    end
    
    subgraph "Region 1 - Stamp A"
    App1[App Service]
    DB1[(SQL Database)]
    Storage1[Storage]
    end
    
    subgraph "Region 1 - Stamp B"
    App2[App Service]
    DB2[(SQL Database)]
    Storage2[Storage]
    end
    
    subgraph "Region 2 - Stamp C"
    App3[App Service]
    DB3[(SQL Database)]
    Storage3[Storage]
    end
    
    Users[Users] --> TM
    TM --> App1
    TM --> App2
    TM --> App3
    
    App1 --> DB1
    App1 --> Storage1
    App2 --> DB2
    App2 --> Storage2
    App3 --> DB3
    App3 --> Storage3
    
    style TM fill:#4CAF50
    style App1 fill:#2196F3
    style App2 fill:#2196F3
    style App3 fill:#2196F3
          </div>

          <h3>Key Characteristics</h3>
          <ul>
            <li>Each stamp operates <strong>independently</strong> - no dependencies on other stamps</li>
            <li>Stamps contain a <strong>subset of customers/tenants</strong></li>
            <li>Data is <strong>implicitly sharded</strong> by stamp</li>
            <li>Can deploy stamps across <strong>multiple regions</strong></li>
            <li>Updates can be deployed to stamps <strong>independently</strong></li>
          </ul>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Horizontal scale-out</strong> - Add stamps to serve more customers</li>
            <li>‚úÖ <strong>Blast radius containment</strong> - Issues in one stamp don't affect others</li>
            <li>‚úÖ <strong>Deployment flexibility</strong> - Different update cadences per stamp</li>
            <li>‚úÖ <strong>Customer isolation</strong> - Dedicated stamps for specific customers</li>
            <li>‚úÖ <strong>Geographic distribution</strong> - Deploy stamps closer to users</li>
            <li>‚úÖ <strong>Deployment rings</strong> - Gradual rollout to different customer groups</li>
          </ul>

          <h3>Problems and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Deployment automation essential</strong> - Use IaC (Bicep, ARM templates, Terraform)</li>
              <li><strong>Cross-stamp operations complex</strong> - Queries across all stamps require aggregation</li>
              <li><strong>Capacity planning required</strong> - Monitor stamp capacity and deploy new stamps proactively</li>
              <li><strong>Minimum two stamps</strong> - Deploy at least two to avoid hard-coded assumptions</li>
              <li><strong>Increased costs</strong> - Multiple infrastructure copies</li>
              <li><strong>Tenant migration difficult</strong> - Moving customers between stamps is complex</li>
              <li><strong>Traffic routing component</strong> - May need centralized routing service</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Natural <strong>scalability limits</strong> exist for components</li>
            <li>Need to <strong>separate certain tenants</strong> from others</li>
            <li>Some tenants need <strong>different solution versions</strong></li>
            <li><strong>Multi-region</strong> applications where tenant data should stay in specific region</li>
            <li>Need to contain <strong>blast radius</strong> during outages</li>
          </ul>

          <p><strong>‚ùå Not suitable for:</strong></p>
          <ul>
            <li><strong>Simple solutions</strong> that don't need high scale</li>
            <li>Systems that scale easily <strong>within single instance</strong></li>
            <li>Solutions where data should be <strong>replicated across all instances</strong> (use Geode pattern)</li>
            <li><strong>Static content only</strong> (use CDN instead)</li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üîß <strong>Operational Excellence</strong> - Immutable infrastructure, advanced deployment models (OE:05, OE:11)</li>
            <li>‚ö° <strong>Performance Efficiency</strong> - Aligns with scale units for scaling out (PE:05)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Key Azure Services:</strong></p>
          
          <ul>
            <li><strong>Azure Front Door</strong> - Global traffic routing to stamps</li>
            <li><strong>Azure Traffic Manager</strong> - DNS-based load balancing across stamps</li>
            <li><strong>Azure API Management</strong> - Centralized routing and policy enforcement</li>
            <li><strong>Bicep/ARM Templates</strong> - Infrastructure as Code for consistent stamp deployment</li>
            <li><strong>Azure Pipelines/GitHub Actions</strong> - Automated stamp deployment and updates</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>Bicep Template for Deployment Stamp:</strong></p>
          <pre><code>// stamp.bicep - Template for a single stamp
param stampName string
param location string
param sqlAdminPassword string @secure()

// App Service Plan
resource appServicePlan 'Microsoft.Web/serverfarms@2022-03-01' = {
  name: 'asp-${stampName}'
  location: location
  sku: {
    name: 'P1v3'
    capacity: 2
  }
}

// Web App
resource webApp 'Microsoft.Web/sites@2022-03-01' = {
  name: 'app-${stampName}'
  location: location
  properties: {
    serverFarmId: appServicePlan.id
    httpsOnly: true
  }
}

// SQL Server
resource sqlServer 'Microsoft.Sql/servers@2022-05-01-preview' = {
  name: 'sql-${stampName}'
  location: location
  properties: {
    administratorLogin: 'sqladmin'
    administratorLoginPassword: sqlAdminPassword
  }
}

// SQL Database
resource sqlDatabase 'Microsoft.Sql/servers/databases@2022-05-01-preview' = {
  parent: sqlServer
  name: 'db-${stampName}'
  location: location
  sku: {
    name: 'S3'
    tier: 'Standard'
  }
}

// Storage Account
resource storageAccount 'Microsoft.Storage/storageAccounts@2022-09-01' = {
  name: 'st${replace(stampName, '-', '')}'
  location: location
  sku: {
    name: 'Standard_LRS'
  }
  kind: 'StorageV2'
}

output webAppHostName string = webApp.properties.defaultHostName
output sqlServerFqdn string = sqlServer.properties.fullyQualifiedDomainName</code></pre>

          <p><strong>Deploy Multiple Stamps with Azure Pipeline:</strong></p>
          <pre><code># azure-pipelines.yml
trigger:
  - main

variables:
  - group: deployment-secrets

stages:
  - stage: DeployStamps
    displayName: 'Deploy Multiple Stamps'
    jobs:
      - job: DeployStamp1
        displayName: 'Deploy Stamp 1 (East US)'
        steps:
          - task: AzureResourceManagerTemplateDeployment@3
            inputs:
              deploymentScope: 'Resource Group'
              azureResourceManagerConnection: 'AzureConnection'
              resourceGroupName: 'rg-stamps-eastus'
              location: 'East US'
              templateLocation: 'Linked artifact'
              csmFile: 'stamp.bicep'
              overrideParameters: '-stampName stamp1-eastus -location eastus -sqlAdminPassword $(SQL_PASSWORD)'
      
      - job: DeployStamp2
        displayName: 'Deploy Stamp 2 (West US)'
        steps:
          - task: AzureResourceManagerTemplateDeployment@3
            inputs:
              deploymentScope: 'Resource Group'
              azureResourceManagerConnection: 'AzureConnection'
              resourceGroupName: 'rg-stamps-westus'
              location: 'West US'
              templateLocation: 'Linked artifact'
              csmFile: 'stamp.bicep'
              overrideParameters: '-stampName stamp2-westus -location westus -sqlAdminPassword $(SQL_PASSWORD)'</code></pre>

          <p><strong>Traffic Routing with API Management:</strong></p>
          <pre><code>// Policy to route traffic to stamps based on tenant
&lt;policies&gt;
    &lt;inbound&gt;
        &lt;base /&gt;
        &lt;!-- Extract tenant ID from header or token --&gt;
        &lt;set-variable name="tenantId" value="@(context.Request.Headers.GetValueOrDefault("X-Tenant-Id"))" /&gt;
        
        &lt;!-- Look up stamp for tenant from Azure Cosmos DB --&gt;
        &lt;send-request mode="new" response-variable-name="stampLookup" timeout="5" ignore-error="false"&gt;
            &lt;set-url&gt;@("https://tenantmapping.cosmos.azure.com/dbs/routing/colls/tenants/docs/" + context.Variables["tenantId"])&lt;/set-url&gt;
            &lt;set-method&gt;GET&lt;/set-method&gt;
            &lt;set-header name="Authorization" exists-action="override"&gt;
                &lt;value&gt;@(context.Variables["cosmosAuthToken"])&lt;/value&gt;
            &lt;/set-header&gt;
        &lt;/send-request&gt;
        
        &lt;!-- Extract stamp URL from response --&gt;
        &lt;set-variable name="stampUrl" value="@(((IResponse)context.Variables["stampLookup"]).Body.As&lt;JObject&gt;()["stampUrl"].ToString())" /&gt;
        
        &lt;!-- Route to the correct stamp --&gt;
        &lt;set-backend-service base-url="@((string)context.Variables["stampUrl"])" /&gt;
    &lt;/inbound&gt;
    &lt;backend&gt;
        &lt;base /&gt;
    &lt;/backend&gt;
    &lt;outbound&gt;
        &lt;base /&gt;
    &lt;/outbound&gt;
    &lt;on-error&gt;
        &lt;base /&gt;
    &lt;/on-error&gt;
&lt;/policies&gt;</code></pre>

          <p><strong>Azure Front Door Configuration for Stamps:</strong></p>
          <pre><code>// Bicep for Azure Front Door with multiple stamp backends
resource frontDoor 'Microsoft.Cdn/profiles@2021-06-01' = {
  name: 'fd-stamps'
  location: 'global'
  sku: {
    name: 'Premium_AzureFrontDoor'
  }
}

resource endpoint 'Microsoft.Cdn/profiles/afdEndpoints@2021-06-01' = {
  parent: frontDoor
  name: 'api-endpoint'
  location: 'global'
  properties: {
    enabledState: 'Enabled'
  }
}

resource originGroup 'Microsoft.Cdn/profiles/originGroups@2021-06-01' = {
  parent: frontDoor
  name: 'stamp-origins'
  properties: {
    loadBalancingSettings: {
      sampleSize: 4
      successfulSamplesRequired: 3
      additionalLatencyInMilliseconds: 50
    }
    healthProbeSettings: {
      probePath: '/health'
      probeRequestType: 'GET'
      probeProtocol: 'Https'
      probeIntervalInSeconds: 30
    }
  }
}

resource stamp1Origin 'Microsoft.Cdn/profiles/originGroups/origins@2021-06-01' = {
  parent: originGroup
  name: 'stamp1-eastus'
  properties: {
    hostName: 'app-stamp1-eastus.azurewebsites.net'
    httpPort: 80
    httpsPort: 443
    originHostHeader: 'app-stamp1-eastus.azurewebsites.net'
    priority: 1
    weight: 1000
    enabledState: 'Enabled'
  }
}

resource stamp2Origin 'Microsoft.Cdn/profiles/originGroups/origins@2021-06-01' = {
  parent: originGroup
  name: 'stamp2-westus'
  properties: {
    hostName: 'app-stamp2-westus.azurewebsites.net'
    httpPort: 80
    httpsPort: 443
    originHostHeader: 'app-stamp2-westus.azurewebsites.net'
    priority: 1
    weight: 1000
    enabledState: 'Enabled'
  }
}</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#sharding"><strong>Sharding</strong></a> - Stamps implicitly shard data; sharding is simpler alternative</li>
            <li>üîó <a href="#geode"><strong>Geodes</strong></a> - All instances serve all users; stamps serve subset</li>
            <li>üîó <a href="#gateway-routing"><strong>Gateway Routing</strong></a> - Route traffic to correct stamp</li>
            <li>üîó <a href="#gateway-offloading"><strong>Gateway Offloading</strong></a> - Centralized traffic routing can offload functions</li>
          </ul>
        </section>

        <!-- Geode Pattern -->
        <section id="geode" role="article">
          <h1>üåç Geode</h1>
          <div class="badges">
            <span class="badge badge-scalability">Scalability</span>
            <span class="badge badge-performance">Performance</span>
            <span class="badge badge-reliability">Reliability</span>
          </div>

          <h2>Context & Problem</h2>
          <p>Many large-scale services face challenges around geo-availability and scale. Classic designs bring data to compute by storing data in a remote server, relying on scale-up for growth. This causes:</p>
          <ul>
            <li><strong>Network latency</strong> - Users on other side of globe connecting to distant endpoint</li>
            <li><strong>Traffic bursts</strong> - Demand spikes overwhelm services in single region</li>
            <li><strong>Cost complexity</strong> - Deploying full app infrastructure to multiple regions for 24x7 service</li>
          </ul>
          
          <p>Modern cloud infrastructure enables geographic load balancing of front-end services and geographic replication of backend services. The geode pattern brings the compute to the data by colocating geo-distributed datastores with compute resources.</p>

          <h2>Solution</h2>
          <p>Deploy the service into multiple satellite deployments spread around the globe, each called a geode. Each geode is behind a global load balancer and uses geo-replicated read-write services like Azure Cosmos DB to host the data plane, ensuring cross-geode data consistency.</p>

          <div class="mermaid">
graph TB
    subgraph "Global Layer"
    LB[Global Load Balancer<br/>Azure Front Door]
    Replication[Data Replication<br/>Azure Cosmos DB Multi-Region]
    end
    
    subgraph "Geode 1 - East US"
    Compute1[Compute<br/>Functions/App Service]
    Data1[(Cosmos DB<br/>East US)]
    end
    
    subgraph "Geode 2 - West Europe"
    Compute2[Compute<br/>Functions/App Service]
    Data2[(Cosmos DB<br/>West Europe)]
    end
    
    subgraph "Geode 3 - Southeast Asia"
    Compute3[Compute<br/>Functions/App Service]
    Data3[(Cosmos DB<br/>Southeast Asia)]
    end
    
    Users[Global Users] --> LB
    LB -->|Route to Nearest| Compute1
    LB -->|Route to Nearest| Compute2
    LB -->|Route to Nearest| Compute3
    
    Compute1 --> Data1
    Compute2 --> Data2
    Compute3 --> Data3
    
    Data1 <-.Multi-Region Replication.-> Replication
    Data2 <-.Multi-Region Replication.-> Replication
    Data3 <-.Multi-Region Replication.-> Replication
    
    style LB fill:#4CAF50
    style Replication fill:#2196F3
    style Compute1 fill:#FF9800
    style Compute2 fill:#FF9800
    style Compute3 fill:#FF9800
          </div>

          <h3>Key Characteristics</h3>
          <ul>
            <li><strong>No isolation</strong> - Geodes never exist in isolation; always multiple geodes in production</li>
            <li><strong>Self-contained</strong> - No dependencies outside geode footprint</li>
            <li><strong>Independent operation</strong> - If one geode dies, others continue</li>
            <li><strong>Loosely coupled</strong> - Connected via edge network and replication backplane</li>
            <li><strong>Shared backplane</strong> - Not like clusters; platform handles quorum issues</li>
            <li><strong>Any geode serves any user</strong> - Unlike stamps where customers assigned to specific stamp</li>
          </ul>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Reduced latency</strong> - Users served from geographically nearest geode</li>
            <li>‚úÖ <strong>High availability</strong> - Multiple geodes survive regional outages</li>
            <li>‚úÖ <strong>Improved performance</strong> - Compute colocated with data</li>
            <li>‚úÖ <strong>Global scale</strong> - Add geodes to serve more regions</li>
            <li>‚úÖ <strong>Active-active</strong> - All geodes actively serve requests</li>
            <li>‚úÖ <strong>Elastic scaling</strong> - Each geode scales independently</li>
          </ul>

          <h3>Problems and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>DevOps maturity required</strong> - Need modern practices to deploy identical geodes rapidly</li>
              <li><strong>Data consistency model</strong> - Choose appropriate Cosmos DB consistency level</li>
              <li><strong>Monitoring strategy</strong> - Track requests executing asynchronously across instances</li>
              <li><strong>Security complexity</strong> - More secrets and ingress points to secure</li>
              <li><strong>Cost optimization</strong> - Balance number of geodes vs pricing tiers</li>
              <li><strong>Serverless recommended</strong> - Reduces cost of multiple deployments</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Implementing <strong>high-scale platform</strong> with users distributed over wide area</li>
            <li>Service requires <strong>extreme availability and resilience</strong></li>
            <li>Need to survive <strong>multiple region outages</strong> simultaneously</li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>Constraints prevent all geodes being <strong>equal for data storage</strong> (data residency requirements)</li>
            <li>No <strong>geographical distribution</strong> required (use availability zones instead)</li>
            <li><strong>Legacy platform retrofit</strong> - pattern works for cloud-native only</li>
            <li><strong>Simple architectures</strong> where geo-redundancy not needed</li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Withstand regional outages, data replication supports multi-region design (RE:05)</li>
            <li>‚ö° <strong>Performance Efficiency</strong> - Serve from region closest to user, reduce latency (PE:03)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Key Azure Services:</strong></p>
          
          <ul>
            <li><strong>Azure Front Door</strong> - Dynamic content acceleration, Anycast routing</li>
            <li><strong>Azure Cosmos DB</strong> - Multi-region write, geo-replication, configurable consistency</li>
            <li><strong>Azure Functions</strong> - Serverless compute, consumption billing</li>
            <li><strong>Azure API Management</strong> - Optional API layer for rate limiting, policies</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>Azure Function with Cosmos DB Multi-Region:</strong></p>
          <pre><code>[FunctionName("ProcessOrder")]
public async Task&lt;IActionResult&gt; ProcessOrder(
    [HttpTrigger(AuthorizationLevel.Function, "post")] HttpRequest req,
    [CosmosDB(
        databaseName: "OrdersDB",
        containerName: "orders",
        Connection = "CosmosDBConnection")] CosmosClient cosmosClient,
    ILogger log)
{
    // Function runs in multiple regions
    // Cosmos DB handles multi-region replication
    string region = Environment.GetEnvironmentVariable("REGION_NAME");
    log.LogInformation($"Processing order in region: {region}");
    
    var order = await JsonSerializer.DeserializeAsync&lt;Order&gt;(req.Body);
    
    var container = cosmosClient.GetDatabase("OrdersDB").GetContainer("orders");
    
    // Write to Cosmos DB - automatically replicated to all regions
    await container.CreateItemAsync(order, new PartitionKey(order.CustomerId));
    
    return new OkObjectResult(new { 
        orderId = order.Id, 
        processedIn = region 
    });
}</code></pre>

          <p><strong>Cosmos DB Multi-Region Configuration:</strong></p>
          <pre><code>// Bicep configuration for Cosmos DB with multi-region write
resource cosmosAccount 'Microsoft.DocumentDB/databaseAccounts@2023-04-15' = {
  name: 'cosmos-geode-example'
  location: 'East US'
  properties: {
    databaseAccountOfferType: 'Standard'
    enableMultipleWriteLocations: true // Critical for geode pattern
    consistencyPolicy: {
      defaultConsistencyLevel: 'Session' // Balance consistency and performance
      maxStalenessPrefix: 100
      maxIntervalInSeconds: 5
    }
    locations: [
      {
        locationName: 'East US'
        failoverPriority: 0
        isZoneRedundant: true
      }
      {
        locationName: 'West Europe'
        failoverPriority: 1
        isZoneRedundant: true
      }
      {
        locationName: 'Southeast Asia'
        failoverPriority: 2
        isZoneRedundant: true
      }
    ]
  }
}

resource database 'Microsoft.DocumentDB/databaseAccounts/sqlDatabases@2023-04-15' = {
  parent: cosmosAccount
  name: 'OrdersDB'
  properties: {
    resource: {
      id: 'OrdersDB'
    }
  }
}

resource container 'Microsoft.DocumentDB/databaseAccounts/sqlDatabases/containers@2023-04-15' = {
  parent: database
  name: 'orders'
  properties: {
    resource: {
      id: 'orders'
      partitionKey: {
        paths: ['/customerId']
        kind: 'Hash'
      }
    }
  }
}</code></pre>

          <p><strong>Azure Front Door Configuration for Geodes:</strong></p>
          <pre><code>resource frontDoor 'Microsoft.Cdn/profiles@2021-06-01' = {
  name: 'fd-geode-routing'
  location: 'global'
  sku: {
    name: 'Premium_AzureFrontDoor'
  }
}

resource endpoint 'Microsoft.Cdn/profiles/afdEndpoints@2021-06-01' = {
  parent: frontDoor
  name: 'api'
  location: 'global'
  properties: {
    enabledState: 'Enabled'
  }
}

resource originGroup 'Microsoft.Cdn/profiles/originGroups@2021-06-01' = {
  parent: frontDoor
  name: 'geode-origins'
  properties: {
    loadBalancingSettings: {
      sampleSize: 4
      successfulSamplesRequired: 3
      additionalLatencyInMilliseconds: 50
    }
    healthProbeSettings: {
      probePath: '/api/health'
      probeRequestType: 'GET'
      probeProtocol: 'Https'
      probeIntervalInSeconds: 30
    }
    sessionAffinityState: 'Disabled' // Important: no affinity needed
  }
}

// Geode 1 - East US
resource geode1Origin 'Microsoft.Cdn/profiles/originGroups/origins@2021-06-01' = {
  parent: originGroup
  name: 'geode-eastus'
  properties: {
    hostName: 'func-geode-eastus.azurewebsites.net'
    httpPort: 80
    httpsPort: 443
    originHostHeader: 'func-geode-eastus.azurewebsites.net'
    priority: 1
    weight: 1000
    enabledState: 'Enabled'
  }
}

// Geode 2 - West Europe
resource geode2Origin 'Microsoft.Cdn/profiles/originGroups/origins@2021-06-01' = {
  parent: originGroup
  name: 'geode-westeurope'
  properties: {
    hostName: 'func-geode-westeurope.azurewebsites.net'
    httpPort: 80
    httpsPort: 443
    originHostHeader: 'func-geode-westeurope.azurewebsites.net'
    priority: 1
    weight: 1000
    enabledState: 'Enabled'
  }
}</code></pre>

          <p><strong>Geode Deployment Script:</strong></p>
          <pre><code># Deploy identical geode to multiple regions
$regions = @("eastus", "westeurope", "southeastasia")
$geodeTemplate = "geode.bicep"

foreach ($region in $regions) {
    Write-Host "Deploying geode to $region..."
    
    az deployment group create `
        --resource-group "rg-geodes" `
        --template-file $geodeTemplate `
        --parameters `
            region=$region `
            geodeName="geode-$region" `
            cosmosConnectionString=$cosmosConnectionString
    
    Write-Host "Geode deployed to $region successfully."
}</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#deployment-stamps"><strong>Deployment Stamps</strong></a> - Stamps serve subset of customers; geodes serve all users</li>
            <li>üîó <a href="#cqrs"><strong>CQRS</strong></a> - Separate read/write models across geodes</li>
            <li>üîó <a href="#cache-aside"><strong>Cache-Aside</strong></a> - Cache data locally in each geode</li>
          </ul>
        </section>

        <!-- Rate Limiting Pattern -->
        <section id="rate-limiting" role="article">
          <h1>‚è±Ô∏è Rate Limiting</h1>
          <div class="badges">
            <span class="badge badge-performance">Performance</span>
            <span class="badge badge-reliability">Reliability</span>
          </div>

          <h2>Context & Problem</h2>
          <p>Many services use a <strong>throttling pattern</strong> to control the resources they consume, imposing limits on the rate at which other applications or services can access them. Performing large numbers of operations using a throttled service can result in increased traffic and throughput, as you'll need to both track rejected requests and then retry those operations.</p>
          
          <p>As the number of operations increases, a throttling limit might require multiple passes of resending data, resulting in a larger performance impact. For example, if you need to ingest 10,000 records into Azure Cosmos DB with 20,000 RUs provisioned capacity, a naive retry-on-error approach could require sending 30,000 total records due to throttling rejections.</p>

          <h2>Solution</h2>
          <p>Rate limiting reduces your traffic and potentially improves throughput by <strong>reducing the number of records sent to a service over a given period of time</strong>. Control the number and/or size of operations sent to the service over a specific time period, optimizing your use of the service while not exceeding its throttling capacity.</p>

          <div class="mermaid">
graph TB
    subgraph "Producer Side"
    App[Application] -->|High Volume| Queue[Durable Message Queue<br/>Event Hubs/Service Bus]
    end
    
    subgraph "Rate Limiter"
    Queue -->|Dequeue| Processor1[Job Processor 1]
    Queue -->|Dequeue| Processor2[Job Processor 2]
    Queue -->|Dequeue| Processor3[Job Processor 3]
    
    Processor1 -->|Rate Limited| RL1[Rate Limit Logic<br/>100 ops/sec]
    Processor2 -->|Rate Limited| RL2[Rate Limit Logic<br/>100 ops/sec]
    Processor3 -->|Rate Limited| RL3[Rate Limit Logic<br/>100 ops/sec]
    end
    
    subgraph "Throttled Service"
    RL1 --> Service[Azure Cosmos DB<br/>20,000 RUs]
    RL2 --> Service
    RL3 --> Service
    end
    
    subgraph "Distributed Locks"
    Blob1[Blob Lease 1<br/>25 RU/s capacity]
    Blob2[Blob Lease 2<br/>25 RU/s capacity]
    Blob3[Blob Lease 3<br/>25 RU/s capacity]
    
    Processor1 -.->|Acquire Lease| Blob1
    Processor2 -.->|Acquire Lease| Blob2
    Processor3 -.->|Acquire Lease| Blob3
    end
    
    style Service fill:#f59e0b,stroke:#d97706,stroke-width:3px,color:#fff
    style Queue fill:#3b82f6,stroke:#2563eb,stroke-width:2px,color:#fff
    style RL1 fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff
    style RL2 fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff
    style RL3 fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff
          </div>

          <h3>Key Concepts</h3>
          <ul>
            <li><strong>Durable messaging</strong> - Use Event Hubs, Service Bus, or Queue Storage to buffer high-volume requests</li>
            <li><strong>Controlled dequeue</strong> - Process messages at rate within throttled service's limits</li>
            <li><strong>Granular releases</strong> - Send smaller batches more frequently (e.g., 20 ops every 200ms instead of 100 ops/second)</li>
            <li><strong>Distributed capacity</strong> - Use blob leases or distributed locks to partition capacity across processors</li>
            <li><strong>Memory efficiency</strong> - Dequeue only what can be processed in current time window</li>
          </ul>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Reduced throttling errors</strong> - Minimize 429 errors and retries</li>
            <li>‚úÖ <strong>Improved throughput</strong> - Optimize service utilization without overwhelming it</li>
            <li>‚úÖ <strong>Predictable performance</strong> - Calculate expected completion time</li>
            <li>‚úÖ <strong>Lower costs</strong> - Reduce unnecessary retries and log processing</li>
            <li>‚úÖ <strong>Memory efficiency</strong> - Process data in controlled batches</li>
            <li>‚úÖ <strong>Resilience</strong> - Protect buffered data from crashes</li>
          </ul>

          <h3>Issues and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Important Considerations:</strong>
            <ul>
              <li><strong>Handle remaining throttling</strong> - Still need proper retry logic for any throttling errors</li>
              <li><strong>Coordinate workstreams</strong> - Multiple workstreams accessing same service need unified rate limiting</li>
              <li><strong>Multi-application contention</strong> - Throttled service shared by multiple apps may require capacity reduction</li>
              <li><strong>Capacity partitioning</strong> - For uncoordinated processes, logically partition service capacity</li>
              <li><strong>Lease management</strong> - Track lease expiration to avoid using expired capacity grants</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Need to <strong>reduce throttling errors</strong> from a rate-limited service</li>
            <li>Want to <strong>reduce traffic</strong> compared to naive retry-on-error approach</li>
            <li>Need to <strong>control memory consumption</strong> by dequeuing only processable records</li>
            <li>Working with services that <strong>throttle by operations, data size, or cost</strong> (e.g., RUs)</li>
            <li>Multiple uncoordinated processes need to <strong>share throttled service capacity</strong></li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üõ°Ô∏è <strong>Reliability (RE:07)</strong> - Self-preservation by acknowledging service limitations and costs</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Durable Messaging Services:</strong></p>
          <ul>
            <li><strong>Azure Service Bus</strong> - Message queues and topics with ordering and transactions</li>
            <li><strong>Azure Queue Storage</strong> - Simple, cost-effective queue storage</li>
            <li><strong>Azure Event Hubs</strong> - High-throughput event streaming (millions of events/second)</li>
          </ul>

          <p><strong>Distributed Lock Management:</strong></p>
          <ul>
            <li><strong>Azure Blob Storage Leases</strong> - Exclusive 15-60 second leases on blobs for capacity partitioning</li>
            <li><strong>Azure Redis Cache</strong> - Distributed locks using RedLock or similar patterns</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>Rate Limiter with Azure Queue Storage:</strong></p>
          <pre><code>public class RateLimitedProcessor
{
    private readonly QueueClient queueClient;
    private readonly CosmosClient cosmosClient;
    private readonly int maxOperationsPerSecond = 100;
    private readonly int batchSize = 20; // Send 20 every 200ms
    private readonly int intervalMs = 200;

    public async Task ProcessQueueAsync(CancellationToken cancellationToken)
    {
        var container = cosmosClient.GetContainer("OrdersDB", "orders");
        
        while (!cancellationToken.IsCancellationRequested)
        {
            var messages = await queueClient.ReceiveMessagesAsync(
                maxMessages: batchSize,
                cancellationToken: cancellationToken);

            if (messages.Value.Length == 0)
            {
                await Task.Delay(intervalMs, cancellationToken);
                continue;
            }

            // Process batch within rate limit
            foreach (var message in messages.Value)
            {
                try
                {
                    var order = JsonSerializer.Deserialize&lt;Order&gt;(message.MessageText);
                    await container.CreateItemAsync(order, 
                        new PartitionKey(order.CustomerId));
                    
                    // Delete message after successful processing
                    await queueClient.DeleteMessageAsync(
                        message.MessageId, 
                        message.PopReceipt);
                }
                catch (CosmosException ex) when (ex.StatusCode == HttpStatusCode.TooManyRequests)
                {
                    // Still got throttled - wait and don't delete message
                    await Task.Delay(TimeSpan.FromSeconds(ex.RetryAfter?.TotalSeconds ?? 1));
                }
            }

            // Wait before processing next batch
            await Task.Delay(intervalMs, cancellationToken);
        }
    }
}</code></pre>

          <p><strong>Distributed Capacity with Blob Leases:</strong></p>
          <pre><code>public class DistributedCapacityManager
{
    private readonly BlobContainerClient containerClient;
    private readonly int totalCapacity = 500; // Total ops/sec
    private readonly int partitionCount = 20; // 20 partitions √ó 25 ops/sec
    private readonly List&lt;BlobLeaseClient&gt; activeLeases = new();

    public async Task&lt;int&gt; AcquireCapacityAsync(int desiredOpsPerSecond)
    {
        int opsPerPartition = totalCapacity / partitionCount; // 25 ops/sec per partition
        int partitionsNeeded = (int)Math.Ceiling(desiredOpsPerSecond / (double)opsPerPartition);
        
        int acquired = 0;
        for (int i = 0; i &lt; partitionCount && acquired &lt; partitionsNeeded; i++)
        {
            var blobClient = containerClient.GetBlobClient($"capacity-partition-{i}");
            
            // Ensure blob exists
            if (!await blobClient.ExistsAsync())
            {
                await blobClient.UploadAsync(new BinaryData(Array.Empty&lt;byte&gt;()));
            }
            
            var leaseClient = blobClient.GetBlobLeaseClient();
            try
            {
                // Try to acquire 15-second lease
                await leaseClient.AcquireAsync(TimeSpan.FromSeconds(15));
                activeLeases.Add(leaseClient);
                acquired++;
            }
            catch (RequestFailedException) 
            { 
                // Lease already held by another processor
            }
        }
        
        return acquired * opsPerPartition;
    }

    public async Task ReleaseCapacityAsync()
    {
        foreach (var lease in activeLeases)
        {
            try { await lease.ReleaseAsync(); }
            catch { /* Best effort release */ }
        }
        activeLeases.Clear();
    }
}</code></pre>

          <p><strong>Multi-Processor Example with Azure Service Bus:</strong></p>
          <pre><code>// Each processor competes for capacity and rate-limits accordingly
public class ServiceBusRateLimitedProcessor
{
    private readonly ServiceBusClient serviceBusClient;
    private readonly DistributedCapacityManager capacityManager;
    private readonly CosmosClient cosmosClient;

    public async Task ProcessAsync(CancellationToken cancellationToken)
    {
        var receiver = serviceBusClient.CreateReceiver("orders-queue");
        
        while (!cancellationToken.IsCancellationRequested)
        {
            // Request capacity for desired throughput
            int grantedCapacity = await capacityManager.AcquireCapacityAsync(100);
            
            if (grantedCapacity == 0)
            {
                await Task.Delay(1000, cancellationToken);
                continue;
            }

            // Process at granted rate
            var deadline = DateTime.UtcNow.AddSeconds(15); // Lease duration
            while (DateTime.UtcNow &lt; deadline && !cancellationToken.IsCancellationRequested)
            {
                int batchSize = grantedCapacity / 5; // Spread over 200ms intervals
                var messages = await receiver.ReceiveMessagesAsync(
                    maxMessages: batchSize,
                    maxWaitTime: TimeSpan.FromMilliseconds(200),
                    cancellationToken: cancellationToken);

                foreach (var message in messages)
                {
                    // Process message...
                    await receiver.CompleteMessageAsync(message);
                }

                await Task.Delay(200, cancellationToken);
            }

            await capacityManager.ReleaseCapacityAsync();
        }
    }
}</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#throttling"><strong>Throttling</strong></a> - Rate limiting is typically implemented in response to throttled services</li>
            <li>üîó <a href="#retry"><strong>Retry</strong></a> - Handle any remaining throttling errors with appropriate retry intervals</li>
            <li>üîó <a href="#queue-load-leveling"><strong>Queue-Based Load Leveling</strong></a> - Similar buffering approach but broader applicability</li>
          </ul>
        </section>

        <!-- Federated Identity Pattern -->
        <section id="federated-identity" role="article">
          <h1>üîê Federated Identity</h1>
          <div class="badges">
            <span class="badge badge-security">Security</span>
            <span class="badge badge-identity">Identity</span>
          </div>

          <h2>Context & Problem</h2>
          <p>Managing user identities, authentication, and authorization is a complex and error-prone task. Organizations often need to support multiple identity providers, social logins, or integration with existing corporate directories. Building and maintaining your own identity management system requires significant security expertise and ongoing maintenance.</p>
          
          <p>Additionally, users increasingly expect to use their existing credentials from identity providers they trust (Microsoft, Google, Facebook, etc.) rather than creating yet another username and password.</p>

          <h2>Solution</h2>
          <p>Delegate authentication to an external identity provider using federation protocols. The application trusts the identity provider to authenticate users and issues tokens that can be verified. This allows the application to outsource complex identity management while maintaining control over authorization decisions.</p>

          <div class="mermaid">
sequenceDiagram
    participant User
    participant App
    participant IdP as Identity Provider<br/>(Entra ID, Google, etc.)
    
    User->>App: 1. Access protected resource
    App-->>User: 2. Redirect to IdP for login
    User->>IdP: 3. Authenticate with credentials
    IdP->>IdP: 4. Validate credentials
    IdP-->>User: 5. Return token (redirect)
    User->>App: 6. Present token
    App->>IdP: 7. Validate token signature
    IdP-->>App: 8. Token valid
    App->>App: 9. Check authorization
    App-->>User: 10. Grant access to resource
          </div>

          <h3>Key Concepts</h3>
          <ul>
            <li><strong>Identity Provider (IdP)</strong> - External service that authenticates users and issues tokens (Microsoft Entra ID, Google, Okta, Auth0)</li>
            <li><strong>Service Provider (SP)</strong> - Your application that relies on the IdP for authentication</li>
            <li><strong>Security Token</strong> - Signed assertion containing user claims (JWT, SAML)</li>
            <li><strong>Trust Relationship</strong> - Pre-established configuration between application and IdP</li>
            <li><strong>Claims</strong> - Statements about the user (email, name, roles, groups)</li>
          </ul>

          <h3>Federation Protocols</h3>
          <ul>
            <li><strong>OAuth 2.0</strong> - Authorization framework for delegated access</li>
            <li><strong>OpenID Connect (OIDC)</strong> - Authentication layer built on OAuth 2.0 (recommended for modern apps)</li>
            <li><strong>SAML 2.0</strong> - XML-based protocol commonly used in enterprise scenarios</li>
            <li><strong>WS-Federation</strong> - Legacy protocol for enterprise federation</li>
          </ul>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Reduced development effort</strong> - No need to build authentication infrastructure</li>
            <li>‚úÖ <strong>Enhanced security</strong> - Leverage security expertise of specialized providers</li>
            <li>‚úÖ <strong>Better user experience</strong> - Users can use existing credentials (SSO)</li>
            <li>‚úÖ <strong>Simplified password management</strong> - No password storage or reset flows</li>
            <li>‚úÖ <strong>MFA support</strong> - Identity providers handle multi-factor authentication</li>
            <li>‚úÖ <strong>Compliance</strong> - Providers often meet regulatory requirements (SOC 2, ISO 27001)</li>
          </ul>

          <h3>Issues and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Token validation</strong> - Always validate token signatures, issuer, audience, and expiration</li>
              <li><strong>Trust boundaries</strong> - Understand what you're trusting the IdP to do vs. what you control</li>
              <li><strong>Authorization vs Authentication</strong> - IdP handles authentication; your app must handle authorization</li>
              <li><strong>Token storage</strong> - Store tokens securely (encrypted, HttpOnly cookies for web)</li>
              <li><strong>Token lifetime</strong> - Balance security with user experience (short-lived with refresh tokens)</li>
              <li><strong>Multiple IdPs</strong> - Plan for supporting multiple identity providers if needed</li>
              <li><strong>Fallback strategy</strong> - Have a plan if the IdP is unavailable</li>
              <li><strong>Privacy concerns</strong> - Understand what data is shared by the IdP</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Building a new application that requires authentication</li>
            <li>Need to support <strong>multiple identity providers</strong> (social login, enterprise SSO)</li>
            <li>Want to provide <strong>single sign-on (SSO)</strong> across multiple applications</li>
            <li>Need to integrate with <strong>corporate directories</strong> (Active Directory, Entra ID)</li>
            <li>Want to <strong>avoid building</strong> authentication infrastructure</li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>You have specific security requirements that cannot be met by external providers</li>
            <li>Network connectivity to IdP cannot be guaranteed (consider local token validation)</li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üîí <strong>Security</strong> - Strong authentication and identity foundation (SE:05, SE:06)</li>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Leverage highly available identity services (RE:02)</li>
            <li>üîß <strong>Operational Excellence</strong> - Reduce operational burden of identity management (OE:06)</li>
            <li>üí∞ <strong>Cost Optimization</strong> - Avoid building custom authentication systems (CO:07)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Microsoft Entra ID (Azure Active Directory):</strong></p>
          <ul>
            <li><strong>App Registrations</strong> - Register applications to enable authentication</li>
            <li><strong>Enterprise Applications</strong> - Configure SSO and user assignment</li>
            <li><strong>B2C Tenant</strong> - Consumer-facing identity management with social logins</li>
            <li><strong>External Identities</strong> - Partner collaboration with guest access</li>
          </ul>

          <p><strong>Azure App Service Authentication:</strong></p>
          <ul>
            <li>Built-in authentication without code changes (Easy Auth)</li>
            <li>Support for Microsoft, Google, Facebook, Twitter, OpenID Connect</li>
            <li>Automatic token refresh and session management</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>ASP.NET Core with Microsoft Entra ID (OpenID Connect):</strong></p>
          <pre><code>// Program.cs
using Microsoft.Identity.Web;

var builder = WebApplication.CreateBuilder(args);

// Add authentication with Microsoft Entra ID
builder.Services.AddAuthentication(OpenIdConnectDefaults.AuthenticationScheme)
    .AddMicrosoftIdentityWebApp(builder.Configuration.GetSection("AzureAd"));

builder.Services.AddAuthorization();
builder.Services.AddRazorPages();

var app = builder.Build();

app.UseAuthentication();
app.UseAuthorization();
app.MapRazorPages();
app.Run();

// appsettings.json
{
  "AzureAd": {
    "Instance": "https://login.microsoftonline.com/",
    "TenantId": "your-tenant-id",
    "ClientId": "your-client-id",
    "CallbackPath": "/signin-oidc"
  }
}

// Protected page
[Authorize]
public class SecurePageModel : PageModel
{
    public string UserName => User.Identity?.Name ?? "Unknown";
    
    public IActionResult OnGet()
    {
        // Access user claims
        var email = User.FindFirst(ClaimTypes.Email)?.Value;
        var roles = User.FindAll(ClaimTypes.Role).Select(c => c.Value);
        
        return Page();
    }
}</code></pre>

          <p><strong>Node.js with Passport and OIDC:</strong></p>
          <pre><code>const passport = require('passport');
const OIDCStrategy = require('passport-azure-ad').OIDCStrategy;

// Configure OIDC strategy
passport.use(new OIDCStrategy({
    identityMetadata: 'https://login.microsoftonline.com/your-tenant/.well-known/openid-configuration',
    clientID: process.env.CLIENT_ID,
    responseType: 'code id_token',
    responseMode: 'form_post',
    redirectUrl: 'http://localhost:3000/auth/callback',
    clientSecret: process.env.CLIENT_SECRET,
    validateIssuer: true,
    passReqToCallback: false
  },
  function(iss, sub, profile, accessToken, refreshToken, done) {
    // User authenticated successfully
    return done(null, profile);
  }
));

// Protect routes
app.get('/protected', 
  passport.authenticate('azuread-openidconnect', { failureRedirect: '/login' }),
  (req, res) => {
    res.send(`Hello ${req.user.displayName}`);
  }
);</code></pre>

          <p><strong>Azure App Service Easy Auth Configuration:</strong></p>
          <pre><code># Enable authentication in Azure App Service
az webapp auth update \
    --resource-group myResourceGroup \
    --name myWebApp \
    --enabled true \
    --action LoginWithAzureActiveDirectory

# Configure Microsoft Entra ID
az webapp auth microsoft update \
    --resource-group myResourceGroup \
    --name myWebApp \
    --client-id "your-client-id" \
    --client-secret "your-client-secret" \
    --issuer "https://sts.windows.net/your-tenant-id/" \
    --allowed-audiences "https://mywebapp.azurewebsites.net"

# Access user info in application
// .NET
var userId = Request.Headers["X-MS-CLIENT-PRINCIPAL-ID"];
var userName = Request.Headers["X-MS-CLIENT-PRINCIPAL-NAME"];

// Node.js
const userId = req.headers['x-ms-client-principal-id'];
const userName = req.headers['x-ms-client-principal-name'];</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#valet-key"><strong>Valet Key</strong></a> - Combine with federated identity to issue temporary access tokens</li>
            <li>üîó <strong>Gatekeeper</strong> - Additional security layer that can validate federated tokens</li>
            <li>üîó <a href="#external-config"><strong>External Configuration Store</strong></a> - Store IdP configuration externally</li>
          </ul>
        </section>

        <!-- Quarantine Pattern -->
        <section id="quarantine" role="article">
          <h1>üõ°Ô∏è Quarantine</h1>
          <div class="badges">
            <span class="badge badge-security">Security</span>
            <span class="badge badge-validation">Validation</span>
          </div>

          <h2>Context & Problem</h2>
          <p>Modern applications frequently consume external software artifacts such as container images, libraries, packages, open-source components, and third-party dependencies. These external resources may contain malware, security vulnerabilities, or malicious code that could compromise the application or infrastructure.</p>
          
          <p>Directly deploying untrusted or unvalidated external artifacts to production environments exposes the system to significant security risks including data breaches, service disruptions, and compliance violations.</p>

          <h2>Solution</h2>
          <p>Implement a quarantine mechanism that isolates and validates external software artifacts before allowing them to be used in production environments. The quarantine process should include automated security scanning, validation checks, and approval workflows to ensure only trusted artifacts are deployed.</p>

          <div class="mermaid">
graph LR
    subgraph "External Sources"
    Ext1[Docker Hub]
    Ext2[npm Registry]
    Ext3[NuGet Gallery]
    Ext4[Maven Central]
    end
    
    subgraph "Quarantine Zone"
    Q[Quarantine<br/>Repository]
    Scan[Security<br/>Scanner]
    Valid[Validation<br/>Checks]
    end
    
    subgraph "Production"
    Approved[Approved<br/>Repository]
    Prod[Production<br/>Environment]
    end
    
    Ext1 --> Q
    Ext2 --> Q
    Ext3 --> Q
    Ext4 --> Q
    
    Q --> Scan
    Scan --> Valid
    Valid -->|Pass| Approved
    Valid -->|Fail| Reject[Reject &<br/>Alert]
    
    Approved --> Prod
    
    style Q fill:#fff3cd
    style Scan fill:#e3f2fd
    style Valid fill:#e3f2fd
    style Approved fill:#d1fae5
    style Reject fill:#f8d7da
          </div>

          <h3>Quarantine Process</h3>
          <ol>
            <li><strong>Ingestion</strong> - External artifacts are pulled into isolated quarantine environment</li>
            <li><strong>Security Scanning</strong> - Automated tools scan for vulnerabilities, malware, and known threats</li>
            <li><strong>Policy Validation</strong> - Verify compliance with organizational security policies</li>
            <li><strong>License Check</strong> - Ensure license compatibility and compliance</li>
            <li><strong>Behavioral Analysis</strong> - Optional dynamic analysis in sandboxed environment</li>
            <li><strong>Approval</strong> - Manual or automated approval based on risk threshold</li>
            <li><strong>Promotion</strong> - Move approved artifacts to trusted repository</li>
            <li><strong>Monitoring</strong> - Continuous monitoring for newly discovered vulnerabilities</li>
          </ol>

          <h3>Validation Types</h3>
          <ul>
            <li><strong>Vulnerability Scanning</strong> - CVE database checks, known exploits</li>
            <li><strong>Malware Detection</strong> - Signature-based and heuristic analysis</li>
            <li><strong>Integrity Verification</strong> - Checksum validation, signature verification</li>
            <li><strong>License Compliance</strong> - Identify licensing restrictions and conflicts</li>
            <li><strong>Configuration Review</strong> - Check for insecure default configurations</li>
            <li><strong>Dependency Analysis</strong> - Recursive scanning of transitive dependencies</li>
            <li><strong>Behavioral Testing</strong> - Runtime behavior in isolated sandbox</li>
          </ul>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Prevent supply chain attacks</strong> - Block compromised or malicious artifacts</li>
            <li>‚úÖ <strong>Early vulnerability detection</strong> - Identify issues before production deployment</li>
            <li>‚úÖ <strong>Compliance assurance</strong> - Enforce organizational security policies</li>
            <li>‚úÖ <strong>License risk management</strong> - Avoid license violations and conflicts</li>
            <li>‚úÖ <strong>Audit trail</strong> - Track artifact provenance and approval history</li>
            <li>‚úÖ <strong>Reduced incident response</strong> - Prevent issues rather than react to them</li>
          </ul>

          <h3>Issues and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Build pipeline impact</strong> - Scanning adds time to deployment process; optimize for speed</li>
              <li><strong>False positives</strong> - Balance security with developer productivity; have exception process</li>
              <li><strong>Continuous monitoring</strong> - New vulnerabilities discovered daily; rescan approved artifacts</li>
              <li><strong>Private repositories</strong> - Ensure quarantine system can access all artifact sources</li>
              <li><strong>Caching strategy</strong> - Cache scanning results for unchanged artifacts</li>
              <li><strong>Severity thresholds</strong> - Define what level of risk is acceptable for your environment</li>
              <li><strong>Air-gapped environments</strong> - Special considerations for disconnected networks</li>
              <li><strong>Emergency overrides</strong> - Have process for critical security patches that need fast-tracking</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Application depends on <strong>external libraries, packages, or container images</strong></li>
            <li>Operating in <strong>regulated industries</strong> with strict security requirements</li>
            <li>Managing <strong>multi-tenant environments</strong> where isolation is critical</li>
            <li>Concerned about <strong>supply chain security</strong> and provenance</li>
            <li>Need to enforce <strong>organizational security policies</strong> on external dependencies</li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>All artifacts are internally developed and already security-tested</li>
            <li>Deployment speed is more critical than security validation (use at your own risk)</li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>üîí <strong>Security</strong> - Defense in depth with artifact validation (SE:04, SE:06, SE:08)</li>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Prevent deployment of unstable or vulnerable components (RE:07)</li>
            <li>üîß <strong>Operational Excellence</strong> - Automated validation and compliance (OE:08, OE:11)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Container Registry (ACR) with Quarantine:</strong></p>
          <ul>
            <li><strong>Content Trust</strong> - Docker Content Trust (Notary) for image signing</li>
            <li><strong>Quarantine Policy</strong> - Automatically quarantine images until scanned</li>
            <li><strong>Microsoft Defender for Containers</strong> - Vulnerability scanning integration</li>
            <li><strong>Azure Policy</strong> - Enforce compliance requirements</li>
          </ul>

          <p><strong>Azure DevOps Security Scanning:</strong></p>
          <ul>
            <li><strong>Component Governance</strong> - Scan for vulnerable open-source components</li>
            <li><strong>Pipeline Security</strong> - Gate deployments based on scan results</li>
            <li><strong>Artifact Feed</strong> - Private NuGet, npm, Maven feeds with scanning</li>
          </ul>

          <p><strong>Third-Party Tools:</strong></p>
          <ul>
            <li><strong>Snyk</strong> - Dependency vulnerability scanning and monitoring</li>
            <li><strong>Aqua Security</strong> - Container security and runtime protection</li>
            <li><strong>Twistlock/Prisma Cloud</strong> - Comprehensive cloud-native security</li>
            <li><strong>JFrog Xray</strong> - Universal artifact analysis and compliance</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>Azure Container Registry with Quarantine Pattern:</strong></p>
          <pre><code># Enable quarantine pattern in ACR
az acr config content-trust update \
    --registry myregistry \
    --status enabled

# Configure Microsoft Defender for Containers
az security assessment create \
    --name "Container registry images should have vulnerability findings resolved" \
    --status-code "Unhealthy"

# Azure Pipeline YAML with security scanning
trigger:
  - main

pool:
  vmImage: 'ubuntu-latest'

stages:
- stage: Quarantine
  jobs:
  - job: ScanImage
    steps:
    - task: Docker@2
      inputs:
        command: build
        repository: myapp
        tags: $(Build.BuildId)
    
    - task: ContainerScan@0
      displayName: 'Scan for vulnerabilities'
      inputs:
        dockerImage: 'myapp:$(Build.BuildId)'
        sevThreshold: 'HIGH'
    
    - task: SnykSecurityScan@1
      displayName: 'Snyk Security Scan'
      inputs:
        serviceConnectionEndpoint: 'Snyk'
        failOnIssues: true
    
    - script: |
        # Custom validation logic
        ./validate-license-compliance.sh
      displayName: 'Validate licenses'

- stage: Approve
  dependsOn: Quarantine
  condition: succeeded()
  jobs:
  - job: ManualApproval
    pool: server
    steps:
    - task: ManualValidation@0
      inputs:
        instructions: 'Review security scan results before promoting to production'

- stage: Promote
  dependsOn: Approve
  condition: succeeded()
  jobs:
  - job: PromoteImage
    steps:
    - task: Docker@2
      inputs:
        command: push
        repository: myregistry.azurecr.io/myapp
        tags: |
          $(Build.BuildId)
          latest</code></pre>

          <p><strong>Custom Quarantine Service:</strong></p>
          <pre><code>public class QuarantineService
{
    private readonly IVulnerabilityScanner _scanner;
    private readonly ILicenseValidator _licenseValidator;
    private readonly IArtifactRepository _quarantineRepo;
    private readonly IArtifactRepository _productionRepo;

    public async Task&lt;QuarantineResult&gt; ProcessArtifactAsync(string artifactUrl)
    {
        var result = new QuarantineResult { ArtifactUrl = artifactUrl };

        // Step 1: Download to quarantine
        var artifact = await _quarantineRepo.DownloadAsync(artifactUrl);
        result.QuarantineId = artifact.Id;

        // Step 2: Vulnerability scanning
        var vulnScanResult = await _scanner.ScanAsync(artifact);
        result.Vulnerabilities = vulnScanResult.Issues;
        result.HighSeverityCount = vulnScanResult.Issues.Count(v => v.Severity == "HIGH" || v.Severity == "CRITICAL");

        // Step 3: License validation
        var licenseResult = await _licenseValidator.ValidateAsync(artifact);
        result.LicenseCompliant = licenseResult.IsCompliant;
        result.LicenseIssues = licenseResult.Issues;

        // Step 4: Policy evaluation
        if (result.HighSeverityCount > 0)
        {
            result.Status = QuarantineStatus.Rejected;
            result.Reason = $"Found {result.HighSeverityCount} high severity vulnerabilities";
            await NotifySecurityTeamAsync(result);
            return result;
        }

        if (!result.LicenseCompliant)
        {
            result.Status = QuarantineStatus.Rejected;
            result.Reason = "License compliance check failed";
            return result;
        }

        // Step 5: Promote to production repository
        result.Status = QuarantineStatus.Approved;
        await _productionRepo.PromoteAsync(artifact);
        result.ProductionUrl = $"https://prod.repository/{artifact.Name}:{artifact.Tag}";

        return result;
    }
}

public enum QuarantineStatus { Quarantined, Scanning, Approved, Rejected }

public class QuarantineResult
{
    public string ArtifactUrl { get; set; }
    public string QuarantineId { get; set; }
    public QuarantineStatus Status { get; set; }
    public List&lt;Vulnerability&gt; Vulnerabilities { get; set; }
    public int HighSeverityCount { get; set; }
    public bool LicenseCompliant { get; set; }
    public List&lt;string&gt; LicenseIssues { get; set; }
    public string Reason { get; set; }
    public string ProductionUrl { get; set; }
}</code></pre>

          <p><strong>GitHub Actions Security Workflow:</strong></p>
          <pre><code>name: Security Quarantine

on:
  pull_request:
  push:
    branches: [main]

jobs:
  quarantine:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'
          exit-code: '1'
      
      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'
      
      - name: Snyk Security Scan
        uses: snyk/actions/node@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --severity-threshold=high
      
      - name: License check
        run: |
          npm install -g license-checker
          license-checker --production --failOn 'GPL;AGPL'</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#valet-key"><strong>Valet Key</strong></a> - Provide limited-time access to quarantined artifacts for review</li>
            <li>üîó <a href="#external-config"><strong>External Configuration Store</strong></a> - Store quarantine policies and thresholds externally</li>
            <li>üîó <a href="#gateway-routing"><strong>Gateway Routing</strong></a> - Route artifact requests through quarantine validation gateway</li>
            <li>üîó <a href="#health-monitoring"><strong>Health Endpoint Monitoring</strong></a> - Monitor quarantine system health and scan queue depth</li>
          </ul>
        </section>

        <!-- Valet Key Pattern -->
        <section id="valet-key" role="article">
          <h1>üîë Valet Key</h1>
          <div class="badges">
            <span class="badge badge-security">Security</span>
            <span class="badge badge-access">Access Control</span>
          </div>

          <h2>Context & Problem</h2>
          <p>Client applications often need to access data or resources stored in cloud services like Azure Blob Storage, Amazon S3, or other data stores. The traditional approach of routing all data through the application server creates several problems:</p>
          
          <ul>
            <li>Increases load and cost for the application (data transfer, compute)</li>
            <li>Limits scalability and responsiveness</li>
            <li>Application becomes a bottleneck for data access</li>
            <li>Requires implementing access control logic in application code</li>
          </ul>

          <h2>Solution</h2>
          <p>Use a token or key that provides clients with restricted direct access to a specific resource. This is similar to a physical valet key that allows a parking attendant to drive your car but restricts access to the trunk and glove compartment.</p>
          
          <p>The application generates a time-limited token with specific permissions (read, write, delete) for a particular resource, then gives this token to the client. The client uses the token to directly access the resource from the storage service without going through the application.</p>

          <div class="mermaid">
sequenceDiagram
    participant Client
    participant App as Application
    participant Storage as Cloud Storage<br/>(Blob, S3)
    
    Client->>App: 1. Request access to resource
    App->>App: 2. Authenticate & authorize user
    App->>App: 3. Generate SAS token/signed URL<br/>(limited permissions & time)
    App-->>Client: 4. Return token/URL
    Client->>Storage: 5. Access resource directly with token
    Storage->>Storage: 6. Validate token
    Storage-->>Client: 7. Return resource data
    
    Note over Client,Storage: Application not involved in data transfer
          </div>

          <h3>How It Works</h3>
          <ol>
            <li>Client requests access to a specific resource from the application</li>
            <li>Application authenticates the client and validates permissions</li>
            <li>Application generates a time-limited, permission-scoped token (valet key)</li>
            <li>Token/URL is returned to the client</li>
            <li>Client directly accesses the storage service using the token</li>
            <li>Storage service validates the token and serves the resource</li>
            <li>Token automatically expires after specified time period</li>
          </ol>

          <h3>Token/Key Types</h3>
          <ul>
            <li><strong>Azure Storage SAS Token</strong> - Shared Access Signature with granular permissions</li>
            <li><strong>AWS Pre-Signed URLs</strong> - Temporary URLs with embedded credentials</li>
            <li><strong>Google Cloud Signed URLs</strong> - Time-limited access to GCS resources</li>
            <li><strong>Cloudinary Signed URLs</strong> - Media delivery with transformation parameters</li>
            <li><strong>Custom JWT Tokens</strong> - Application-specific resource tokens</li>
          </ul>

          <h3>Benefits</h3>
          <ul>
            <li>‚úÖ <strong>Reduced server load</strong> - Data transfer happens directly between client and storage</li>
            <li>‚úÖ <strong>Lower costs</strong> - No data egress through application servers</li>
            <li>‚úÖ <strong>Better performance</strong> - Direct access eliminates application as bottleneck</li>
            <li>‚úÖ <strong>Improved scalability</strong> - Storage service handles scale, not application</li>
            <li>‚úÖ <strong>Enhanced security</strong> - Time-limited, permission-scoped access</li>
            <li>‚úÖ <strong>Simplified architecture</strong> - Offload data delivery to storage service</li>
          </ul>

          <h3>Issues and Considerations</h3>
          <div class="callout callout-warning">
            <strong>‚ö†Ô∏è Critical Considerations:</strong>
            <ul>
              <li><strong>Token expiration</strong> - Balance security (short) with user experience (long enough)</li>
              <li><strong>Revocation</strong> - Most valet keys cannot be revoked before expiration; plan accordingly</li>
              <li><strong>Token scope</strong> - Grant minimum necessary permissions (principle of least privilege)</li>
              <li><strong>Network security</strong> - Always use HTTPS to prevent token interception</li>
              <li><strong>Client trust</strong> - Client can share token; consider implications</li>
              <li><strong>Audit logging</strong> - Enable storage service logging to track access</li>
              <li><strong>Cross-origin access</strong> - Configure CORS if web clients access from different domain</li>
              <li><strong>Large files</strong> - Consider upload/download resumption if connections unreliable</li>
            </ul>
          </div>

          <h3>When to Use This Pattern</h3>
          <p><strong>‚úÖ Use when:</strong></p>
          <ul>
            <li>Need to minimize resource usage and <strong>maximize scalability</strong></li>
            <li>Clients need to <strong>upload or download large files</strong></li>
            <li>Want to <strong>reduce data transfer costs</strong> through application servers</li>
            <li>Storage service supports <strong>token-based access</strong> (SAS, signed URLs)</li>
            <li>Application already authenticates clients (to validate before issuing tokens)</li>
          </ul>

          <p><strong>‚ùå Not suitable when:</strong></p>
          <ul>
            <li>Need to <strong>validate or transform data</strong> during transfer</li>
            <li>Need <strong>immediate revocation</strong> of access rights</li>
            <li>Resources are very small (overhead of token generation not worth it)</li>
            <li>Storage service doesn't support granular token-based access</li>
            <li>Complex authorization logic that changes frequently</li>
          </ul>

          <h3>Well-Architected Framework Alignment</h3>
          <ul>
            <li>‚ö° <strong>Performance Efficiency</strong> - Direct access eliminates bottlenecks (PE:05, PE:08)</li>
            <li>üí∞ <strong>Cost Optimization</strong> - Reduced compute and bandwidth costs (CO:02, CO:12)</li>
            <li>üîí <strong>Security</strong> - Least privilege access with time limits (SE:05, SE:08)</li>
            <li>üõ°Ô∏è <strong>Reliability</strong> - Leverage storage service reliability (RE:02)</li>
          </ul>

          <h3>Azure Implementation</h3>
          <p><strong>Azure Blob Storage - SAS Tokens:</strong></p>
          <ul>
            <li><strong>Service SAS</strong> - Access to specific blob, container, queue, or table</li>
            <li><strong>Account SAS</strong> - Access to resources across multiple services</li>
            <li><strong>User Delegation SAS</strong> - Secured with Entra ID credentials (recommended)</li>
            <li><strong>Stored Access Policy</strong> - Allows token revocation by revoking policy</li>
          </ul>

          <p><strong>Other Azure Services Supporting Valet Key:</strong></p>
          <ul>
            <li><strong>Azure Cosmos DB</strong> - Resource tokens for document-level access</li>
            <li><strong>Azure Service Bus</strong> - Shared Access Signatures for queues/topics</li>
            <li><strong>Azure Event Hubs</strong> - SAS tokens for event streaming</li>
            <li><strong>Azure Files</strong> - SAS tokens for file share access</li>
          </ul>

          <h3>Example Code</h3>
          <p><strong>Generate SAS Token for Blob Upload (.NET):</strong></p>
          <pre><code>using Azure.Storage.Blobs;
using Azure.Storage.Sas;

public class ValetKeyService
{
    private readonly BlobServiceClient _blobServiceClient;

    public async Task&lt;string&gt; GenerateUploadTokenAsync(
        string containerName, 
        string blobName, 
        TimeSpan validity)
    {
        // Get container client
        var containerClient = _blobServiceClient.GetBlobContainerClient(containerName);
        await containerClient.CreateIfNotExistsAsync();

        // Get blob client
        var blobClient = containerClient.GetBlobClient(blobName);

        // Define permissions (write only)
        var sasBuilder = new BlobSasBuilder
        {
            BlobContainerName = containerName,
            BlobName = blobName,
            Resource = "b", // Blob
            StartsOn = DateTimeOffset.UtcNow,
            ExpiresOn = DateTimeOffset.UtcNow.Add(validity)
        };

        // Grant write and create permissions only
        sasBuilder.SetPermissions(BlobSasPermissions.Write | BlobSasPermissions.Create);

        // Generate SAS token
        var sasToken = blobClient.GenerateSasUri(sasBuilder);
        
        return sasToken.ToString();
    }

    public async Task&lt;string&gt; GenerateDownloadTokenAsync(
        string containerName, 
        string blobName, 
        TimeSpan validity)
    {
        var containerClient = _blobServiceClient.GetBlobContainerClient(containerName);
        var blobClient = containerClient.GetBlobClient(blobName);

        var sasBuilder = new BlobSasBuilder
        {
            BlobContainerName = containerName,
            BlobName = blobName,
            Resource = "b",
            StartsOn = DateTimeOffset.UtcNow,
            ExpiresOn = DateTimeOffset.UtcNow.Add(validity)
        };

        // Grant read permission only
        sasBuilder.SetPermissions(BlobSasPermissions.Read);

        var sasToken = blobClient.GenerateSasUri(sasBuilder);
        return sasToken.ToString();
    }
}

// API Controller
[ApiController]
[Route("api/[controller]")]
public class FilesController : ControllerBase
{
    private readonly ValetKeyService _valetKeyService;

    [HttpPost("upload-url")]
    [Authorize]
    public async Task&lt;IActionResult&gt; GetUploadUrl([FromBody] UploadRequest request)
    {
        // Validate user has permission to upload
        if (!await AuthorizeUploadAsync(User, request.FileName))
            return Forbid();

        // Generate valet key (15 minute validity)
        var uploadUrl = await _valetKeyService.GenerateUploadTokenAsync(
            "user-uploads",
            $"{User.Identity.Name}/{request.FileName}",
            TimeSpan.FromMinutes(15)
        );

        return Ok(new { uploadUrl });
    }

    [HttpGet("download-url/{fileName}")]
    [Authorize]
    public async Task&lt;IActionResult&gt; GetDownloadUrl(string fileName)
    {
        // Validate user has permission to download
        if (!await AuthorizeDownloadAsync(User, fileName))
            return Forbid();

        // Generate valet key (5 minute validity)
        var downloadUrl = await _valetKeyService.GenerateDownloadTokenAsync(
            "user-uploads",
            $"{User.Identity.Name}/{fileName}",
            TimeSpan.FromMinutes(5)
        );

        return Ok(new { downloadUrl });
    }
}</code></pre>

          <p><strong>Client-Side Usage (JavaScript):</strong></p>
          <pre><code>// Get upload URL from application
async function uploadFile(file) {
    // Step 1: Request valet key from app
    const response = await fetch('/api/files/upload-url', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${accessToken}`
        },
        body: JSON.stringify({ fileName: file.name })
    });

    const { uploadUrl } = await response.json();

    // Step 2: Upload directly to Azure Storage using valet key
    const uploadResponse = await fetch(uploadUrl, {
        method: 'PUT',
        headers: {
            'x-ms-blob-type': 'BlockBlob',
            'Content-Type': file.type
        },
        body: file
    });

    if (uploadResponse.ok) {
        console.log('File uploaded successfully');
    }
}

// Download file with valet key
async function downloadFile(fileName) {
    // Step 1: Request valet key from app
    const response = await fetch(`/api/files/download-url/${fileName}`, {
        headers: {
            'Authorization': `Bearer ${accessToken}`
        }
    });

    const { downloadUrl } = await response.json();

    // Step 2: Download directly from Azure Storage
    window.location.href = downloadUrl; // Browser will download file
}</code></pre>

          <p><strong>AWS S3 Pre-Signed URL (Python):</strong></p>
          <pre><code>import boto3
from botocore.exceptions import ClientError

def generate_presigned_url(bucket_name, object_key, expiration=3600, http_method='GET'):
    """
    Generate a presigned URL for S3 object access
    
    :param bucket_name: S3 bucket name
    :param object_key: Object key in the bucket
    :param expiration: Time in seconds for URL to remain valid
    :param http_method: HTTP method (GET for download, PUT for upload)
    :return: Presigned URL as string
    """
    s3_client = boto3.client('s3')
    
    try:
        # Generate presigned URL
        if http_method == 'GET':
            url = s3_client.generate_presigned_url(
                'get_object',
                Params={'Bucket': bucket_name, 'Key': object_key},
                ExpiresIn=expiration
            )
        elif http_method == 'PUT':
            url = s3_client.generate_presigned_url(
                'put_object',
                Params={'Bucket': bucket_name, 'Key': object_key},
                ExpiresIn=expiration
            )
        else:
            raise ValueError(f'Unsupported HTTP method: {http_method}')
            
        return url
    
    except ClientError as e:
        print(f'Error generating presigned URL: {e}')
        return None

# Flask API endpoint
from flask import Flask, jsonify, request
from functools import wraps

app = Flask(__name__)

def require_auth(f):
    @wraps(f)
    def decorated(*args, **kwargs):
        # Implement your authentication logic
        token = request.headers.get('Authorization')
        if not token or not verify_token(token):
            return jsonify({'error': 'Unauthorized'}), 401
        return f(*args, **kwargs)
    return decorated

@app.route('/api/upload-url', methods=['POST'])
@require_auth
def get_upload_url():
    data = request.json
    file_name = data.get('fileName')
    user_id = get_user_id_from_token(request.headers.get('Authorization'))
    
    # Generate presigned URL for upload (15 minutes)
    object_key = f'uploads/{user_id}/{file_name}'
    url = generate_presigned_url('my-bucket', object_key, 900, 'PUT')
    
    return jsonify({'uploadUrl': url})

@app.route('/api/download-url/&lt;file_name&gt;', methods=['GET'])
@require_auth
def get_download_url(file_name):
    user_id = get_user_id_from_token(request.headers.get('Authorization'))
    
    # Verify user owns this file
    object_key = f'uploads/{user_id}/{file_name}'
    
    # Generate presigned URL for download (5 minutes)
    url = generate_presigned_url('my-bucket', object_key, 300, 'GET')
    
    return jsonify({'downloadUrl': url})</code></pre>

          <p><strong>Azure Storage with Stored Access Policy (for revocation):</strong></p>
          <pre><code>// Create stored access policy for revocable tokens
var containerClient = blobServiceClient.GetBlobContainerClient("documents");

// Define policy
var accessPolicy = new BlobSignedIdentifier
{
    Id = "read-policy-2024",
    AccessPolicy = new BlobAccessPolicy
    {
        PolicyStartsOn = DateTimeOffset.UtcNow,
        PolicyExpiresOn = DateTimeOffset.UtcNow.AddYears(1),
        Permissions = "r" // Read only
    }
};

await containerClient.SetAccessPolicyAsync(
    permissions: new[] { accessPolicy }
);

// Generate SAS token using stored policy
var sasBuilder = new BlobSasBuilder
{
    BlobContainerName = "documents",
    BlobName = "report.pdf",
    Resource = "b",
    Identifier = "read-policy-2024" // Reference to stored policy
};

var sasToken = blobClient.GenerateSasUri(sasBuilder);

// To revoke all tokens: delete or modify the stored access policy
await containerClient.SetAccessPolicyAsync(permissions: Array.Empty&lt;BlobSignedIdentifier&gt;());</code></pre>

          <h3>Related Patterns</h3>
          <ul>
            <li>üîó <a href="#federated-identity"><strong>Federated Identity</strong></a> - Authenticate users before issuing valet keys</li>
            <li>üîó <strong>Gatekeeper</strong> - Additional validation layer before issuing tokens</li>
            <li>üîó <a href="#gateway-routing"><strong>Gateway Routing</strong></a> - Route token requests through centralized gateway</li>
            <li>üîó <a href="#static-content"><strong>Static Content Hosting</strong></a> - Combine with CDN for optimal performance</li>
          </ul>
        </section>

        <!-- Resources Section -->
        <section id="resources" role="article">
          <h1>üìö Resources</h1>
          <div class="badges">
            <span class="badge badge-docs">Documentation</span>
            <span class="badge badge-community">Community</span>
            <span class="badge badge-tools">Tools</span>
          </div>

          <h2>Official Documentation</h2>
          
          <h3>Microsoft Azure Architecture Center</h3>
          <ul>
            <li>üåê <a href="https://learn.microsoft.com/azure/architecture/" target="_blank" rel="noopener">Azure Architecture Center</a> - Main hub for architecture guidance</li>
            <li>üìñ <a href="https://learn.microsoft.com/azure/architecture/patterns/" target="_blank" rel="noopener">Cloud Design Patterns</a> - Complete catalog of all patterns</li>
            <li>üèõÔ∏è <a href="https://learn.microsoft.com/azure/architecture/guide/architecture-styles/" target="_blank" rel="noopener">Architecture Styles</a> - Guide to choosing architecture styles</li>
            <li>üéØ <a href="https://learn.microsoft.com/azure/architecture/framework/" target="_blank" rel="noopener">Azure Well-Architected Framework</a> - Five pillars of architectural excellence</li>
            <li>üìê <a href="https://learn.microsoft.com/azure/architecture/browse/" target="_blank" rel="noopener">Architecture Reference</a> - Browse reference architectures</li>
          </ul>

          <h3>Pattern Categories</h3>
          <ul>
            <li>üíæ <a href="https://learn.microsoft.com/azure/architecture/patterns/category/data-management" target="_blank" rel="noopener">Data Management Patterns</a></li>
            <li>üé® <a href="https://learn.microsoft.com/azure/architecture/patterns/category/design-implementation" target="_blank" rel="noopener">Design & Implementation Patterns</a></li>
            <li>üì® <a href="https://learn.microsoft.com/azure/architecture/patterns/category/messaging" target="_blank" rel="noopener">Messaging Patterns</a></li>
            <li>üõ°Ô∏è <a href="https://learn.microsoft.com/azure/architecture/patterns/category/resiliency" target="_blank" rel="noopener">Reliability & Resiliency Patterns</a></li>
            <li>‚ö° <a href="https://learn.microsoft.com/azure/architecture/patterns/category/performance-scalability" target="_blank" rel="noopener">Performance & Scalability Patterns</a></li>
            <li>üîí <a href="https://learn.microsoft.com/azure/architecture/patterns/category/security" target="_blank" rel="noopener">Security Patterns</a></li>
          </ul>

          <h2>Books & Publications</h2>
          <ul>
            <li>üìï <strong>Domain-Driven Design</strong> by Eric Evans - Origin of Anti-Corruption Layer pattern</li>
            <li>üìó <strong>Enterprise Integration Patterns</strong> by Gregor Hohpe & Bobby Woolf - Messaging patterns fundamentals</li>
            <li>üìò <strong>Designing Data-Intensive Applications</strong> by Martin Kleppmann - Deep dive into distributed systems</li>
            <li>üìô <strong>Building Microservices</strong> by Sam Newman - Microservices architecture patterns</li>
            <li>üìî <strong>Release It!</strong> by Michael Nygard - Resilience patterns (Circuit Breaker, Bulkhead)</li>
            <li>üìì <strong>Cloud Native Patterns</strong> by Cornelia Davis - Patterns for cloud-native applications</li>
          </ul>

          <h2>Azure Services by Pattern</h2>
          
          <h3>Messaging & Integration</h3>
          <ul>
            <li>üî∑ <a href="https://learn.microsoft.com/azure/service-bus-messaging/" target="_blank" rel="noopener">Azure Service Bus</a> - Enterprise messaging with queues and topics</li>
            <li>üî∑ <a href="https://learn.microsoft.com/azure/event-grid/" target="_blank" rel="noopener">Azure Event Grid</a> - Event-driven architectures at scale</li>
            <li>üî∑ <a href="https://learn.microsoft.com/azure/event-hubs/" target="_blank" rel="noopener">Azure Event Hubs</a> - Big data streaming platform</li>
            <li>üî∑ <a href="https://learn.microsoft.com/azure/storage/queues/" target="_blank" rel="noopener">Azure Queue Storage</a> - Simple queue service</li>
          </ul>

          <h3>API Management & Gateway</h3>
          <ul>
            <li>üî∑ <a href="https://learn.microsoft.com/azure/api-management/" target="_blank" rel="noopener">Azure API Management</a> - Full-featured API gateway</li>
            <li>üî∑ <a href="https://learn.microsoft.com/azure/application-gateway/" target="_blank" rel="noopener">Azure Application Gateway</a> - Layer 7 load balancer</li>
            <li>üî∑ <a href="https://learn.microsoft.com/azure/frontdoor/" target="_blank" rel="noopener">Azure Front Door</a> - Global application acceleration</li>
          </ul>

          <h3>Data & Storage</h3>
          <ul>
            <li>üî∑ <a href="https://learn.microsoft.com/azure/cosmos-db/" target="_blank" rel="noopener">Azure Cosmos DB</a> - Globally distributed database</li>
            <li>üî∑ <a href="https://learn.microsoft.com/azure/storage/" target="_blank" rel="noopener">Azure Storage</a> - Blob, File, Queue, and Table storage</li>
            <li>üî∑ <a href="https://learn.microsoft.com/azure/azure-cache-for-redis/" target="_blank" rel="noopener">Azure Cache for Redis</a> - In-memory caching</li>
            <li>üî∑ <a href="https://learn.microsoft.com/azure/azure-sql/" target="_blank" rel="noopener">Azure SQL Database</a> - Managed relational database</li>
          </ul>

          <h3>Compute & Containers</h3>
          <ul>
            <li>üî∑ <a href="https://learn.microsoft.com/azure/app-service/" target="_blank" rel="noopener">Azure App Service</a> - Web apps and APIs</li>
            <li>üî∑ <a href="https://learn.microsoft.com/azure/azure-functions/" target="_blank" rel="noopener">Azure Functions</a> - Serverless compute</li>
            <li>üî∑ <a href="https://learn.microsoft.com/azure/container-apps/" target="_blank" rel="noopener">Azure Container Apps</a> - Serverless containers</li>
            <li>üî∑ <a href="https://learn.microsoft.com/azure/aks/" target="_blank" rel="noopener">Azure Kubernetes Service (AKS)</a> - Managed Kubernetes</li>
            <li>üî∑ <a href="https://learn.microsoft.com/azure/container-instances/" target="_blank" rel="noopener">Azure Container Instances</a> - Fast container deployment</li>
          </ul>

          <h3>Identity & Security</h3>
          <ul>
            <li>üî∑ <a href="https://learn.microsoft.com/entra/identity/" target="_blank" rel="noopener">Microsoft Entra ID</a> - Identity and access management</li>
            <li>üî∑ <a href="https://learn.microsoft.com/azure/key-vault/" target="_blank" rel="noopener">Azure Key Vault</a> - Secrets and key management</li>
            <li>üî∑ <a href="https://learn.microsoft.com/azure/defender-for-cloud/" target="_blank" rel="noopener">Microsoft Defender for Cloud</a> - Cloud security posture</li>
          </ul>

          <h2>Tools & SDKs</h2>
          
          <h3>Development Tools</h3>
          <ul>
            <li>üíª <a href="https://portal.azure.com/" target="_blank" rel="noopener">Azure Portal</a> - Web-based management console</li>
            <li>üíª <a href="https://learn.microsoft.com/cli/azure/" target="_blank" rel="noopener">Azure CLI</a> - Command-line interface</li>
            <li>üíª <a href="https://learn.microsoft.com/powershell/azure/" target="_blank" rel="noopener">Azure PowerShell</a> - PowerShell module</li>
            <li>üíª <a href="https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-azuretools" target="_blank" rel="noopener">Azure Tools for VS Code</a> - VS Code extensions</li>
            <li>üíª <a href="https://learn.microsoft.com/azure/developer/terraform/" target="_blank" rel="noopener">Terraform on Azure</a> - Infrastructure as Code</li>
            <li>üíª <a href="https://learn.microsoft.com/azure/azure-resource-manager/bicep/" target="_blank" rel="noopener">Azure Bicep</a> - DSL for Azure resources</li>
          </ul>

          <h3>Monitoring & Diagnostics</h3>
          <ul>
            <li>üìä <a href="https://learn.microsoft.com/azure/azure-monitor/" target="_blank" rel="noopener">Azure Monitor</a> - Comprehensive monitoring solution</li>
            <li>üìä <a href="https://learn.microsoft.com/azure/application-insights/" target="_blank" rel="noopener">Application Insights</a> - APM and analytics</li>
            <li>üìä <a href="https://learn.microsoft.com/azure/azure-monitor/logs/" target="_blank" rel="noopener">Log Analytics</a> - Log query and analysis</li>
          </ul>

          <h3>SDKs & Libraries</h3>
          <ul>
            <li>‚öôÔ∏è <a href="https://learn.microsoft.com/dotnet/azure/" target="_blank" rel="noopener">Azure SDK for .NET</a></li>
            <li>‚öôÔ∏è <a href="https://learn.microsoft.com/python/api/overview/azure/" target="_blank" rel="noopener">Azure SDK for Python</a></li>
            <li>‚öôÔ∏è <a href="https://learn.microsoft.com/javascript/api/overview/azure/" target="_blank" rel="noopener">Azure SDK for JavaScript/TypeScript</a></li>
            <li>‚öôÔ∏è <a href="https://learn.microsoft.com/java/azure/" target="_blank" rel="noopener">Azure SDK for Java</a></li>
            <li>‚öôÔ∏è <a href="https://github.com/Azure/azure-sdk-for-go" target="_blank" rel="noopener">Azure SDK for Go</a></li>
          </ul>

          <h2>Learning Resources</h2>
          
          <h3>Microsoft Learn</h3>
          <ul>
            <li>üéì <a href="https://learn.microsoft.com/training/paths/azure-architecture-fundamentals/" target="_blank" rel="noopener">Azure Architecture Fundamentals</a></li>
            <li>üéì <a href="https://learn.microsoft.com/training/paths/architect-modern-apps/" target="_blank" rel="noopener">Architect Modern Applications</a></li>
            <li>üéì <a href="https://learn.microsoft.com/training/paths/architect-migration-bcdr/" target="_blank" rel="noopener">Architect Migration, Business Continuity & Disaster Recovery</a></li>
            <li>üéì <a href="https://learn.microsoft.com/training/paths/architect-infrastructure-operations/" target="_blank" rel="noopener">Architect Infrastructure Operations</a></li>
          </ul>

          <h3>Certifications</h3>
          <ul>
            <li>üèÜ <a href="https://learn.microsoft.com/certifications/azure-solutions-architect/" target="_blank" rel="noopener">Azure Solutions Architect Expert</a> - AZ-305</li>
            <li>üèÜ <a href="https://learn.microsoft.com/certifications/azure-developer/" target="_blank" rel="noopener">Azure Developer Associate</a> - AZ-204</li>
            <li>üèÜ <a href="https://learn.microsoft.com/certifications/azure-administrator/" target="_blank" rel="noopener">Azure Administrator Associate</a> - AZ-104</li>
          </ul>

          <h2>Community & Support</h2>
          <ul>
            <li>üí¨ <a href="https://techcommunity.microsoft.com/category/azure" target="_blank" rel="noopener">Azure Tech Community</a> - Forums and discussions</li>
            <li>üí¨ <a href="https://learn.microsoft.com/answers/tags/133/azure" target="_blank" rel="noopener">Microsoft Q&A for Azure</a> - Community Q&A</li>
            <li>üí¨ <a href="https://stackoverflow.com/questions/tagged/azure" target="_blank" rel="noopener">Stack Overflow - Azure</a> - Developer questions</li>
            <li>üí¨ <a href="https://www.reddit.com/r/AZURE/" target="_blank" rel="noopener">Reddit - r/AZURE</a> - Community discussions</li>
            <li>üêô <a href="https://github.com/Azure" target="_blank" rel="noopener">Azure on GitHub</a> - Open source projects and samples</li>
            <li>üêô <a href="https://github.com/mspnp/architecture-center" target="_blank" rel="noopener">Architecture Center on GitHub</a> - Contribute to documentation</li>
          </ul>

          <h2>Sample Code & References</h2>
          <ul>
            <li>üì¶ <a href="https://github.com/Azure-Samples" target="_blank" rel="noopener">Azure Code Samples</a> - Official samples repository</li>
            <li>üì¶ <a href="https://learn.microsoft.com/samples/browse/?products=azure" target="_blank" rel="noopener">Browse Azure Samples</a> - Searchable sample browser</li>
            <li>üì¶ <a href="https://github.com/mspnp/samples" target="_blank" rel="noopener">Azure Architecture Samples</a> - Pattern implementation samples</li>
            <li>üì¶ <a href="https://azuresdkdocs.blob.core.windows.net/$web/index.html" target="_blank" rel="noopener">Azure SDK Documentation</a> - Complete SDK reference</li>
          </ul>

          <h2>Stay Updated</h2>
          <ul>
            <li>üì∞ <a href="https://azure.microsoft.com/blog/" target="_blank" rel="noopener">Azure Blog</a> - Official announcements and updates</li>
            <li>üì∞ <a href="https://azure.microsoft.com/updates/" target="_blank" rel="noopener">Azure Updates</a> - Product updates and previews</li>
            <li>üì∞ <a href="https://learn.microsoft.com/azure/architecture/changelog" target="_blank" rel="noopener">Architecture Center Changelog</a> - Documentation updates</li>
            <li>üé• <a href="https://www.youtube.com/@MicrosoftAzure" target="_blank" rel="noopener">Microsoft Azure YouTube</a> - Videos and tutorials</li>
            <li>üé• <a href="https://learn.microsoft.com/shows/azure-friday/" target="_blank" rel="noopener">Azure Friday</a> - Weekly show with Azure experts</li>
            <li>üê¶ <a href="https://twitter.com/Azure" target="_blank" rel="noopener">Azure on Twitter</a> - Follow @Azure</li>
          </ul>

          <h2>Related Technologies & Standards</h2>
          <ul>
            <li>üåê <a href="https://www.w3.org/TR/webarch/" target="_blank" rel="noopener">Web Architecture</a> - W3C standards</li>
            <li>üåê <a href="https://12factor.net/" target="_blank" rel="noopener">The Twelve-Factor App</a> - Methodology for building SaaS apps</li>
            <li>üåê <a href="https://microservices.io/patterns/" target="_blank" rel="noopener">Microservices.io Patterns</a> - Comprehensive microservices patterns</li>
            <li>üåê <a href="https://www.enterpriseintegrationpatterns.com/" target="_blank" rel="noopener">Enterprise Integration Patterns</a> - Classic messaging patterns</li>
            <li>üåê <a href="https://martinfowler.com/architecture/" target="_blank" rel="noopener">Martin Fowler - Architecture</a> - Software architecture articles</li>
            <li>üåê <a href="https://www.reactive-streams.org/" target="_blank" rel="noopener">Reactive Streams</a> - Asynchronous stream processing standard</li>
          </ul>

          <div class="callout callout-info">
            <strong>üí° Tip:</strong> Bookmark this page and the Azure Architecture Center for quick reference. These patterns are regularly updated with new insights and Azure service capabilities.
          </div>
        
          
          <hr />
          <div class="document-footer">
            <p>
              <strong>Last Updated:</strong> January 2026 | 
              <strong>Curated by:</strong> Murthy Vepa with ‚ù§Ô∏è | <strong>Powered by:</strong> GitHub Copilot
            </p>
          </div>
        
        </section>       
        </div>
      </main>
    </div>
    
    <nav class="controls" role="navigation" aria-label="Pagination">
      <div class="btn-group" role="group">
        <button class="btn btn-outline-info btn-sm" id="prevBtn" title="Previous" aria-label="Previous concept">&nbsp;&lt;&nbsp;</button>
        <button class="btn btn-outline-info btn-sm" id="nextBtn" title="Next" aria-label="Next concept">&nbsp;&gt;&nbsp;</button>
      </div>
    </nav>
  </div>  <div class="offcanvas offcanvas-start" tabindex="-1" id="sidebarOffcanvas" aria-labelledby="sidebarLabel">
    <div class="offcanvas-header">
      <h5 class="offcanvas-title" id="sidebarLabel">Contents</h5>
      <button type="button" class="btn-close" data-bs-dismiss="offcanvas" aria-label="Close"></button>
    </div>
    <div class="offcanvas-body p-0">
      <ul class="list-group list-group-flush w-100" id="tocMobile"></ul>
    </div>
  </div>

  <script>
    // ---- Mermaid Initialization ----
    document.addEventListener('DOMContentLoaded', () => {
      if (window.mermaid) {
        window.mermaid.contentLoaded();
      }
    });

    // ---- Configuration ----
    const sectionConfig = [
      // Overview
      { id: "overview", title: "‚òÅÔ∏è Overview", tags: ["intro", "overview", "cloud", "azure"], group: "Overview" },
      
      // Architecture Styles
      { id: "arch-styles-intro", title: "üèõÔ∏è Architecture Styles", tags: ["architecture", "styles", "patterns"], group: "Architecture Styles" },
      { id: "n-tier", title: "üè¢ N-tier", tags: ["architecture", "traditional", "layers"], group: "Architecture Styles" },
      { id: "web-queue-worker", title: "‚öôÔ∏è Web-Queue-Worker", tags: ["architecture", "async", "messaging"], group: "Architecture Styles" },
      { id: "microservices-arch", title: "üî∑ Microservices", tags: ["architecture", "distributed", "modern"], group: "Architecture Styles" },
      { id: "event-driven-arch", title: "‚ö° Event-driven", tags: ["architecture", "events", "realtime"], group: "Architecture Styles" },
      { id: "big-data-arch", title: "üìä Big Data", tags: ["architecture", "analytics", "ml"], group: "Architecture Styles" },
      { id: "big-compute-arch", title: "üíª Big Compute", tags: ["architecture", "hpc", "simulation"], group: "Architecture Styles" },
      
      // Data Management Patterns
      { id: "cache-aside", title: "üíæ Cache-Aside", tags: ["data", "performance", "caching"], group: "Data Management" },
      { id: "cqrs", title: "üìä CQRS", tags: ["data", "design", "command-query"], group: "Data Management" },
      { id: "event-sourcing", title: "üìù Event Sourcing", tags: ["data", "events", "audit"], group: "Data Management" },
      { id: "index-table", title: "üìá Index Table", tags: ["data", "query", "performance"], group: "Data Management" },
      { id: "materialized-view", title: "üëÅÔ∏è Materialized View", tags: ["data", "performance", "query"], group: "Data Management" },
      { id: "sharding", title: "üîÄ Sharding", tags: ["data", "scalability", "partitioning"], group: "Data Management" },
      
      // Design & Implementation Patterns
      { id: "ambassador", title: "üîå Ambassador", tags: ["design", "proxy", "connectivity"], group: "Design & Implementation" },
      { id: "anti-corruption", title: "üõ°Ô∏è Anti-Corruption Layer", tags: ["design", "legacy", "integration"], group: "Design & Implementation" },
      { id: "backends-frontends", title: "üñ•Ô∏è Backends for Frontends", tags: ["design", "api", "bff"], group: "Design & Implementation" },
      { id: "compute-consolidation", title: "üì¶ Compute Resource Consolidation", tags: ["design", "cost", "efficiency"], group: "Design & Implementation" },
      { id: "external-config", title: "‚öôÔ∏è External Configuration Store", tags: ["design", "config", "deployment"], group: "Design & Implementation" },
      { id: "gateway-aggregation", title: "üîÄ Gateway Aggregation", tags: ["design", "api", "gateway"], group: "Design & Implementation" },
      { id: "gateway-offloading", title: "üì§ Gateway Offloading", tags: ["design", "api", "gateway"], group: "Design & Implementation" },
      { id: "gateway-routing", title: "üîÄ Gateway Routing", tags: ["design", "api", "gateway"], group: "Design & Implementation" },
      { id: "sidecar", title: "üöó Sidecar", tags: ["design", "containers", "auxiliary"], group: "Design & Implementation" },
      { id: "strangler-fig", title: "üå≥ Strangler Fig", tags: ["design", "legacy", "migration"], group: "Design & Implementation" },
      
      // Messaging Patterns
      { id: "async-request-reply", title: "‚è±Ô∏è Asynchronous Request-Reply", tags: ["messaging", "async", "communication"], group: "Messaging" },
      { id: "claim-check", title: "üé´ Claim Check", tags: ["messaging", "payload", "storage"], group: "Messaging" },
      { id: "choreography", title: "üé≠ Choreography", tags: ["messaging", "events", "orchestration"], group: "Messaging" },
      { id: "competing-consumers", title: "üèÉ Competing Consumers", tags: ["messaging", "scalability", "queue"], group: "Messaging" },
      { id: "messaging-bridge", title: "üåâ Messaging Bridge", tags: ["messaging", "integration", "bridge"], group: "Messaging" },
      { id: "pipes-filters", title: "üîß Pipes and Filters", tags: ["messaging", "processing", "pipeline"], group: "Messaging" },
      { id: "priority-queue", title: "üéØ Priority Queue", tags: ["messaging", "queue", "priority"], group: "Messaging" },
      { id: "pub-sub", title: "üì¢ Publisher/Subscriber", tags: ["messaging", "events", "pub-sub"], group: "Messaging" },
      { id: "queue-load-leveling", title: "‚öñÔ∏è Queue-Based Load Leveling", tags: ["messaging", "queue", "resilience"], group: "Messaging" },
      { id: "sequential-convoy", title: "üöõ Sequential Convoy", tags: ["messaging", "ordering", "sequence"], group: "Messaging" },
      
      // Reliability & Resiliency Patterns
      { id: "bulkhead", title: "üö¢ Bulkhead", tags: ["reliability", "isolation", "fault-tolerance"], group: "Reliability & Resiliency" },
      { id: "circuit-breaker", title: "‚ö° Circuit Breaker", tags: ["reliability", "fault-tolerance", "resilience"], group: "Reliability & Resiliency" },
      { id: "compensating-transaction", title: "‚Ü©Ô∏è Compensating Transaction", tags: ["reliability", "transactions", "consistency"], group: "Reliability & Resiliency" },
      { id: "health-monitoring", title: "üíö Health Endpoint Monitoring", tags: ["reliability", "monitoring", "health"], group: "Reliability & Resiliency" },
      { id: "leader-election", title: "üëë Leader Election", tags: ["reliability", "coordination", "distributed"], group: "Reliability & Resiliency" },
      { id: "retry", title: "üîÑ Retry", tags: ["reliability", "fault-tolerance", "transient"], group: "Reliability & Resiliency" },
      { id: "saga", title: "üìñ Saga", tags: ["reliability", "transactions", "distributed"], group: "Reliability & Resiliency" },
      { id: "scheduler-agent", title: "üìÖ Scheduler Agent Supervisor", tags: ["reliability", "coordination", "workflow"], group: "Reliability & Resiliency" },
      { id: "throttling", title: "üö¶ Throttling", tags: ["reliability", "rate-limiting", "protection"], group: "Reliability & Resiliency" },
      
      // Performance & Scalability Patterns
      { id: "deployment-stamps", title: "üìÆ Deployment Stamps", tags: ["performance", "scalability", "deployment"], group: "Performance & Scalability" },
      { id: "geode", title: "üåç Geode", tags: ["performance", "geography", "latency"], group: "Performance & Scalability" },
      { id: "rate-limiting", title: "‚è±Ô∏è Rate Limiting", tags: ["performance", "throttling", "protection"], group: "Performance & Scalability" },
      { id: "static-content", title: "üìÑ Static Content Hosting", tags: ["performance", "cdn", "caching"], group: "Performance & Scalability" },
      
      // Security Patterns
      { id: "federated-identity", title: "üîê Federated Identity", tags: ["security", "authentication", "identity"], group: "Security" },
      { id: "quarantine", title: "üõ°Ô∏è Quarantine", tags: ["security", "validation", "safety"], group: "Security" },
      { id: "valet-key", title: "üîë Valet Key", tags: ["security", "access", "tokens"], group: "Security" },
      
      // Resources
      { id: "resources", title: "üìö Resources", tags: ["docs", "links", "reference"], group: "Resources" }
    ];

    // ---- State & rendering ----
    const state = {
      index: 0,
      filtered: sectionConfig.map((_, i) => i), // indices
    };

    const els = {
      toc: document.getElementById('toc'),
      tocMobile: document.getElementById('tocMobile'),
      prev: document.getElementById('prevBtn'),
      next: document.getElementById('nextBtn'),
      toggleSidebar: document.getElementById('toggleSidebar'),
      themeToggle: document.getElementById('themeToggle'),
      main: document.getElementById('main'),
      sidebar: document.querySelector('nav.sidebar'),
      sidebarOffcanvas: document.getElementById('sidebarOffcanvas')
    };

    function buildTOC(){
      // Clear both TOC lists
      els.toc.innerHTML = '';
      els.tocMobile.innerHTML = '';
      
      // Group sections by category
      const groups = {};
      const groupOrder = ['Overview', 'Architecture Styles', 'Data Management', 'Design & Implementation', 'Messaging', 
                          'Reliability & Resiliency', 'Performance & Scalability', 'Security', 'Resources'];
      
      state.filtered.forEach((idx) => {
        const s = sectionConfig[idx];
        const group = s.group || 'Other';
        if (!groups[group]) groups[group] = [];
        groups[group].push(s);
      });
      
      // Build menu with groups and sub-items
      groupOrder.forEach(groupName => {
        if (!groups[groupName]) return;
        
        const items = groups[groupName];
        
        // If group has only one item, render it as top-level
        if (items.length === 1) {
          const s = items[0];
          
          // Desktop sidebar
          const liDesktop = document.createElement('li');
          liDesktop.className = 'list-group-item';
          const aDesktop = document.createElement('a');
          aDesktop.href = `#${s.id}`;
          aDesktop.textContent = s.title;
          aDesktop.addEventListener('click', (e) => {
            e.preventDefault();
            navigateToId(s.id);
            closeSidebar();
          });
          liDesktop.appendChild(aDesktop);
          els.toc.appendChild(liDesktop);
          
          // Mobile offcanvas
          const liMobile = document.createElement('li');
          liMobile.className = 'list-group-item';
          const aMobile = document.createElement('a');
          aMobile.href = `#${s.id}`;
          aMobile.textContent = s.title;
          aMobile.addEventListener('click', (e) => {
            e.preventDefault();
            navigateToId(s.id);
            closeSidebar();
          });
          liMobile.appendChild(aMobile);
          els.tocMobile.appendChild(liMobile);
        } else {
          // Group header (non-clickable category label)
          const headerDesktop = document.createElement('li');
          headerDesktop.className = 'list-group-item';
          headerDesktop.style.cssText = 'pointer-events: none; padding: 0.75rem 1.25rem; background: linear-gradient(135deg, rgba(59, 130, 246, 0.08) 0%, rgba(16, 185, 129, 0.08) 100%); border-left: 3px solid #3b82f6; border-radius: 4px;';
          headerDesktop.innerHTML = `<span style="font-weight: 800; font-size: 0.8rem; letter-spacing: 0.8px; color: #1e40af; display: flex; align-items: center; gap: 0.5rem;"><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2.5" stroke-linecap="round" stroke-linejoin="round"><path d="M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path></svg>${groupName}</span>`;
          els.toc.appendChild(headerDesktop);
          
          const headerMobile = document.createElement('li');
          headerMobile.className = 'list-group-item';
          headerMobile.style.cssText = 'pointer-events: none; padding: 0.75rem 1.25rem; background: linear-gradient(135deg, rgba(59, 130, 246, 0.08) 0%, rgba(16, 185, 129, 0.08) 100%); border-left: 3px solid #3b82f6; border-radius: 4px;';
          headerMobile.innerHTML = `<span style="font-weight: 800; font-size: 0.8rem; letter-spacing: 0.8px; color: #1e40af; display: flex; align-items: center; gap: 0.5rem;"><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2.5" stroke-linecap="round" stroke-linejoin="round"><path d="M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path></svg>${groupName}</span>`;
          els.tocMobile.appendChild(headerMobile);
          
          // Sub-items
          items.forEach(s => {
            // Desktop sidebar
            const liDesktop = document.createElement('li');
            liDesktop.className = 'list-group-sub-item';
            const aDesktop = document.createElement('a');
            aDesktop.href = `#${s.id}`;
            aDesktop.textContent = s.title;
            aDesktop.addEventListener('click', (e) => {
              e.preventDefault();
              navigateToId(s.id);
              closeSidebar();
            });
            liDesktop.appendChild(aDesktop);
            els.toc.appendChild(liDesktop);
            
            // Mobile offcanvas
            const liMobile = document.createElement('li');
            liMobile.className = 'list-group-sub-item';
            const aMobile = document.createElement('a');
            aMobile.href = `#${s.id}`;
            aMobile.textContent = s.title;
            aMobile.addEventListener('click', (e) => {
              e.preventDefault();
              navigateToId(s.id);
              closeSidebar();
            });
            liMobile.appendChild(aMobile);
            els.tocMobile.appendChild(liMobile);
          });
        }
      });
      
      highlightActiveTOC();
    }

    function setActiveByIndex(i){
      const ids = state.filtered.map(idx => sectionConfig[idx].id);
      document.querySelectorAll('section').forEach(s => s.classList.remove('active'));
      const id = ids[i];
      const active = document.getElementById(id);
      if (active){
        active.classList.add('active');
        active.setAttribute('tabindex', '-1');
        active.focus({preventScroll:true});
      }
      updateControls();
      highlightActiveTOC();
      updateURLHash(id);
    }

    function updateControls(){
      const count = state.filtered.length;
      els.prev.disabled = state.index <= 0;
      els.next.disabled = state.index >= count - 1;
    }

    function filterTOC(query){
      const q = query.trim().toLowerCase();
      state.filtered = sectionConfig
        .map((s, i) => ({s, i}))
        .filter(({s}) => s.title.toLowerCase().includes(q) || s.tags.some(t => t.toLowerCase().includes(q)))
        .map(({i}) => i);

      state.index = Math.min(state.index, Math.max(0, state.filtered.length - 1));
      buildTOC();
      setActiveByIndex(state.index);
    }

    function navigate(delta){
      const count = state.filtered.length;
      const nextIndex = Math.min(Math.max(state.index + delta, 0), count - 1);
      if (nextIndex !== state.index){
        state.index = nextIndex;
        setActiveByIndex(state.index);
        // Scroll content to top
        const contentEl = document.querySelector('.content');
        if (contentEl) contentEl.scrollTop = 0;
      }
    }

    function navigateToId(id){
      const idxInFiltered = state.filtered.findIndex(fi => sectionConfig[fi].id === id);
      if (idxInFiltered !== -1){
        state.index = idxInFiltered;
        setActiveByIndex(state.index);
        // Scroll content to top
        const contentEl = document.querySelector('.content');
        if (contentEl) contentEl.scrollTop = 0;
      } else {
        state.filtered = sectionConfig.map((_, i) => i);
        buildTOC();
        navigateToId(id);
      }
    }

    function updateURLHash(id){
      const url = new URL(window.location);
      url.hash = id;
      history.replaceState(null, '', url);
    }

    function highlightActiveTOC(){
      const ids = state.filtered.map(idx => sectionConfig[idx].id);
      const activeId = ids[state.index];
      // Highlight desktop sidebar
      els.toc.querySelectorAll('a').forEach(a => {
        const isActive = a.getAttribute('href') === `#${activeId}`;
        a.classList.toggle('active', isActive);
        // Also toggle active on parent li for sub-items
        if (a.parentElement.classList.contains('list-group-sub-item')) {
          a.parentElement.classList.toggle('active', isActive);
        }
      });
      // Highlight mobile offcanvas
      els.tocMobile.querySelectorAll('a').forEach(a => {
        const isActive = a.getAttribute('href') === `#${activeId}`;
        a.classList.toggle('active', isActive);
        // Also toggle active on parent li for sub-items
        if (a.parentElement.classList.contains('list-group-sub-item')) {
          a.parentElement.classList.toggle('active', isActive);
        }
      });
    }

    function openSidebar(){
      const offcanvas = new bootstrap.Offcanvas(document.getElementById('sidebarOffcanvas'));
      offcanvas.show();
    }
    function closeSidebar(){
      const offcanvasElement = document.getElementById('sidebarOffcanvas');
      const offcanvas = bootstrap.Offcanvas.getInstance(offcanvasElement);
      if(offcanvas) offcanvas.hide();
    }

    // ---- Events ----
    els.prev.addEventListener('click', () => navigate(-1));
    els.next.addEventListener('click', () => navigate(1));

    // Keyboard navigation
    window.addEventListener('keydown', (e) => {
      if (e.key === 'ArrowLeft') navigate(-1);
      else if (e.key === 'ArrowRight') navigate(1);
      else if (e.key === 'Escape') closeSidebar();
    });

    // Deep linking on load/hash change
    window.addEventListener('hashchange', () => {
      const id = location.hash.replace('#','');
      if (id) navigateToId(id);
    });

    // Sidebar toggle (mobile)
    els.toggleSidebar.addEventListener('click', () => {
      openSidebar();
    });

    // Restore theme
    (function(){
      try {
        const saved = localStorage.getItem('concepts-theme');
        if (saved) { 
          document.documentElement.setAttribute('data-theme', saved);
          els.themeToggle.textContent = saved === 'light' ? 'üåó' : 'üåô';
        }
      } catch {}
    })();

    // Initial render
    buildTOC();
    
    // Navigate to hash if present, otherwise show first section
    const initialId = location.hash.replace('#','');
    if (initialId){ 
    navigateToId(initialId); 
    } else {
    setActiveByIndex(0);
    // Scroll content to top on initial load
    const contentEl = document.querySelector('.content');
    if (contentEl) contentEl.scrollTop = 0;
    }

  </script>
  <!-- Bootstrap JS -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>